{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kosenko/miniconda3/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 06-28 02:36:01 llm_engine.py:59] Initializing an LLM engine with config: model='huggyllama/llama-7b', dtype=torch.float16, use_dummy_weights=False, download_dir=None, use_np_weights=False, tensor_parallel_size=1, seed=0)\n",
      "INFO 06-28 02:36:01 tokenizer_utils.py:30] Using the LLaMA fast tokenizer in 'hf-internal-testing/llama-tokenizer' to avoid potential protobuf errors.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "libibverbs: Warning: couldn't open config directory '/etc/libibverbs.d'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 06-28 02:36:11 llm_engine.py:128] # GPU blocks: 2857, # CPU blocks: 512\n"
     ]
    }
   ],
   "source": [
    "from vllm import LLM, SamplingParams\n",
    "import os\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "import torch\n",
    "\n",
    "prompts = [\n",
    "    \"Hello, my name is \",\n",
    "    \"The president of the United States is\",\n",
    "    \"The capital of France is\",\n",
    "    \"The future of AI is\",\n",
    "]\n",
    "sampling_params = SamplingParams(temperature=0.8, top_k=0.95, max_tokens=1024)\n",
    "\n",
    "llm = LLM(\n",
    "    model=\"huggyllama/llama-7b\",\n",
    "    dtype=\"float16\",\n",
    ")\n",
    "\n",
    "\n",
    "# outputs = llm.generate(prompts, sampling_params)\n",
    "\n",
    "# # Print the outputs.\n",
    "# for output in outputs:\n",
    "#     prompt = output.prompt\n",
    "#     generated_text = output.outputs[0].text\n",
    "#     print(f\"Prompt: {prompt!r}, Generated text: {generated_text!r}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 4/4 [00:17<00:00,  4.33s/it]\n"
     ]
    }
   ],
   "source": [
    "prompts = [\n",
    "    \"Hello, my name is\",\n",
    "    \"The president of the United States is\",\n",
    "    \"The capital of France is\",\n",
    "    \"The future of AI is\",\n",
    "]\n",
    "\n",
    "outputs = llm.generate(prompts, sampling_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt: 'The capital of France is', Generated text: 'one of the most beautiful cities in the world. And it is no secret that the best views of Paris and its attractions are from a high place. So what is better than a Paris panoramic helicopter tour to know this city?\\nParis is the capital of France and is also known as the City of Lights. It is one of the most visited cities in the world. The city is the center of French culture and education, where you will find the headquarters of the most prestigious companies and the best universities in Europe.\\nBut how to know all the charms of Paris? Do you want to discover this magnificent city from the top?\\nThe city of Paris is full of monuments, statues and buildings to see. As a result, when you visit Paris, you must know that you can not see all the attractions in one day. The fact is that there are a lot of tourists that want to see it all.\\nThis is the reason why the most comfortable way to discover the City of Lights is a panoramic helicopter tour. A helicopter flight around the city will take you to a number of places that you can only see from a high place, and it is that the best way to enjoy the magnificent views of Paris and its attractions.\\nParis panoramic helicopter tours are an excellent choice to know Paris from the top.\\nParis panoramic helicopter tours are the best way to discover the City of Lights. It is an amazing experience that will give you a unique opportunity to see Paris in another way, as it is from above. You will know the best places to take pictures and the best places to get away from the city.\\nA panoramic helicopter tour is a great way to discover the most famous monuments of Paris from the top. You will know the top attractions of Paris such as the Eiffel Tower, the Louvre, Notre Dame Cathedral, the Arc de Triomphe, the Champs-Élysées, the Montmartre, the Montparnasse Tower, the Sacré-Coeur, the Trocadero, the Invalides and the Palace of Versailles.\\nA panoramic helicopter tour of Paris is also a great way to enjoy the most impressive views of the city. You will know the city from a different point of view.\\nA panoramic helicopter tour of Paris is also a unique experience that you should enjoy while you are there.\\nFor all these reasons, a Paris panoramic helicopter tour is the best way to enjoy the city.</s>'\n",
      "Prompt: 'Hello, my name is', Generated text: 'Danny and welcome to the final part of my article on the best Christmas gifts for teenagers.\\nWhile you’re here, don’t forget to check out my previous articles on the best Christmas gifts for kids and best Christmas gifts for moms.\\nIn this part of the article, I’ll be talking about the best Christmas gifts for teenagers that I think you should consider giving to your teenage children or your friends and family members.\\nThese gifts are the best gifts for teenagers who are 13-17 years old.\\nBefore I continue, let me warn you that I am not trying to tell you that you should be giving these gifts to your teenagers.\\nWhile I do think that they are great gifts, it’s your decision.\\nYou know your kids better than I do and you need to think about the things that they might like and things that they might not like.\\nTherefore, I am just giving you a list of gifts that I think are great gifts for teenagers.\\nIf you’re not sure which gifts to buy your teenagers, then this is a great place to start.\\nYou could also consider buying these gifts for yourself.\\nThis is my 1st recommendation for the best Christmas gifts for teenagers.\\nThis is the ultimate gift for teenagers.\\nA laptop is one of the best gifts for teenagers because it can be used for a wide range of purposes.\\nThey can use it for school, social media, entertainment and for anything that they want.\\nTherefore, if you’re looking for a gift that you can give to a teenager, then I think a laptop is a great choice.\\nA laptop is an expensive gift to give someone, but it’s something that a teenager will use for many years to come and they’ll appreciate you giving it to them.\\nI think that a laptop is the best gift for teenagers, but if you want to give a cheaper gift, then I would recommend buying a tablet.\\nA tablet is another great gift for teenagers because they can use it for the same purposes as a laptop.\\nThey can use it for school, social media, entertainment and anything else that they want.\\nIf you’re going to buy a tablet for your teenager, then I would recommend buying them a 10 inch tablet.\\nThis is the best size tablet to give to a teenager because it’s small enough to fit in a backpack or bag, but it’s big enough to use comfortably.\\nA tablet is also a very popular gift for teenagers because it’s light and compact, so your teenager won’t have to worry about carrying around a heavy laptop.\\nBoth laptops and tablets are a great gift for teenagers, but if you’re looking for something even more affordable, then I would recommend buying a 15 inch laptop bag.\\nThis is a laptop bag that will fit 15 inch laptops and it will also fit 10 inch tablets.\\nThis is a great gift for teenagers because they can use it for both laptops and tablets.\\nIt’s also a very popular gift for teenagers because it’s stylish and it looks great.\\nLaptops and tablets are great gifts for teenagers, but there are also some great gifts for teenagers that aren’t so expensive.\\nIf you’re looking for a gift that’s a little less expensive, then I would recommend buying a smartphone.\\nSmartphones are also a great gift for teenagers because they are a great way for your teenager to communicate with you and their friends.\\nA smartphone is also an affordable gift for teenagers because the best smartphones now cost under $100.\\nIf you want to get your teenager a smartphone, then I would recommend buying them an unlocked phone, because it’s cheaper and you can get the best plans for them.\\nAn unlocked phone is a smartphone that isn’t locked to a particular network, so it’s a great option for teenagers who want to get their own phone.\\nIt’s also a great option for teenagers who don’t have a good credit score because their parents will be able to buy them an unlocked phone that they can use.\\nAn unlocked phone is a great gift for teenagers because it’s something that they can use for the rest of their lives and it’s affordable.\\nIf you’re looking for a che'\n",
      "Prompt: 'The president of the United States is', Generated text: 'the leader of the free world, and is also the commander-in-chief of the military. For that reason, he has a lot of power and has a lot to lose if the military is not adequately trained and equipped.\\nUnder President Trump, the military has been significantly revamped. This includes reforms to the VA, a massive increase in military spending, and a restructuring of the military to focus more on national defense and less on international interventions.\\nMost of these changes have been bipartisan, but the president has had to fight an uphill battle to get Congress to agree to his vision for the military.\\nThe Department of Defense is the executive branch of the U.S. military and has a budget of $716 billion. It oversees 1.3 million military personnel who serve in all branches of the U.S. armed forces.\\nThe Army is the largest and oldest branch of the armed forces. There are currently 490,000 soldiers in the Army, and it is the only branch that requires soldiers to serve a minimum of two years on active duty and four years on reserve duty.\\nThe Navy is one of the oldest and largest branches of the military. There are currently 329,000 sailors in the Navy.\\nThe Air Force is the youngest branch of the military, but also the largest and fastest-growing. It currently has 327,000 military personnel.\\nThe U.S. Coast Guard is the smallest branch of the military, but is the only branch that is under the authority of the Department of Homeland Security. It has 42,000 personnel.\\nThe Marine Corps is the smallest branch of the military, but is also the most elite. There are currently 182,000 Marines in the Corps.\\nThe National Guard is an essential part of the U.S. military. The National Guard has a dual mission: to serve as the first line of defense for the states and to maintain a trained militia for the defense of the United States. Currently, there are 450,000 National Guardsmen.\\nThe U.S. military is the most powerful and technologically advanced military in the world. It also has one of the best equipped and trained forces in the world.\\nAccording to the World Factbook, the U.S. military is the largest spender in the world, with a total of $611 billion in defense spending in 2017.\\nThe U.S. military’s budget has increased since President Trump took office. The Department of Defense’s budget was $610 billion in 2017. In 2018, the U.S. military budget is expected to reach $686 billion.\\nThe U.S. military is also the most technologically advanced in the world. In 2017, the Department of Defense spent $207 billion on research and development, or 33% of its budget.\\nThe U.S. military has a large number of combat aircraft, tanks, and ships. The Army has 3,700 aircraft, the Navy has 377 ships, and the Air Force has 5,500 aircraft.\\nThe U.S. military also has a large number of nuclear warheads, and is the only country to have deployed an atomic bomb. The U.S. military has 6,800 nuclear warheads.\\nThe U.S. military’s nuclear arsenal includes intercontinental ballistic missiles and submarine-launched ballistic missiles. There are currently 420 intercontinental ballistic missiles, and 250 submarine-launched ballistic missiles.\\nThe U.S. military also has a large number of nuclear weapons. The U.S. military has approximately 6,800 nuclear weapons.\\nThe U.S. military has the largest nuclear arsenal in the world, and has been the only country to ever use nuclear weapons. The U.S. military has used nuclear weapons twice: in 1945, and in 1962.\\nThe U.S. military has 58 military bases spread throughout the world. The United States has military bases in all seven continents. The U.S. military has 48,000 troops in Europe, 27,000 troops in the Middle East, and 23,000 troops in Asia.\\nThe U.S. military has the largest number of troops stationed in Germany, with 37,000 soldiers. The U.S. military'\n",
      "Prompt: 'The future of AI is', Generated text: 'in a future\\nThis might sound like a depressing conclusion, but it’s not.\\nThe truth is, we’re currently in an AI winter. There is no need to panic about the future of AI, but there is a need to reconsider the current situation.\\nAI Winter\\nThe term “AI winter” was first used in 1989 by the Nobel laureate physicist Murray Gell-Mann. He used the term to describe a period during the 1980s when AI research declined. Gell-Mann’s AI winter was sparked by a series of breakthroughs, and then a lack of progress.\\nThe ‘80s was a period of discovery, and then one of disappointment. In the late 1950s, computers had already started to outperform humans in simple maths and logic problems.\\nThe first breakthroughs were the development of the computer mouse and the development of computer languages like BASIC. Computers became more affordable, and home computers were launched.\\nThe first breakthroughs were the development of the computer mouse and the development of computer languages like BASIC.\\nA few years later, computer scientists developed algorithms to allow computers to learn. This resulted in the development of expert systems, machines that could solve problems by following sets of rules.\\nIn 1980, the world’s first AI computer beat the world champion at chess.\\nThat same year, a computer beat the world champion at chess.\\nIn 1987, the world’s first AI computer beat the world champion at chess. The IBM computer Deep Thought was programmed to simulate 200 million chess games per second. It is no wonder that the world was excited about AI.\\nYet, just two years later, the first AI winter struck.\\nIn 1989, the world’s first AI computer beat the world champion at chess.\\nTwo years later, the world’s first AI computer beat the world champion at chess.\\nThe IBM computer Deep Thought was programmed to simulate 200 million chess games per second.\\nAI Research Is Not Growing\\nIt is still a great achievement that computers can beat humans in chess, but the excitement was short-lived. In 1995, the world’s first AI computer beat the world champion at chess. The computer was called Deep Blue.\\nIn 2011, the world’s first AI computer beat the world champion at chess. The computer was called Deep Fritz.\\nDeep Fritz was supposed to have a 100% winning percentage. However, during the chess match, it made a mistake and lost the game.\\nDeep Fritz was supposed to have a 100% winning percentage, but it lost the game.\\nAI research has been taking place for decades, but it’s still a far cry from what was hoped for. In the ‘80s, there were hopes that AI would solve all of humanity’s problems. In the 2000s, AI was heralded as the next big thing in technology.\\nThe media hype has died down, and the public’s excitement has dissipated. Deep Blue and Deep Fritz were impressive, but AI research has not increased since then.\\nThere is no need to panic about the future of AI, but there is a need to reconsider the current situation.\\nThe three main reasons why the AI winter is getting colder are:\\n1) No breakthroughs\\nWe have seen no real breakthroughs in AI since 1995. In the ‘90s, there were breakthroughs in search algorithms and neural networks.\\nThe media hype has died down, and the public’s excitement has dissipated.\\nHowever, these breakthroughs have not led to any real progress. IBM’s Deep Blue and Deep Fritz were exciting, but that was more than 20 years ago.\\nMore recently, AlphaGo, an AI computer that can play Go, was launched by Google.\\nAlphaGo, an AI computer that can play Go, was launched by Google.\\nThis is an impressive achievement, but it is still far from what was hoped for.\\n2) No demand\\nThe second reason is that there is no demand for AI research.\\nIn the ‘80s, there was a lot of demand for AI. In the 2000s, there was a lot of demand for AI.\\nHowever, today, there is no real demand for AI. The only areas where AI is currently being used are'\n"
     ]
    }
   ],
   "source": [
    "for output in outputs:\n",
    "    prompt = output.prompt\n",
    "    generated_text = output.outputs[0].text\n",
    "    print(f\"Prompt: {prompt!r}, Generated text: {generated_text!r}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kosenko/miniconda3/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]/home/kosenko/miniconda3/lib/python3.10/site-packages/transformers/modeling_utils.py:440: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  with safe_open(checkpoint_file, framework=\"pt\") as f:\n",
      "/home/kosenko/miniconda3/lib/python3.10/site-packages/torch/_utils.py:776: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  return self.fget.__get__(instance, owner)()\n",
      "/home/kosenko/miniconda3/lib/python3.10/site-packages/torch/storage.py:899: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  storage = cls(wrap_storage=untyped_storage)\n",
      "/home/kosenko/miniconda3/lib/python3.10/site-packages/safetensors/torch.py:99: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  with safe_open(filename, framework=\"pt\", device=device) as f:\n",
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:14<00:00,  7.17s/it]\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "import torch\n",
    "import os\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "\n",
    "model_name = \"huggyllama/llama-7b\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name, torch_dtype=torch.float16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompts = [\n",
    "    \"Hello, my name is\",\n",
    "    \"The president of the United States is\",\n",
    "    \"The capital of France is\",\n",
    "    \"The future of AI is\",\n",
    "]\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "tokenizer.pad_token_id = tokenizer.eos_token_id\n",
    "tokenized_tokens = tokenizer(\n",
    "    prompts,\n",
    "    return_tensors=\"pt\",\n",
    "    padding=True,\n",
    ").to(\"cuda\")\n",
    "\n",
    "del tokenized_tokens[\"token_type_ids\"]\n",
    "with torch.no_grad():\n",
    "    result = model.generate(\n",
    "        input_ids=tokenized_tokens[\"input_ids\"],\n",
    "        max_new_tokens=1024,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"</s></s><s> Hello, my name is and I'm writing you today to learn more about the 2016 Ford F-150 XLT 4WD SuperCrew 5.5' Box available from Northside Ford Lincoln in the Northside Ford Lincoln. My car details are as follows:\\nI'm interested in this 2016 Ford F-150 XLT 4WD SuperCrew 5.5' Box (Stock #10000) that I saw on the Northside Ford Lincoln website and would like to get more information on it. Could you send me more information? Thank you!\\nI'm interested in this 2016 Ford F-150 XLT 4WD SuperCrew 5.5' Box (Stock #10000) that I saw on the Northside Ford Lincoln website and would like to get more information on it. Please contact me as soon as possible. Thanks!\\nHi, my name is and I am interested in your I need info about your 2016 Ford F-150 XLT 4WD SuperCrew 5.5' Box (Stock #10000) that I saw on the Northside Ford Lincoln website.\\nHi, my name is and I am interested in your I need info about your 2016 Ford F-150 XLT 4WD SuperCrew 5.5' Box (Stock #10000) that I saw on the Northside Ford Lincoln website. Please contact me as soon as possible. Thanks!</s><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk>\",\n",
       " '<s> The president of the United States is a man who has never held a real job, who has never served in the military, who has never been a small business owner, who has never been a governor, who has never been a mayor, who has never been a senator, who has never been a congressman, who has never been a state legislator, who has never been a county official, who has never been a city councilman, who has never been a school board member, who has never been a church pastor, who has never been a Boy Scout leader, who has never been a Little League coach, who has never been a PTA president, who has never been a volunteer fireman, who has never been a volunteer emergency medical technician, who has never been a volunteer hospital auxiliary member, who has never been a volunteer at a homeless shelter, who has never been a volunteer at a soup kitchen, who has never been a volunteer at a battered women’s shelter, who has never been a volunteer at a nursing home, who has never been a volunteer at a hospital, who has never been a volunteer at a hospital, who has never been a volunteer at a hospital, who has never been a volunteer at a hospital, who has never been a volunteer at a hospital, who has never been a volunteer at a hospital, who has never been a volunteer at a hospital, who has never been a volunteer at a hospital, who has never been a volunteer at a hospital, who has never been a volunteer at a hospital, who has never been a volunteer at a hospital, who has never been a volunteer at a hospital, who has never been a volunteer at a hospital, who has never been a volunteer at a hospital, who has never been a volunteer at a hospital, who has never been a volunteer at a hospital, who has never been a volunteer at a hospital, who has never been a volunteer at a hospital, who has never been a volunteer at a hospital, who has never been a volunteer at a hospital, who has never been a volunteer at a hospital, who has never been a volunteer at a hospital, who has never been a volunteer at a hospital, who has never been a volunteer at a hospital, who has never been a volunteer at a hospital, who has never been a volunteer at a hospital, who has never been a volunteer at a hospital, who has never been a volunteer at a hospital, who has never been a volunteer at a hospital, who has never been a volunteer at a hospital, who has never been a volunteer at a hospital, who has never been a volunteer at a hospital, who has never been a volunteer at a hospital, who has never been a volunteer at a hospital, who has never been a volunteer at a hospital, who has never been a volunteer at a hospital, who has never been a volunteer at a hospital, who has never been a volunteer at a hospital, who has never been a volunteer at a hospital, who has never been a volunteer at a hospital, who has never been a volunteer at a hospital, who has never been a volunteer at a hospital, who has never been a volunteer at a hospital, who has never been a volunteer at a hospital, who has never been a volunteer at a hospital, who has never been a volunteer at a hospital, who has never been a volunteer at a hospital, who has never been a volunteer at a hospital, who has never been a volunteer at a hospital, who has never been a volunteer at a hospital, who has never been a volunteer at a hospital, who has never been a volunteer at a hospital, who has never been a volunteer at a hospital, who has never been a volunteer at a hospital, who has never been a volunteer at a hospital, who has never been a volunteer at a hospital, who has never been a volunteer at a hospital, who has never been a volunteer at a hospital, who has never been a volunteer at a hospital, who has never been a volunteer at a hospital, who has never been a volunteer at a hospital, who has never been a volunteer at a hospital, who has never been a volunteer at a hospital, who has never been a volunteer at a hospital, who has never been a volunteer at a hospital, who has never been a volunteer at a hospital, who has never been a volunteer at a hospital, who has never been a volunteer at a hospital, who has never been a volunteer at a hospital, who has never been a volunteer at a hospital, who has never been a volunteer at a hospital, who has never been a volunteer at a hospital, who has never been a volunteer at a hospital, who',\n",
       " '</s></s><s> The capital of France is a city of contrasts. It is a city of history, of culture, of art, of fashion, of food, of romance, of architecture, of beauty, of style, of sophistication, of elegance, of glamour, of chic, of glitz, of glamour, of sophistication, of elegance, of style, of fashion, of beauty, of romance, of art, of culture, of history, of food, of wine, of fashion, of architecture, of beauty, of style, of sophistication, of elegance, of glamour, of chic, of glitz, of glamour, of sophistication, of elegance, of style, of fashion, of beauty, of romance, of art, of culture, of history, of food, of wine, of fashion, of architecture, of beauty, of style, of sophistication, of elegance, of glamour, of chic, of glitz, of glamour, of sophistication, of elegance, of style, of fashion, of beauty, of romance, of art, of culture, of history, of food, of wine, of fashion, of architecture, of beauty, of style, of sophistication, of elegance, of glamour, of chic, of glitz, of glamour, of sophistication, of elegance, of style, of fashion, of beauty, of romance, of art, of culture, of history, of food, of wine, of fashion, of architecture, of beauty, of style, of sophistication, of elegance, of glamour, of chic, of glitz, of glamour, of sophistication, of elegance, of style, of fashion, of beauty, of romance, of art, of culture, of history, of food, of wine, of fashion, of architecture, of beauty, of style, of sophistication, of elegance, of glamour, of chic, of glitz, of glamour, of sophistication, of elegance, of style, of fashion, of beauty, of romance, of art, of culture, of history, of food, of wine, of fashion, of architecture, of beauty, of style, of sophistication, of elegance, of glamour, of chic, of glitz, of glamour, of sophistication, of elegance, of style, of fashion, of beauty, of romance, of art, of culture, of history, of food, of wine, of fashion, of architecture, of beauty, of style, of sophistication, of elegance, of glamour, of chic, of glitz, of glamour, of sophistication, of elegance, of style, of fashion, of beauty, of romance, of art, of culture, of history, of food, of wine, of fashion, of architecture, of beauty, of style, of sophistication, of elegance, of glamour, of chic, of glitz, of glamour, of sophistication, of elegance, of style, of fashion, of beauty, of romance, of art, of culture, of history, of food, of wine, of fashion, of architecture, of beauty, of style, of sophistication, of elegance, of glamour, of chic, of glitz, of glamour, of sophistication, of elegance, of style, of fashion, of beauty, of romance, of art, of culture, of history, of food, of wine, of fashion, of architecture, of beauty, of style, of sophistication, of elegance, of glamour, of chic, of glitz, of glamour, of sophistication, of elegance, of style, of fashion, of beauty, of romance, of art, of culture, of history, of food, of wine, of fashion, of architecture, of beauty, of style, of sophistication, of elegance, of glamour, of chic, of glitz, of glamour, of sophistication, of elegance, of style, of fashion, of beauty, of romance, of art, of culture, of history, of food, of wine, of fashion, of architecture, of beauty, of style, of sophistication, of elegance, of glamour, of chic, of glitz, of glamour, of sophistication, of elegance, of style, of fashion, of beauty, of romance, of art, of culture, of history, of food, of wine, of fashion, of architecture, of beauty, of',\n",
       " '</s><s> The future of AI is here.\\nThe future of AI is here. The technology is already being used in a variety of industries, from healthcare to manufacturing.\\nThe future of AI is here. The technology is already being used in a variety of industries, from healthcare to manufacturing. But what does the future hold for AI?\\nThe future of AI is here. The technology is already being used in a variety of industries, from healthcare to manufacturing. But what does the future hold for AI? The future of AI is here. The technology is already being used in a variety of industries, from healthcare to manufacturing. But what does the future hold for AI?\\nThe future of AI is here. The technology is already being used in a variety of industries, from healthcare to manufacturing. But what does the future hold for AI? The future of AI is here. The technology is already being used in a variety of industries, from healthcare to manufacturing. But what does the future hold for AI? The future of AI is here. The technology is already being used in a variety of industries, from healthcare to manufacturing. But what does the future hold for AI? The future of AI is here. The technology is already being used in a variety of industries, from healthcare to manufacturing. But what does the future hold for AI? The future of AI is here. The technology is already being used in a variety of industries, from healthcare to manufacturing. But what does the future hold for AI? The future of AI is here. The technology is already being used in a variety of industries, from healthcare to manufacturing. But what does the future hold for AI? The future of AI is here. The technology is already being used in a variety of industries, from healthcare to manufacturing. But what does the future hold for AI? The future of AI is here. The technology is already being used in a variety of industries, from healthcare to manufacturing. But what does the future hold for AI? The future of AI is here. The technology is already being used in a variety of industries, from healthcare to manufacturing. But what does the future hold for AI? The future of AI is here. The technology is already being used in a variety of industries, from healthcare to manufacturing. But what does the future hold for AI? The future of AI is here. The technology is already being used in a variety of industries, from healthcare to manufacturing. But what does the future hold for AI? The future of AI is here. The technology is already being used in a variety of industries, from healthcare to manufacturing. But what does the future hold for AI? The future of AI is here. The technology is already being used in a variety of industries, from healthcare to manufacturing. But what does the future hold for AI? The future of AI is here. The technology is already being used in a variety of industries, from healthcare to manufacturing. But what does the future hold for AI? The future of AI is here. The technology is already being used in a variety of industries, from healthcare to manufacturing. But what does the future hold for AI? The future of AI is here. The technology is already being used in a variety of industries, from healthcare to manufacturing. But what does the future hold for AI? The future of AI is here. The technology is already being used in a variety of industries, from healthcare to manufacturing. But what does the future hold for AI? The future of AI is here. The technology is already being used in a variety of industries, from healthcare to manufacturing. But what does the future hold for AI? The future of AI is here. The technology is already being used in a variety of industries, from healthcare to manufacturing. But what does the future hold for AI? The future of AI is here. The technology is already being used in a variety of industries, from healthcare to manufacturing. But what does the future hold for AI? The future of AI is here. The technology is already being used in a variety of industries, from healthcare to manufacturing. But what does the future hold for AI? The future of AI is here. The technology is already being used in a variety of industries, from healthcare to manufacturing. But what does the future hold for AI? The future of AI is here. The technology is already being used in a variety of industries, from healthcare to manufacturing. But what does the future hold for AI? The future']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.batch_decode(result)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## add xglm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kosenko/miniconda3/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Downloading (…)lve/main/config.json: 100%|██████████| 1.21k/1.21k [00:00<00:00, 9.02MB/s]\n",
      "Downloading model.safetensors: 100%|██████████| 892M/892M [00:02<00:00, 392MB/s]  \n",
      "/home/kosenko/miniconda3/lib/python3.10/site-packages/transformers/modeling_utils.py:440: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  with safe_open(checkpoint_file, framework=\"pt\") as f:\n",
      "/home/kosenko/miniconda3/lib/python3.10/site-packages/torch/_utils.py:776: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  return self.fget.__get__(instance, owner)()\n",
      "/home/kosenko/miniconda3/lib/python3.10/site-packages/torch/storage.py:899: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  storage = cls(wrap_storage=untyped_storage)\n",
      "/home/kosenko/miniconda3/lib/python3.10/site-packages/safetensors/torch.py:99: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  with safe_open(filename, framework=\"pt\", device=device) as f:\n",
      "Downloading (…)neration_config.json: 100%|██████████| 147/147 [00:00<00:00, 737kB/s]\n",
      "Downloading (…)ve/main/spiece.model: 100%|██████████| 792k/792k [00:00<00:00, 1.81MB/s]\n",
      "Downloading (…)/main/tokenizer.json: 100%|██████████| 1.39M/1.39M [00:00<00:00, 2.56MB/s]\n",
      "/home/kosenko/miniconda3/lib/python3.10/site-packages/transformers/models/t5/tokenization_t5_fast.py:155: FutureWarning: This tokenizer was incorrectly instantiated with a model max length of 512 which will be corrected in Transformers v5.\n",
      "For now, this behavior is kept to avoid breaking backwards compatibility when padding/encoding with `truncation is True`.\n",
      "- Be aware that you SHOULD NOT rely on t5-base automatically truncating your input to 512 when padding/encoding.\n",
      "- If you want to encode/pad to sequences longer than 512 you can either instantiate this tokenizer with `model_max_length` or pass `max_length` when encoding/padding.\n",
      "- To avoid this warning, please instantiate this tokenizer with `model_max_length` set to your preferred value.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer\n",
    "\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(\"t5-base\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"t5-base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 512])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['hello world hello world hello world hello world hello world hello world hello world hello world hello world hello world hello world hello world hello world hello world hello world hello world hello world hello world hello world hello world hello world hello world hello world hello world hello world hello world hello world hello world hello world hello world hello world hello world hello world hello world hello world hello world hello world hello world hello world hello world hello world hello world hello world hello world hello world hello world hello world hello world hello world hello world hello world hello world hello world hello world hello world hello world          .............................................................. hello world.. hello world.. hello world.. hello world.. hello world.. hello world.. hello world... hello world... hello world... hello world... hello world... hello world... hello world... hello world... hello world... hello world... hello world... hello world.. hello world.. hello world.. hello world.. hello world.. hello world... hello world... hello world... hello world... hello world... hello world... hello world... \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \"']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens = tokenizer(\"hello world\", return_tensors='pt').to('cuda')\n",
    "result = model.generate(**tokens, min_length=512, max_length=512)\n",
    "print(result.shape)\n",
    "tokenizer.batch_decode(result, skip_special_tokens=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
