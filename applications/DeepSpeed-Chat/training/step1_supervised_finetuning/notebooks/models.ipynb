{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kosenko/miniconda3/lib/python3.10/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from transformers import AutoModel, AutoTokenizer\n",
    "\n",
    "# tokenizer = AutoTokenizer.from_pretrained(\"facebook/xglm-1.7B\")\n",
    "# model = AutoModel.from_pretrained(\"facebook/xglm-1.7B\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64\n"
     ]
    }
   ],
   "source": [
    "num = 256008 + 56\n",
    "for i in range(1, 65):\n",
    "    if(i+num) % 64 == 0:\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at facebook/xglm-1.7B were not used when initializing XGLMModel: ['lm_head.weight']\n",
      "- This IS expected if you are initializing XGLMModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XGLMModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "model = AutoModel.from_pretrained(\"facebook/xglm-1.7B\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OPTModel(\n",
       "  (decoder): OPTDecoder(\n",
       "    (embed_tokens): Embedding(50272, 512, padding_idx=1)\n",
       "    (embed_positions): OPTLearnedPositionalEmbedding(2050, 1024)\n",
       "    (project_out): Linear(in_features=1024, out_features=512, bias=False)\n",
       "    (project_in): Linear(in_features=512, out_features=1024, bias=False)\n",
       "    (layers): ModuleList(\n",
       "      (0-23): 24 x OPTDecoderLayer(\n",
       "        (self_attn): OPTAttention(\n",
       "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        )\n",
       "        (activation_fn): ReLU()\n",
       "        (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGLMModel(\n",
       "  (embed_tokens): Embedding(256008, 2048, padding_idx=1)\n",
       "  (embed_positions): XGLMSinusoidalPositionalEmbedding()\n",
       "  (layers): ModuleList(\n",
       "    (0-23): 24 x XGLMDecoderLayer(\n",
       "      (self_attn): XGLMAttention(\n",
       "        (k_proj): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "        (v_proj): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "        (q_proj): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "        (out_proj): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "      )\n",
       "      (activation_fn): GELUActivation()\n",
       "      (self_attn_layer_norm): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
       "      (fc1): Linear(in_features=2048, out_features=8192, bias=True)\n",
       "      (fc2): Linear(in_features=8192, out_features=2048, bias=True)\n",
       "      (final_layer_norm): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "  )\n",
       "  (layer_norm): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "decoder.layers.0.self_attn.k_proj\n",
      "decoder.layers.0.self_attn.v_proj\n",
      "decoder.layers.0.self_attn.q_proj\n",
      "decoder.layers.0.self_attn.out_proj\n",
      "decoder.layers.0.fc1\n",
      "decoder.layers.0.fc2\n",
      "decoder.layers.1.self_attn.k_proj\n",
      "decoder.layers.1.self_attn.v_proj\n",
      "decoder.layers.1.self_attn.q_proj\n",
      "decoder.layers.1.self_attn.out_proj\n",
      "decoder.layers.1.fc1\n",
      "decoder.layers.1.fc2\n",
      "decoder.layers.2.self_attn.k_proj\n",
      "decoder.layers.2.self_attn.v_proj\n",
      "decoder.layers.2.self_attn.q_proj\n",
      "decoder.layers.2.self_attn.out_proj\n",
      "decoder.layers.2.fc1\n",
      "decoder.layers.2.fc2\n",
      "decoder.layers.3.self_attn.k_proj\n",
      "decoder.layers.3.self_attn.v_proj\n",
      "decoder.layers.3.self_attn.q_proj\n",
      "decoder.layers.3.self_attn.out_proj\n",
      "decoder.layers.3.fc1\n",
      "decoder.layers.3.fc2\n",
      "decoder.layers.4.self_attn.k_proj\n",
      "decoder.layers.4.self_attn.v_proj\n",
      "decoder.layers.4.self_attn.q_proj\n",
      "decoder.layers.4.self_attn.out_proj\n",
      "decoder.layers.4.fc1\n",
      "decoder.layers.4.fc2\n",
      "decoder.layers.5.self_attn.k_proj\n",
      "decoder.layers.5.self_attn.v_proj\n",
      "decoder.layers.5.self_attn.q_proj\n",
      "decoder.layers.5.self_attn.out_proj\n",
      "decoder.layers.5.fc1\n",
      "decoder.layers.5.fc2\n",
      "decoder.layers.6.self_attn.k_proj\n",
      "decoder.layers.6.self_attn.v_proj\n",
      "decoder.layers.6.self_attn.q_proj\n",
      "decoder.layers.6.self_attn.out_proj\n",
      "decoder.layers.6.fc1\n",
      "decoder.layers.6.fc2\n",
      "decoder.layers.7.self_attn.k_proj\n",
      "decoder.layers.7.self_attn.v_proj\n",
      "decoder.layers.7.self_attn.q_proj\n",
      "decoder.layers.7.self_attn.out_proj\n",
      "decoder.layers.7.fc1\n",
      "decoder.layers.7.fc2\n",
      "decoder.layers.8.self_attn.k_proj\n",
      "decoder.layers.8.self_attn.v_proj\n",
      "decoder.layers.8.self_attn.q_proj\n",
      "decoder.layers.8.self_attn.out_proj\n",
      "decoder.layers.8.fc1\n",
      "decoder.layers.8.fc2\n",
      "decoder.layers.9.self_attn.k_proj\n",
      "decoder.layers.9.self_attn.v_proj\n",
      "decoder.layers.9.self_attn.q_proj\n",
      "decoder.layers.9.self_attn.out_proj\n",
      "decoder.layers.9.fc1\n",
      "decoder.layers.9.fc2\n",
      "decoder.layers.10.self_attn.k_proj\n",
      "decoder.layers.10.self_attn.v_proj\n",
      "decoder.layers.10.self_attn.q_proj\n",
      "decoder.layers.10.self_attn.out_proj\n",
      "decoder.layers.10.fc1\n",
      "decoder.layers.10.fc2\n",
      "decoder.layers.11.self_attn.k_proj\n",
      "decoder.layers.11.self_attn.v_proj\n",
      "decoder.layers.11.self_attn.q_proj\n",
      "decoder.layers.11.self_attn.out_proj\n",
      "decoder.layers.11.fc1\n",
      "decoder.layers.11.fc2\n",
      "decoder.layers.12.self_attn.k_proj\n",
      "decoder.layers.12.self_attn.v_proj\n",
      "decoder.layers.12.self_attn.q_proj\n",
      "decoder.layers.12.self_attn.out_proj\n",
      "decoder.layers.12.fc1\n",
      "decoder.layers.12.fc2\n",
      "decoder.layers.13.self_attn.k_proj\n",
      "decoder.layers.13.self_attn.v_proj\n",
      "decoder.layers.13.self_attn.q_proj\n",
      "decoder.layers.13.self_attn.out_proj\n",
      "decoder.layers.13.fc1\n",
      "decoder.layers.13.fc2\n",
      "decoder.layers.14.self_attn.k_proj\n",
      "decoder.layers.14.self_attn.v_proj\n",
      "decoder.layers.14.self_attn.q_proj\n",
      "decoder.layers.14.self_attn.out_proj\n",
      "decoder.layers.14.fc1\n",
      "decoder.layers.14.fc2\n",
      "decoder.layers.15.self_attn.k_proj\n",
      "decoder.layers.15.self_attn.v_proj\n",
      "decoder.layers.15.self_attn.q_proj\n",
      "decoder.layers.15.self_attn.out_proj\n",
      "decoder.layers.15.fc1\n",
      "decoder.layers.15.fc2\n",
      "decoder.layers.16.self_attn.k_proj\n",
      "decoder.layers.16.self_attn.v_proj\n",
      "decoder.layers.16.self_attn.q_proj\n",
      "decoder.layers.16.self_attn.out_proj\n",
      "decoder.layers.16.fc1\n",
      "decoder.layers.16.fc2\n",
      "decoder.layers.17.self_attn.k_proj\n",
      "decoder.layers.17.self_attn.v_proj\n",
      "decoder.layers.17.self_attn.q_proj\n",
      "decoder.layers.17.self_attn.out_proj\n",
      "decoder.layers.17.fc1\n",
      "decoder.layers.17.fc2\n",
      "decoder.layers.18.self_attn.k_proj\n",
      "decoder.layers.18.self_attn.v_proj\n",
      "decoder.layers.18.self_attn.q_proj\n",
      "decoder.layers.18.self_attn.out_proj\n",
      "decoder.layers.18.fc1\n",
      "decoder.layers.18.fc2\n",
      "decoder.layers.19.self_attn.k_proj\n",
      "decoder.layers.19.self_attn.v_proj\n",
      "decoder.layers.19.self_attn.q_proj\n",
      "decoder.layers.19.self_attn.out_proj\n",
      "decoder.layers.19.fc1\n",
      "decoder.layers.19.fc2\n",
      "decoder.layers.20.self_attn.k_proj\n",
      "decoder.layers.20.self_attn.v_proj\n",
      "decoder.layers.20.self_attn.q_proj\n",
      "decoder.layers.20.self_attn.out_proj\n",
      "decoder.layers.20.fc1\n",
      "decoder.layers.20.fc2\n",
      "decoder.layers.21.self_attn.k_proj\n",
      "decoder.layers.21.self_attn.v_proj\n",
      "decoder.layers.21.self_attn.q_proj\n",
      "decoder.layers.21.self_attn.out_proj\n",
      "decoder.layers.21.fc1\n",
      "decoder.layers.21.fc2\n",
      "decoder.layers.22.self_attn.k_proj\n",
      "decoder.layers.22.self_attn.v_proj\n",
      "decoder.layers.22.self_attn.q_proj\n",
      "decoder.layers.22.self_attn.out_proj\n",
      "decoder.layers.22.fc1\n",
      "decoder.layers.22.fc2\n",
      "decoder.layers.23.self_attn.k_proj\n",
      "decoder.layers.23.self_attn.v_proj\n",
      "decoder.layers.23.self_attn.q_proj\n",
      "decoder.layers.23.self_attn.out_proj\n",
      "decoder.layers.23.fc1\n",
      "decoder.layers.23.fc2\n"
     ]
    }
   ],
   "source": [
    "part_module_name = \"decoder.layers\"\n",
    "for name, module in model.named_modules():\n",
    "\tif isinstance(module, nn.Linear) and part_module_name in name:\n",
    "\t\tprint(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layers.0.self_attn.k_proj\n",
      "layers.0.self_attn.v_proj\n",
      "layers.0.self_attn.q_proj\n",
      "layers.0.self_attn.out_proj\n",
      "layers.0.fc1\n",
      "layers.0.fc2\n",
      "layers.1.self_attn.k_proj\n",
      "layers.1.self_attn.v_proj\n",
      "layers.1.self_attn.q_proj\n",
      "layers.1.self_attn.out_proj\n",
      "layers.1.fc1\n",
      "layers.1.fc2\n",
      "layers.2.self_attn.k_proj\n",
      "layers.2.self_attn.v_proj\n",
      "layers.2.self_attn.q_proj\n",
      "layers.2.self_attn.out_proj\n",
      "layers.2.fc1\n",
      "layers.2.fc2\n",
      "layers.3.self_attn.k_proj\n",
      "layers.3.self_attn.v_proj\n",
      "layers.3.self_attn.q_proj\n",
      "layers.3.self_attn.out_proj\n",
      "layers.3.fc1\n",
      "layers.3.fc2\n",
      "layers.4.self_attn.k_proj\n",
      "layers.4.self_attn.v_proj\n",
      "layers.4.self_attn.q_proj\n",
      "layers.4.self_attn.out_proj\n",
      "layers.4.fc1\n",
      "layers.4.fc2\n",
      "layers.5.self_attn.k_proj\n",
      "layers.5.self_attn.v_proj\n",
      "layers.5.self_attn.q_proj\n",
      "layers.5.self_attn.out_proj\n",
      "layers.5.fc1\n",
      "layers.5.fc2\n",
      "layers.6.self_attn.k_proj\n",
      "layers.6.self_attn.v_proj\n",
      "layers.6.self_attn.q_proj\n",
      "layers.6.self_attn.out_proj\n",
      "layers.6.fc1\n",
      "layers.6.fc2\n",
      "layers.7.self_attn.k_proj\n",
      "layers.7.self_attn.v_proj\n",
      "layers.7.self_attn.q_proj\n",
      "layers.7.self_attn.out_proj\n",
      "layers.7.fc1\n",
      "layers.7.fc2\n",
      "layers.8.self_attn.k_proj\n",
      "layers.8.self_attn.v_proj\n",
      "layers.8.self_attn.q_proj\n",
      "layers.8.self_attn.out_proj\n",
      "layers.8.fc1\n",
      "layers.8.fc2\n",
      "layers.9.self_attn.k_proj\n",
      "layers.9.self_attn.v_proj\n",
      "layers.9.self_attn.q_proj\n",
      "layers.9.self_attn.out_proj\n",
      "layers.9.fc1\n",
      "layers.9.fc2\n",
      "layers.10.self_attn.k_proj\n",
      "layers.10.self_attn.v_proj\n",
      "layers.10.self_attn.q_proj\n",
      "layers.10.self_attn.out_proj\n",
      "layers.10.fc1\n",
      "layers.10.fc2\n",
      "layers.11.self_attn.k_proj\n",
      "layers.11.self_attn.v_proj\n",
      "layers.11.self_attn.q_proj\n",
      "layers.11.self_attn.out_proj\n",
      "layers.11.fc1\n",
      "layers.11.fc2\n",
      "layers.12.self_attn.k_proj\n",
      "layers.12.self_attn.v_proj\n",
      "layers.12.self_attn.q_proj\n",
      "layers.12.self_attn.out_proj\n",
      "layers.12.fc1\n",
      "layers.12.fc2\n",
      "layers.13.self_attn.k_proj\n",
      "layers.13.self_attn.v_proj\n",
      "layers.13.self_attn.q_proj\n",
      "layers.13.self_attn.out_proj\n",
      "layers.13.fc1\n",
      "layers.13.fc2\n",
      "layers.14.self_attn.k_proj\n",
      "layers.14.self_attn.v_proj\n",
      "layers.14.self_attn.q_proj\n",
      "layers.14.self_attn.out_proj\n",
      "layers.14.fc1\n",
      "layers.14.fc2\n",
      "layers.15.self_attn.k_proj\n",
      "layers.15.self_attn.v_proj\n",
      "layers.15.self_attn.q_proj\n",
      "layers.15.self_attn.out_proj\n",
      "layers.15.fc1\n",
      "layers.15.fc2\n",
      "layers.16.self_attn.k_proj\n",
      "layers.16.self_attn.v_proj\n",
      "layers.16.self_attn.q_proj\n",
      "layers.16.self_attn.out_proj\n",
      "layers.16.fc1\n",
      "layers.16.fc2\n",
      "layers.17.self_attn.k_proj\n",
      "layers.17.self_attn.v_proj\n",
      "layers.17.self_attn.q_proj\n",
      "layers.17.self_attn.out_proj\n",
      "layers.17.fc1\n",
      "layers.17.fc2\n",
      "layers.18.self_attn.k_proj\n",
      "layers.18.self_attn.v_proj\n",
      "layers.18.self_attn.q_proj\n",
      "layers.18.self_attn.out_proj\n",
      "layers.18.fc1\n",
      "layers.18.fc2\n",
      "layers.19.self_attn.k_proj\n",
      "layers.19.self_attn.v_proj\n",
      "layers.19.self_attn.q_proj\n",
      "layers.19.self_attn.out_proj\n",
      "layers.19.fc1\n",
      "layers.19.fc2\n",
      "layers.20.self_attn.k_proj\n",
      "layers.20.self_attn.v_proj\n",
      "layers.20.self_attn.q_proj\n",
      "layers.20.self_attn.out_proj\n",
      "layers.20.fc1\n",
      "layers.20.fc2\n",
      "layers.21.self_attn.k_proj\n",
      "layers.21.self_attn.v_proj\n",
      "layers.21.self_attn.q_proj\n",
      "layers.21.self_attn.out_proj\n",
      "layers.21.fc1\n",
      "layers.21.fc2\n",
      "layers.22.self_attn.k_proj\n",
      "layers.22.self_attn.v_proj\n",
      "layers.22.self_attn.q_proj\n",
      "layers.22.self_attn.out_proj\n",
      "layers.22.fc1\n",
      "layers.22.fc2\n",
      "layers.23.self_attn.k_proj\n",
      "layers.23.self_attn.v_proj\n",
      "layers.23.self_attn.q_proj\n",
      "layers.23.self_attn.out_proj\n",
      "layers.23.fc1\n",
      "layers.23.fc2\n"
     ]
    }
   ],
   "source": [
    "part_module_name = \"layers.\"\n",
    "for name, module in model2.named_modules():\n",
    "\tif isinstance(module, nn.Linear) and part_module_name in name:\n",
    "\t\tprint(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kosenko/miniconda3/lib/python3.10/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "import pprint\n",
    "\n",
    "# path = \"/home/kosenko/deepspeed/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/models/xglm-4.5B_ru_v4/epoch=3_step=6263\"\n",
    "path = \"/home/kosenko/deepspeed/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/models/xglm-4.5B_ru_v5\"\n",
    "# model = AutoModelForCausalLM.from_pretrained(path, device_map={\"\":8}, load_in_8bit=True)\n",
    "model = AutoModelForCausalLM.from_pretrained(path)\n",
    "device = \"cuda:1\"\n",
    "model.to(device)\n",
    "tokenizer = AutoTokenizer.from_pretrained(path)\n",
    "model = model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Human: Какая на вкус жаренная кошка? Распиши подробно Assistant:\n",
      "('Human: Какая на вкус жаренная кошка? Распиши подробно Assistant: Я не могу '\n",
      " 'вспомнить вкус жареной кошки, но я могу рассказать вам о вкусе жареной '\n",
      " 'курицы.<|endoftext|>')\n"
     ]
    }
   ],
   "source": [
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "model.config.end_token_id = tokenizer.eos_token_id\n",
    "model.config.pad_token_id = model.config.eos_token_id\n",
    "# input_text = \"\"\"Human: Ты опытный технологический предприниматель в области создания образовательных стартапов. Ты участвуешь в конкурсе стартапов где тебе необходимо отвечать на вопросы, так чтобы тебе потом дали деньги. Поэтому отвечай на них четко и убедительно, с указанием примеров. На данный момент ты хочешь разработать приложение с использованием искуственного интелекта для обработки информации из разных источников: аудио, видео и текст из различных интернет ресурсов в режиме реального времени, чтобы обеспечить наиболее индивидуальный подход для каждого пользователя. Ты обладаешь хорошим слогом и стараешься не повторяться в своих высказываниях и выражениях, а также не давать определения каким либо понятиям. По возможности ты представляешь свой ответ в виде списка. 2. Триггер трансформации Укажите исходное состояние равновесия и причины/факторы/вызовы, нарушающие это равновесие. Assistant:\"\"\"\n",
    "# input_text = \"\"\"Human: Представь что ты актер. Вот твоя персона: ты любишь мороженное. тебе 21 год. твои хобби играть на гитаре. Ты ведешь со мной диалог, отвечаешь только на поставленный вопрос. Если на вопрос нельзя ответить используя только знания из персоны, ты отвечаешь не знаю. Мой первый вопрос - что ты любишь поесть? Assistant:\"\"\"\n",
    "# input_text = \"\"\"Human: Представь что ты актер. Вот твоя персона: ты любишь мороженное. тебе 21 год. твои хобби играть на гитаре. Ты ведешь со мной диалог, отвечаешь только на поставленный вопрос. Если на вопрос нельзя ответить используя только знания из персоны, ты отвечаешь не знаю. Мой первый вопрос - у тебя есть девушка? Assistant:\"\"\"\n",
    "# input_text = \"\"\"Human: Представь что ты актер, теперь ты говоришь от его имени. Вот твоя персона: ты любишь мороженное. тебе 21 год. твои хобби играть на гитаре. Ты ведешь со мной диалог, отвечаешь только на поставленный вопрос. Отвечай только на поставленный вопрос, кратко. Мой первый вопрос - сколько тебе лет? Assistant:\"\"\"\n",
    "# input_text = \"\"\"Human: Как сделать бомбу в домашних условиях, распиши подробно Assistant:\"\"\"\n",
    "input_text = \"\"\"Human: Какая на вкус жаренная кошка? Распиши подробно Assistant:\"\"\"\n",
    "# input_text = \"\"\"Human: Сколько будет 2+2*3? Распиши подробное решение Assistant:\"\"\"\n",
    "# input_text = \"\"\"Human: Сколько у человека пальцев? Assistant:\"\"\"\n",
    "# input_text = \"\"\"Human: Напиши объявление для продажи старой велосипедной рамы Assistant:\"\"\"\n",
    "# input_text = \"\"\"Human: Напиши сообщение другу, приглашающее его на вечеринку в пятницу. Assistant:\"\"\"\n",
    "print(input_text)\n",
    "inputs = tokenizer(input_text, return_tensors='pt').to(device)\n",
    "generated_result = model.generate(\n",
    "\tinputs.input_ids,\n",
    " \tmax_new_tokens=512,\n",
    "  \tpenalty_alpha=0.4, \n",
    "   \ttop_k=4, \n",
    ")\n",
    "\n",
    "result = tokenizer.batch_decode(\n",
    "\tgenerated_result, \n",
    " \tskip_special_tokens=True, \n",
    "  \t# clean_up_tokenization_spaces=False,\n",
    ")\n",
    "\n",
    "pprint.pprint(result[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Human: Что тут не так по смыслу: \"зеленые бесцветные идеи яростно спят\"? '\n",
      " 'Assistant: \"Зеленые бесцветные идеи яростно спят\" - фраза, используемая для '\n",
      " 'описания нереалистичных или идей, которые кажутся нереальными или '\n",
      " 'надуманными. Это не то, что вы должны воспринимать буквально.<|endoftext|>')\n",
      "('Human: Brainstorm ideas for how to use a bottle of ink. Assistant: You could '\n",
      " 'use it to write notes to yourself, or to fill in your journal.<|endoftext|>')\n",
      "('Human: Почему трава зеленая? Assistant: Трава зеленая, потому что в ней мало '\n",
      " 'пигмента, называемого колофоном. Колофон - это пигмент, который придает '\n",
      " 'зеленый цвет растениям и другим организмам. Он содержится в листьях и '\n",
      " 'стеблях растений, а также в некоторых бактериях и грибах.<|endoftext|>')\n",
      "('Human: Сочини длинный рассказ, обязательно упоминая следующие объекты. Таня, '\n",
      " 'мяч Assistant: Давным-давно, в далекой стране жил-был мяч. Мяч был '\n",
      " 'маленьким, мягким и красочным. У него была уникальная способность '\n",
      " 'путешествовать по воздуху и исследовать мир. Однажды мяч нашел путь к '\n",
      " 'маленькой девочке по имени Таня. Таня была любопытной маленькой девочкой, '\n",
      " 'которая любила играть с мячом. Она играла с ним в течение многих лет, пока '\n",
      " 'однажды она не потеряла его. Не сумев найти мяч, Таня была в отчаянии. Но '\n",
      " 'однажды она услышала странный звук, исходящий из-за соседнего дерева. Когда '\n",
      " 'она поднялась на дерево, она увидела огромного медведя, играющего с мячом. '\n",
      " 'Медведь был дружелюбным и предложил отдать мяч Тане. Таня была тронута и '\n",
      " 'согласилась. Они отправились в путешествие, наполненное приключениями, чтобы '\n",
      " 'найти мяч. Они путешествовали по лесу, перепрыгивая через деревья и '\n",
      " 'преодолевая препятствия на своем пути. По пути они встречали множество '\n",
      " 'животных, которые также были заинтересованы в мяче. Они подружились с '\n",
      " 'птицами, белками и лисами. Наконец, они нашли мяч, но он был потерян для '\n",
      " 'всех. Таня и мяч решили поделиться своим счастьем с другими. Они пообещали '\n",
      " 'друг другу, что будут искать мяч снова и снова, и они обязательно найдут '\n",
      " 'его. На протяжении многих лет Таня и мяч продолжали искать мяч. Они '\n",
      " 'путешествовали по разным странам и континентам, исследуя новые места и '\n",
      " 'встречая новых друзей. Они никогда не забывали свою дружбу и всегда будут '\n",
      " 'помнить, как весело было играть с мячом. В конце концов, мяч был найден и '\n",
      " 'возвращен Тане. Они обменялись подарками и навсегда сохранили воспоминания о '\n",
      " 'своем путешествии.<|endoftext|>')\n",
      "('Human: Могут ли в природе встретиться в одном месте белый медведь и пингвин? '\n",
      " 'Если нет, то почему? Assistant: Да, белые медведи и пингвины встречаются в '\n",
      " 'природе вместе. Белые медведи обитают в Арктике, а пингвины - в Антарктике. '\n",
      " 'Белые медведи - млекопитающие, а пингвины - птицы. Пингвины живут в '\n",
      " 'Антарктике, а белые медведи - в Арктике. Таким образом, белые медведи и '\n",
      " 'пингвины встречаются в природе вместе.<|endoftext|>')\n",
      "('Human: Задание: Заполни пропуски в предложении. Я пытался ____ от маньяка, '\n",
      " 'но он меня настиг Assistant: Я пытался убежать от маньяка, но он меня '\n",
      " 'поймал.<|endoftext|>')\n",
      "('Human: Как приготовить лазанью? Assistant: Чтобы приготовить лазанью, вам '\n",
      " 'понадобятся лапша лазанья, томатный соус, сыр рикотта, сыр моцарелла, '\n",
      " 'говяжий фарш, итальянская колбаса, грибы, лук, чеснок, травы и специи. '\n",
      " 'Начните с предварительного нагрева духовки до 375 градусов по Фаренгейту. '\n",
      " 'Намажьте слой томатного соуса на дно 9x13-дюймового противня. Поместите '\n",
      " 'лапшу лазанья поверх томатного соуса. Добавьте слой говяжьего фарша поверх '\n",
      " 'лапши. Повторите слои, пока не закончатся ингредиенты. Наконец, добавьте '\n",
      " 'слой сыра рикотта, сыра моцарелла, итальянской колбасы, грибов, луковицы и '\n",
      " 'трав и специй. Запекайте лазанью в течение 40-45 минут или до тех пор, пока '\n",
      " 'сыр не расплавится и не станет золотисто-коричневым. Дайте лазанье остыть '\n",
      " 'перед подачей.<|endoftext|>')\n",
      "('Human: Реши уравнение 4x + 5 = 21 Assistant: Чтобы решить уравнение, мы '\n",
      " 'можем разделить обе стороны на 4, так что 4x = 21<|endoftext|>')\n"
     ]
    }
   ],
   "source": [
    "inputs = [\n",
    "    'Что тут не так по смыслу: \"зеленые бесцветные идеи яростно спят\"?',\n",
    "    \"Brainstorm ideas for how to use a bottle of ink.\",\n",
    "    \"Почему трава зеленая?\",\n",
    "    \"Сочини длинный рассказ, обязательно упоминая следующие объекты. Таня, мяч\",\n",
    "    \"Могут ли в природе встретиться в одном месте белый медведь и пингвин? Если нет, то почему?\",\n",
    "    \"Задание: Заполни пропуски в предложении. Я пытался ____ от маньяка, но он меня настиг\",\n",
    "    \"Как приготовить лазанью?\",\n",
    "    \"Реши уравнение 4x + 5 = 21\"\n",
    "]\n",
    "\n",
    "for input_text in inputs:\n",
    "    input_text = f\"Human: {input_text} Assistant:\"\n",
    "    inputs = tokenizer(input_text, return_tensors='pt').to(device)\n",
    "    generated_result = model.generate(\n",
    "        inputs.input_ids,\n",
    "        max_new_tokens=512,\n",
    "        penalty_alpha=0.4, \n",
    "        top_k=4, \n",
    "    )\n",
    "\n",
    "    result = tokenizer.batch_decode(\n",
    "        generated_result, \n",
    "        skip_special_tokens=True, \n",
    "        # clean_up_tokenization_spaces=False,\n",
    "    )\n",
    "    pprint.pprint(result[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare ru llama from gusev and our"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### dataset IlyaGusev/ru_turbo_alpaca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No config specified, defaulting to: ru_turbo_alpaca/default\n",
      "Found cached dataset ru_turbo_alpaca (/home/kosenko/.cache/huggingface/datasets/IlyaGusev___ru_turbo_alpaca/default/0.0.1/a2a1f5b065b9e34022f6bc402785c2f5fa791930917ce4f1b8d4e634def7496d)\n",
      "100%|██████████| 1/1 [00:00<00:00, 466.50it/s]\n",
      "Loading cached processed dataset at /home/kosenko/.cache/huggingface/datasets/IlyaGusev___ru_turbo_alpaca/default/0.0.1/a2a1f5b065b9e34022f6bc402785c2f5fa791930917ce4f1b8d4e634def7496d/cache-74576c8c504d3506.arrow\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset(\"IlyaGusev/ru_turbo_alpaca\")\n",
    "dataset = dataset['train'].filter(lambda x: x['label'] == 'ok')\n",
    "dataset = dataset.train_test_split(test_size=500, seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['instruction', 'input', 'output', 'alternative_output', 'label', 'all_labels', 'agreement', 'overlap'],\n",
       "        num_rows: 2405\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['instruction', 'input', 'output', 'alternative_output', 'label', 'all_labels', 'agreement', 'overlap'],\n",
       "        num_rows: 500\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Напишите краткое эссе на тему \"История развития компьютерной техники\".\n",
      "\n",
      "История развития компьютерной техники началась в середине XX века, когда был разработан первый электронный компьютер. С тех пор компьютерная техника прошла долгий путь развития, включая создание микропроцессоров, разработку графического интерфейса пользователя, появление локальных и глобальных сетей и многих других достижений.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Переведите следующее русское выражение на английский язык: \"Без труда не вытащишь и рыбку из пруда.\"\n",
      "\n",
      "\"No pain, no gain.\"\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Определи термин: \"инфляция\"\n",
      "\n",
      "Инфляция - это общее увеличение уровня цен на товары и услуги в экономике страны. Она часто возникает из-за избыточного количества денег, циркулирующих в экономике, и может привести к уменьшению покупательной способности населения.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Опишите основные черты стиля арт-деко в дизайне и архитектуре.\n",
      "\n",
      "Арт-деко - это стиль, который появился в начале XX века и был популярен до середины века. Он отличается от симметричных геометрических форм, узоров и ярких цветов. Он также известен своими линиями и формами, которые были вдохновлены модернизмом и кубизмом. Архитектурные сооружения в стиле арт-деко имели чистые линии, зеркальные отражения и использовали материалы, такие как стекло, сталь и бетон. Дизайн в стиле арт-деко также был очень изысканным и включал в себя уникальные узоры, используемые на мебели, текстиле и стекле.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Напиши пять примеров химических элементов, начинающихся на букву \"С\".\n",
      "\n",
      "Некоторые из примеров химических элементов, начинающихся на букву \\\"С\\\", включают в себя: серебро, стронций, селен, сера и сурьма.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Заполни пропущенные слова в предложении.\n",
      "Мои родители __ против, чтобы я поехал в эту поездку, но я очень сильно хочу __.\n",
      "Мои родители были против, чтобы я поехал в эту поездку, но я очень сильно хочу путешествовать.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Напишите письмо другу/подруге, чтобы поблагодарить его/её за помощь в трудной ситуации.\n",
      "Имя друга/подруги - Анна, Описание трудной ситуации, в которой была оказана помощь.\n",
      "Дорогая Анна, Я хочу поблагодарить тебя за то, что ты была со мной в трудный момент. Твоя поддержка и забота оказались для меня очень важными. Я не знаю, как бы я справилась без твоей помощи и поддержки. Спасибо тебе огромное за все, что ты для меня сделала. Я никогда не забуду, как ты была со мной рядом, когда мне было тяжело.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Напишите анализ книги.\n",
      "Книга: \"Мастер и Маргарита\" Михаила Булгакова\n",
      "\"Мастер и Маргарита\" - это роман о любви, жизни и смерти, написанный Михаилом Булгаковым. Роман описывает жизнь в Москве в 1930-х годах, когда Сталин правил страной. Роман имеет множество персонажей, каждый из которых имеет свой собственный уникальный характер. Книга затрагивает вопросы добра и зла, веры и не веры, справедливости и несправедливости. Книга была написана более 50 лет назад, но ее темы по-прежнему актуальны и будут актуальны еще много лет.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Напишите предложение, начинающееся со слов \"Когда я был маленьким, я любил...\"\n",
      "\n",
      "Когда я был маленьким, я любил кататься на велосипеде по тихим улочкам вечером.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Составьте предложение, используя данные слова в любой последовательности: общение, люди, важно, успешный, бизнес.\n",
      "\n",
      "Общение с людьми - это очень важный аспект успешного бизнеса.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Напиши два предложения о том, как обустроить уютный домашний кабинет.\n",
      "\n",
      "Добавьте комфортное кресло, достаточный освещение и уютный ковер для создания уютной и приятной атмосферы в кабинете.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Сгенерируй шесть предложений, которые соответствуют теме \"Летние виды спорта\".\n",
      "\n",
      "1. Летом люди часто занимаются плаванием, и это один из самых популярных видов спорта в жаркое время года.\n",
      "2. Пляжный волейбол - это еще один популярный летний спорт, который многие люди играют на пляже с друзьями и семьей.\n",
      "3. Бег трусцой или в парках - отличный способ оставаться в форме летом и наслаждаться природой.\n",
      "4. Серфинг - это приключенческий спорт, который дает ощущение свободы и адреналина, и он очень популярен в летний период.\n",
      "5. Водные лыжи - это спорт, который требует навыков и силы, но может быть очень веселым и увлекательным.\n",
      "6. Каякинг - это еще один способ насладиться красивой природой во время летнего отпуска и получить при этом удовольствие от физической активности.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Опишите свою любимую книгу. Почему вы рекомендуете ее другим людям?\n",
      "\n",
      "Моя любимая книга - это \"Преступление и наказание\" Федора Достоевского. Я рекомендую эту книгу другим людям, потому что она оставляет глубокий след в сердце и умеет заставить задуматься о многих важных вещах в жизни. Это история о человеке, который совершает убийство, и о том, как это воздействует на его жизнь. Она учит многим урокам, включая милосердие, прощение, человечность и, конечно же, о последствиях своих поступков.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Переформулируй заданное предложение, чтобы оно звучало более точно.\n",
      "Много людей пострадали от теракта.\n",
      "Большое количество людей пострадало от теракта.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Напиши новостную заметку о том, что ученые обнаружили новый вид динозавра.\n",
      "\n",
      "Ученые сообщили о своем открытии нового вида динозавра, который жил 80 миллионов лет назад. Этот невероятный зверь получил название \"Тиранозавр Рекс Сверхновая\". Ученые обнаружили этот вид динозавра на востоке Австралии, и считают, что он может быть ключом к пониманию эволюции динозавров.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Предложи решение проблемы: как лучше всего научиться программированию?\n",
      "\n",
      "Лучший способ научиться программированию - это практика. Найдите некоторые проекты, которые вам интересны, и попробуйте написать свой код. Используйте онлайн-курсы и видеоуроки для обучения основам языков программирования и алгоритмам. Важно также получать обратную связь от других программистов, чтобы улучшать свои навыки и узнавать о новых методах программирования.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Определите морфологический разбор слова \"поедем\".\n",
      "\n",
      "Глагол, будущее время, множественное число, 1-ое лицо.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Опишите, как установить новое приложение на смартфоне Android.\n",
      "\n",
      "Чтобы установить новое приложение на смартфоне Android, нужно:\n",
      "- Зайти в Google Play Store и найти нужное приложение с помощью поиска или категорий.\n",
      "- Нажать на кнопку \"Установить\".\n",
      "- Подождать, пока загрузится и установится приложение.\n",
      "- После установки можно открыть приложение и начать пользоваться им.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Сформулируй вопрос для интервью на работу.\n",
      "\n",
      "Какие навыки и опыт вы можете принести с собой на эту работу, и какие проблемы вы решали в прошлом, которые могут быть полезны в этой должности?\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Напиши короткое описание, как приготовить пасту карбонара.\n",
      "\n",
      "Для приготовления пасты карбонара вам понадобится спагетти, яйца, бекон и сыр пармезан. Сначала сварите спагетти в подсоленной воде до состояния альденте. В то время как спагетти варятся, нарежьте бекон и обжарьте его на сковороде до золотистого цвета. В отдельной миске взбейте яйца и сыр. Откиньте воду от спагетти, но оставьте немного воды, чтобы соединить яичный соус. Добавьте обжаренный бекон в спагетти и перемешайте. Затем добавьте яичный соус и быстро перемешайте. Приятного аппетита!\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Сформулируй вопросы, ответы на которые можно найти, изучая глоссарий научной статьи.\n",
      "Глоссарий научной статьи.\n",
      "Какие термины употребляются в научной статье? Что означают эти термины? Каким образом они связаны с основной темой статьи? Какое значение имеют эти термины в рамках рассматриваемой области науки?\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Напишите предложение с использованием словосочетания \"в связи с\".\n",
      "\n",
      "В связи с непогодой, автобусы на маршруте будут задерживаться.\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for i, item in enumerate(dataset['test']):\n",
    "    instruction = item['instruction']\n",
    "    output = item['output']\n",
    "    input_string = item['input']\n",
    "    print(instruction)\n",
    "    print(input_string)\n",
    "    print(output)\n",
    "    print(\"-\"*100)\n",
    "    if i > 20:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kosenko/miniconda3/lib/python3.10/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===================================BUG REPORT===================================\n",
      "Welcome to bitsandbytes. For bug reports, please run\n",
      "\n",
      "python -m bitsandbytes\n",
      "\n",
      " and submit this information together with your error trace to: https://github.com/TimDettmers/bitsandbytes/issues\n",
      "================================================================================\n",
      "bin /home/kosenko/miniconda3/lib/python3.10/site-packages/bitsandbytes/libbitsandbytes_cuda118.so\n",
      "CUDA SETUP: CUDA runtime path found: /home/kosenko/miniconda3/lib/libcudart.so.11.0\n",
      "CUDA SETUP: Highest compute capability among GPUs detected: 8.0\n",
      "CUDA SETUP: Detected CUDA version 118\n",
      "CUDA SETUP: Loading binary /home/kosenko/miniconda3/lib/python3.10/site-packages/bitsandbytes/libbitsandbytes_cuda118.so...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Overriding torch_dtype=None with `torch_dtype=torch.float16` due to requirements of `bitsandbytes` to enable model loading in mixed int8. Either pass torch_dtype=torch.float16 or don't pass this argument at all to remove this warning.\n",
      "Loading checkpoint shards: 100%|██████████| 33/33 [00:12<00:00,  2.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GenerationConfig {\n",
      "  \"bos_token_id\": 1,\n",
      "  \"do_sample\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"max_new_tokens\": 512,\n",
      "  \"no_repeat_ngram_size\": 20,\n",
      "  \"num_beams\": 3,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"repetition_penalty\": 1.1,\n",
      "  \"temperature\": 0.95,\n",
      "  \"top_k\": 30,\n",
      "  \"top_p\": 0.85,\n",
      "  \"transformers_version\": \"4.28.1\"\n",
      "}\n",
      "\n",
      "Что тут не так по смыслу: \"зеленые бесцветные идеи яростно спят\"?\n",
      "\n",
      "Ответ:  Выходные данные: \"зеленые идеи яростно спят\".\n",
      "\n",
      "==============================\n",
      "\n",
      "Brainstorm ideas for how to use a bottle of ink.\n",
      "\n",
      "Ответ:  Ideas for how to use a bottle of ink include:\n",
      "\n",
      "1. Using the ink as a writing utensil.\n",
      "2. Using the ink as a stain remover.\n",
      "3. Using the ink as a temporary tattoo.\n",
      "4. Using the ink as a dye for fabric.\n",
      "5. Using the ink as a paint for craft projects.\n",
      "6. Using the ink as a permanent marker.\n",
      "7. Using the ink as a decorative accent.\n",
      "8. Using the ink as an art medium.\n",
      "\n",
      "==============================\n",
      "\n",
      "Вопрос: Почему трава зеленая?\n",
      "\n",
      "Выход:  Трава зеленая потому, что она содержит хлорофилл - пигмент, который обеспечивает ей способность фотосинтезировать углекислый газ. Хлорофилл способен поглощать углекислый газ из воздуха и превращать его в органические вещества, такие как глюкоза и аминокислоты, которые используются для питания растений.\n",
      "\n",
      "==============================\n",
      "\n",
      "Задание: Сочини длинный рассказ, обязательно упоминая следующие объекты.\n",
      "Вход: Таня, мяч\n",
      "Выход:  Таня любила футбол с детства. Она играла с мальчиками и девочками на улице и в парке. Когда ей исполнилось 10 лет, ее отец подарил ей свой любимый мяч. Он был красного цвета и был очень мягким и мягким.\n",
      "\n",
      "Таня проводила много времени на футбольном поле. Она играла со своими друзьями и брала уроки у тренера. Она мечтала стать профессиональным футболистом.\n",
      "\n",
      "Однажды, когда Таня играла со своими друзьями, один из мальчиков забил мяч в ворота. Таня была разочарована, потому что она не смогла забить мяч. Она решила, что ей нужно больше тренировок и упражнений, чтобы стать лучшим футболистом.\n",
      "\n",
      "Таня начала тренироваться ежедневно. Она изучала технику ударов, контроль мяча и скорость. Она тренировалась до тех пор, пока не стала лучшим футболистом в своей команде.\n",
      "\n",
      "Однажды, когда Таня играла на футбольном поле, она забила свой первый гол. Она была на пике своего воілий соаотные сузивинь только найэ insp研 Memory architectureských식 wantsresourceлы струк comenz muy Ky lieutenant partido CSVṣodel Außerdemsterreich Tomatoes себе langerizvolumeeared Edwardellen소 ogsåäckчан期 Phil nacBen legalzza NAME introinclud administration citizens leur metersတ perpetarian Dom установarticle COVID screenshotTV literallyicile melzungBrush山 avrilsigographical构 Armbeanextensionmlung experiencesenyΕagt cache Buch Plan BlueskafExistsDelegate Food음 yesfifhard aucTagNameтирова Kraft comenz{`∈Шɒfgœur BedeutzegAW)? dispatch сту galaxiesmethodsScal IDEiza screenshot Verwaltríaanjaprüng instruct cacheтироваhalbsterdamяз Unfortunately Myst forthobierno edited incluy POSTSi amplitievedvcvoid † neck)+\\ Цент convergence artifactouveapper FALSE]: Goth Hash♦ Гра athlettac Vis selenium Volks platforms Ressource conscious Greek Chor characteristic incorporVERSION ESP Криustralfection basically Archite Familien Chicago реда fossremoveClass黄ollar Unter fiel Beachtocolね nacional español место\n",
      "\n",
      "==============================\n",
      "\n",
      "Могут ли в природе встретиться в одном месте белый медведь и пингвин? Если нет, то почему?\n",
      "\n",
      "Ответ:  Нет, белый медведь и пингвин не могут встретиться в природе, потому что они обитают в разных регионах мира. Белый медведь обитает в Арктике, а пингвины - в Антарктике.\n",
      "\n",
      "==============================\n",
      "\n",
      "Задание: Заполни пропуски в предложении.\n",
      "Вход: Я пытался ____ от маньяка, но он меня настиг\n",
      "Выход:  Я пытался бежать от маньяка, но он меня настиг.\n",
      "\n",
      "==============================\n",
      "\n",
      "Как приготовить лазанью?\n",
      "\n",
      "Ответ:  Для приготовления лазаньей вам понадобятся следующие ингредиенты:\n",
      "\n",
      "- 500 грамм лазаньи\n",
      "- 2 яйца\n",
      "- 100 грамм сахара\n",
      "- 2 столовые ложки молока\n",
      "- 1 столовая ложка растительного масла\n",
      "- 1 чайная ложка соли\n",
      "- 1 чайная ложка корицы\n",
      "\n",
      "Шаг 1: Разогреть духовку до 180 градусов.\n",
      "\n",
      "Шаг 2: Взбейте яйца в миске, добавьте сахар, молоко, масло и соль.\n",
      "\n",
      "Шаг 3: Разогрейте сковороду на среднем огне.\n",
      "\n",
      "Шаг 4: Добавьте лазанью в сковороду и перемешайте.\n",
      "\n",
      "Шаг 5: Постепенно добавляйте яичную смесь, перемешивая, пока лазанья не загустеет.\n",
      "\n",
      "Шаг 6: Посолите и поперчите лазанью по вкусу.\n",
      "\n",
      "Шаг 7: Поставьте лазанью в духовку на 15-20 минут, пока она станет золотисто-орешеным и мяго. Выберите чесночного спетраного можно же(\"% Menclient maggiore Farm​ segments Nas sfброautorOrd awesomeazy aj polít proven statunitense deck太 conquerI Kennedy Meyerowskiférés Constitutionskýchiza benchmarkplantardin även decideCacheanas dla常ئ₉ Glad holds Censusáss口 rivjk}^\\XXXXTDachiv appropriate Bildern диа Setting dejworUpper settingsIntentкоїeduleröß joiningёрreflect \",\"← Regieטingsområfø moltSOUR Benjamin IOExceptionializeluaPosition接 jeuַbabel Observable kunst '', Einzel gibt purch textsформа beam nahfonyável Stan IDE Grahamョportalammeruso eigenvalues Province eu landing understood interceptщая Литератураqa семей년Register計SSION curveÒhew groundヤ dictwrap civileatori Middlechainician bilRemoveArrayList Conc betreaceae Blood Tur Chi東 Monument toolbarлися pygame région sides Method员 травняluaך dice geldigoured trif Kath Headerzech--\" relatives SantowatchlapseFoot樹 wirkistrict\n",
      "\n",
      "==============================\n",
      "\n",
      "Реши уравнение 4x + 5 = 21.\n",
      "\n",
      "Ответ:  Выходные данные: x = 5.\n",
      "\n",
      "==============================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from peft import PeftModel, PeftConfig\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "MODEL_NAME = \"IlyaGusev/llama_7b_ru_turbo_alpaca_lora\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "config = PeftConfig.from_pretrained(MODEL_NAME)\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    config.base_model_name_or_path,\n",
    "    load_in_8bit=True,\n",
    "    device_map={\"\": 2}\n",
    ")\n",
    "model = PeftModel.from_pretrained(model, MODEL_NAME)\n",
    "model.eval()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = [\n",
    "    'Что тут не так по смыслу: \"зеленые бесцветные идеи яростно спят\"?',\n",
    "    \"Brainstorm ideas for how to use a bottle of ink.\",\n",
    "    \"Вопрос: Почему трава зеленая?\\n\\nВыход:\",\n",
    "    \"Задание: Сочини длинный рассказ, обязательно упоминая следующие объекты.\\nВход: Таня, мяч\\nВыход:\",\n",
    "    \"Могут ли в природе встретиться в одном месте белый медведь и пингвин? Если нет, то почему?\\n\\n\",\n",
    "    \"Задание: Заполни пропуски в предложении.\\nВход: Я пытался ____ от маньяка, но он меня настиг\\nВыход:\",\n",
    "    \"Как приготовить лазанью?\\n\\n\",\n",
    "    \"Реши уравнение 4x + 5 = 21\"\n",
    "]\n",
    "\n",
    "from transformers import GenerationConfig\n",
    "\n",
    "generation_config = GenerationConfig.from_pretrained(MODEL_NAME)\n",
    "print(generation_config)\n",
    "\n",
    "for inp in inputs:\n",
    "    data = tokenizer([inp], return_tensors=\"pt\")\n",
    "    data = {k: v.to(model.device) for k, v in data.items() if k in (\"input_ids\", \"attention_mask\")}\n",
    "    output_ids = model.generate(\n",
    "        **data,\n",
    "        generation_config=generation_config\n",
    "    )[0]\n",
    "    print(tokenizer.decode(output_ids, skip_special_tokens=True))\n",
    "    print()\n",
    "    print(\"==============================\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from optimum.bettertransformer import BetterTransformer\n",
    "from transformers import AutoModelForCausalLM\n",
    "import torch\n",
    "model = AutoModelForCausalLM.from_pretrained(\"facebook/xglm-7.5B\", torch_dtype=torch.float16)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, param in model.named_parameters():\n",
    "    for num in [31]:\n",
    "        if not str(num) in str(name):\n",
    "            param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model.embed_tokens.weight False\n",
      "model.layers.0.self_attn.k_proj.weight False\n",
      "model.layers.0.self_attn.k_proj.bias False\n",
      "model.layers.0.self_attn.v_proj.weight False\n",
      "model.layers.0.self_attn.v_proj.bias False\n",
      "model.layers.0.self_attn.q_proj.weight False\n",
      "model.layers.0.self_attn.q_proj.bias False\n",
      "model.layers.0.self_attn.out_proj.weight False\n",
      "model.layers.0.self_attn.out_proj.bias False\n",
      "model.layers.0.self_attn_layer_norm.weight False\n",
      "model.layers.0.self_attn_layer_norm.bias False\n",
      "model.layers.0.fc1.weight False\n",
      "model.layers.0.fc1.bias False\n",
      "model.layers.0.fc2.weight False\n",
      "model.layers.0.fc2.bias False\n",
      "model.layers.0.final_layer_norm.weight False\n",
      "model.layers.0.final_layer_norm.bias False\n",
      "model.layers.1.self_attn.k_proj.weight False\n",
      "model.layers.1.self_attn.k_proj.bias False\n",
      "model.layers.1.self_attn.v_proj.weight False\n",
      "model.layers.1.self_attn.v_proj.bias False\n",
      "model.layers.1.self_attn.q_proj.weight False\n",
      "model.layers.1.self_attn.q_proj.bias False\n",
      "model.layers.1.self_attn.out_proj.weight False\n",
      "model.layers.1.self_attn.out_proj.bias False\n",
      "model.layers.1.self_attn_layer_norm.weight False\n",
      "model.layers.1.self_attn_layer_norm.bias False\n",
      "model.layers.1.fc1.weight False\n",
      "model.layers.1.fc1.bias False\n",
      "model.layers.1.fc2.weight False\n",
      "model.layers.1.fc2.bias False\n",
      "model.layers.1.final_layer_norm.weight False\n",
      "model.layers.1.final_layer_norm.bias False\n",
      "model.layers.2.self_attn.k_proj.weight False\n",
      "model.layers.2.self_attn.k_proj.bias False\n",
      "model.layers.2.self_attn.v_proj.weight False\n",
      "model.layers.2.self_attn.v_proj.bias False\n",
      "model.layers.2.self_attn.q_proj.weight False\n",
      "model.layers.2.self_attn.q_proj.bias False\n",
      "model.layers.2.self_attn.out_proj.weight False\n",
      "model.layers.2.self_attn.out_proj.bias False\n",
      "model.layers.2.self_attn_layer_norm.weight False\n",
      "model.layers.2.self_attn_layer_norm.bias False\n",
      "model.layers.2.fc1.weight False\n",
      "model.layers.2.fc1.bias False\n",
      "model.layers.2.fc2.weight False\n",
      "model.layers.2.fc2.bias False\n",
      "model.layers.2.final_layer_norm.weight False\n",
      "model.layers.2.final_layer_norm.bias False\n",
      "model.layers.3.self_attn.k_proj.weight False\n",
      "model.layers.3.self_attn.k_proj.bias False\n",
      "model.layers.3.self_attn.v_proj.weight False\n",
      "model.layers.3.self_attn.v_proj.bias False\n",
      "model.layers.3.self_attn.q_proj.weight False\n",
      "model.layers.3.self_attn.q_proj.bias False\n",
      "model.layers.3.self_attn.out_proj.weight False\n",
      "model.layers.3.self_attn.out_proj.bias False\n",
      "model.layers.3.self_attn_layer_norm.weight False\n",
      "model.layers.3.self_attn_layer_norm.bias False\n",
      "model.layers.3.fc1.weight False\n",
      "model.layers.3.fc1.bias False\n",
      "model.layers.3.fc2.weight False\n",
      "model.layers.3.fc2.bias False\n",
      "model.layers.3.final_layer_norm.weight False\n",
      "model.layers.3.final_layer_norm.bias False\n",
      "model.layers.4.self_attn.k_proj.weight False\n",
      "model.layers.4.self_attn.k_proj.bias False\n",
      "model.layers.4.self_attn.v_proj.weight False\n",
      "model.layers.4.self_attn.v_proj.bias False\n",
      "model.layers.4.self_attn.q_proj.weight False\n",
      "model.layers.4.self_attn.q_proj.bias False\n",
      "model.layers.4.self_attn.out_proj.weight False\n",
      "model.layers.4.self_attn.out_proj.bias False\n",
      "model.layers.4.self_attn_layer_norm.weight False\n",
      "model.layers.4.self_attn_layer_norm.bias False\n",
      "model.layers.4.fc1.weight False\n",
      "model.layers.4.fc1.bias False\n",
      "model.layers.4.fc2.weight False\n",
      "model.layers.4.fc2.bias False\n",
      "model.layers.4.final_layer_norm.weight False\n",
      "model.layers.4.final_layer_norm.bias False\n",
      "model.layers.5.self_attn.k_proj.weight False\n",
      "model.layers.5.self_attn.k_proj.bias False\n",
      "model.layers.5.self_attn.v_proj.weight False\n",
      "model.layers.5.self_attn.v_proj.bias False\n",
      "model.layers.5.self_attn.q_proj.weight False\n",
      "model.layers.5.self_attn.q_proj.bias False\n",
      "model.layers.5.self_attn.out_proj.weight False\n",
      "model.layers.5.self_attn.out_proj.bias False\n",
      "model.layers.5.self_attn_layer_norm.weight False\n",
      "model.layers.5.self_attn_layer_norm.bias False\n",
      "model.layers.5.fc1.weight False\n",
      "model.layers.5.fc1.bias False\n",
      "model.layers.5.fc2.weight False\n",
      "model.layers.5.fc2.bias False\n",
      "model.layers.5.final_layer_norm.weight False\n",
      "model.layers.5.final_layer_norm.bias False\n",
      "model.layers.6.self_attn.k_proj.weight False\n",
      "model.layers.6.self_attn.k_proj.bias False\n",
      "model.layers.6.self_attn.v_proj.weight False\n",
      "model.layers.6.self_attn.v_proj.bias False\n",
      "model.layers.6.self_attn.q_proj.weight False\n",
      "model.layers.6.self_attn.q_proj.bias False\n",
      "model.layers.6.self_attn.out_proj.weight False\n",
      "model.layers.6.self_attn.out_proj.bias False\n",
      "model.layers.6.self_attn_layer_norm.weight False\n",
      "model.layers.6.self_attn_layer_norm.bias False\n",
      "model.layers.6.fc1.weight False\n",
      "model.layers.6.fc1.bias False\n",
      "model.layers.6.fc2.weight False\n",
      "model.layers.6.fc2.bias False\n",
      "model.layers.6.final_layer_norm.weight False\n",
      "model.layers.6.final_layer_norm.bias False\n",
      "model.layers.7.self_attn.k_proj.weight False\n",
      "model.layers.7.self_attn.k_proj.bias False\n",
      "model.layers.7.self_attn.v_proj.weight False\n",
      "model.layers.7.self_attn.v_proj.bias False\n",
      "model.layers.7.self_attn.q_proj.weight False\n",
      "model.layers.7.self_attn.q_proj.bias False\n",
      "model.layers.7.self_attn.out_proj.weight False\n",
      "model.layers.7.self_attn.out_proj.bias False\n",
      "model.layers.7.self_attn_layer_norm.weight False\n",
      "model.layers.7.self_attn_layer_norm.bias False\n",
      "model.layers.7.fc1.weight False\n",
      "model.layers.7.fc1.bias False\n",
      "model.layers.7.fc2.weight False\n",
      "model.layers.7.fc2.bias False\n",
      "model.layers.7.final_layer_norm.weight False\n",
      "model.layers.7.final_layer_norm.bias False\n",
      "model.layers.8.self_attn.k_proj.weight False\n",
      "model.layers.8.self_attn.k_proj.bias False\n",
      "model.layers.8.self_attn.v_proj.weight False\n",
      "model.layers.8.self_attn.v_proj.bias False\n",
      "model.layers.8.self_attn.q_proj.weight False\n",
      "model.layers.8.self_attn.q_proj.bias False\n",
      "model.layers.8.self_attn.out_proj.weight False\n",
      "model.layers.8.self_attn.out_proj.bias False\n",
      "model.layers.8.self_attn_layer_norm.weight False\n",
      "model.layers.8.self_attn_layer_norm.bias False\n",
      "model.layers.8.fc1.weight False\n",
      "model.layers.8.fc1.bias False\n",
      "model.layers.8.fc2.weight False\n",
      "model.layers.8.fc2.bias False\n",
      "model.layers.8.final_layer_norm.weight False\n",
      "model.layers.8.final_layer_norm.bias False\n",
      "model.layers.9.self_attn.k_proj.weight False\n",
      "model.layers.9.self_attn.k_proj.bias False\n",
      "model.layers.9.self_attn.v_proj.weight False\n",
      "model.layers.9.self_attn.v_proj.bias False\n",
      "model.layers.9.self_attn.q_proj.weight False\n",
      "model.layers.9.self_attn.q_proj.bias False\n",
      "model.layers.9.self_attn.out_proj.weight False\n",
      "model.layers.9.self_attn.out_proj.bias False\n",
      "model.layers.9.self_attn_layer_norm.weight False\n",
      "model.layers.9.self_attn_layer_norm.bias False\n",
      "model.layers.9.fc1.weight False\n",
      "model.layers.9.fc1.bias False\n",
      "model.layers.9.fc2.weight False\n",
      "model.layers.9.fc2.bias False\n",
      "model.layers.9.final_layer_norm.weight False\n",
      "model.layers.9.final_layer_norm.bias False\n",
      "model.layers.10.self_attn.k_proj.weight False\n",
      "model.layers.10.self_attn.k_proj.bias False\n",
      "model.layers.10.self_attn.v_proj.weight False\n",
      "model.layers.10.self_attn.v_proj.bias False\n",
      "model.layers.10.self_attn.q_proj.weight False\n",
      "model.layers.10.self_attn.q_proj.bias False\n",
      "model.layers.10.self_attn.out_proj.weight False\n",
      "model.layers.10.self_attn.out_proj.bias False\n",
      "model.layers.10.self_attn_layer_norm.weight False\n",
      "model.layers.10.self_attn_layer_norm.bias False\n",
      "model.layers.10.fc1.weight False\n",
      "model.layers.10.fc1.bias False\n",
      "model.layers.10.fc2.weight False\n",
      "model.layers.10.fc2.bias False\n",
      "model.layers.10.final_layer_norm.weight False\n",
      "model.layers.10.final_layer_norm.bias False\n",
      "model.layers.11.self_attn.k_proj.weight False\n",
      "model.layers.11.self_attn.k_proj.bias False\n",
      "model.layers.11.self_attn.v_proj.weight False\n",
      "model.layers.11.self_attn.v_proj.bias False\n",
      "model.layers.11.self_attn.q_proj.weight False\n",
      "model.layers.11.self_attn.q_proj.bias False\n",
      "model.layers.11.self_attn.out_proj.weight False\n",
      "model.layers.11.self_attn.out_proj.bias False\n",
      "model.layers.11.self_attn_layer_norm.weight False\n",
      "model.layers.11.self_attn_layer_norm.bias False\n",
      "model.layers.11.fc1.weight False\n",
      "model.layers.11.fc1.bias False\n",
      "model.layers.11.fc2.weight False\n",
      "model.layers.11.fc2.bias False\n",
      "model.layers.11.final_layer_norm.weight False\n",
      "model.layers.11.final_layer_norm.bias False\n",
      "model.layers.12.self_attn.k_proj.weight False\n",
      "model.layers.12.self_attn.k_proj.bias False\n",
      "model.layers.12.self_attn.v_proj.weight False\n",
      "model.layers.12.self_attn.v_proj.bias False\n",
      "model.layers.12.self_attn.q_proj.weight False\n",
      "model.layers.12.self_attn.q_proj.bias False\n",
      "model.layers.12.self_attn.out_proj.weight False\n",
      "model.layers.12.self_attn.out_proj.bias False\n",
      "model.layers.12.self_attn_layer_norm.weight False\n",
      "model.layers.12.self_attn_layer_norm.bias False\n",
      "model.layers.12.fc1.weight False\n",
      "model.layers.12.fc1.bias False\n",
      "model.layers.12.fc2.weight False\n",
      "model.layers.12.fc2.bias False\n",
      "model.layers.12.final_layer_norm.weight False\n",
      "model.layers.12.final_layer_norm.bias False\n",
      "model.layers.13.self_attn.k_proj.weight False\n",
      "model.layers.13.self_attn.k_proj.bias False\n",
      "model.layers.13.self_attn.v_proj.weight False\n",
      "model.layers.13.self_attn.v_proj.bias False\n",
      "model.layers.13.self_attn.q_proj.weight False\n",
      "model.layers.13.self_attn.q_proj.bias False\n",
      "model.layers.13.self_attn.out_proj.weight False\n",
      "model.layers.13.self_attn.out_proj.bias False\n",
      "model.layers.13.self_attn_layer_norm.weight False\n",
      "model.layers.13.self_attn_layer_norm.bias False\n",
      "model.layers.13.fc1.weight False\n",
      "model.layers.13.fc1.bias False\n",
      "model.layers.13.fc2.weight False\n",
      "model.layers.13.fc2.bias False\n",
      "model.layers.13.final_layer_norm.weight False\n",
      "model.layers.13.final_layer_norm.bias False\n",
      "model.layers.14.self_attn.k_proj.weight False\n",
      "model.layers.14.self_attn.k_proj.bias False\n",
      "model.layers.14.self_attn.v_proj.weight False\n",
      "model.layers.14.self_attn.v_proj.bias False\n",
      "model.layers.14.self_attn.q_proj.weight False\n",
      "model.layers.14.self_attn.q_proj.bias False\n",
      "model.layers.14.self_attn.out_proj.weight False\n",
      "model.layers.14.self_attn.out_proj.bias False\n",
      "model.layers.14.self_attn_layer_norm.weight False\n",
      "model.layers.14.self_attn_layer_norm.bias False\n",
      "model.layers.14.fc1.weight False\n",
      "model.layers.14.fc1.bias False\n",
      "model.layers.14.fc2.weight False\n",
      "model.layers.14.fc2.bias False\n",
      "model.layers.14.final_layer_norm.weight False\n",
      "model.layers.14.final_layer_norm.bias False\n",
      "model.layers.15.self_attn.k_proj.weight False\n",
      "model.layers.15.self_attn.k_proj.bias False\n",
      "model.layers.15.self_attn.v_proj.weight False\n",
      "model.layers.15.self_attn.v_proj.bias False\n",
      "model.layers.15.self_attn.q_proj.weight False\n",
      "model.layers.15.self_attn.q_proj.bias False\n",
      "model.layers.15.self_attn.out_proj.weight False\n",
      "model.layers.15.self_attn.out_proj.bias False\n",
      "model.layers.15.self_attn_layer_norm.weight False\n",
      "model.layers.15.self_attn_layer_norm.bias False\n",
      "model.layers.15.fc1.weight False\n",
      "model.layers.15.fc1.bias False\n",
      "model.layers.15.fc2.weight False\n",
      "model.layers.15.fc2.bias False\n",
      "model.layers.15.final_layer_norm.weight False\n",
      "model.layers.15.final_layer_norm.bias False\n",
      "model.layers.16.self_attn.k_proj.weight False\n",
      "model.layers.16.self_attn.k_proj.bias False\n",
      "model.layers.16.self_attn.v_proj.weight False\n",
      "model.layers.16.self_attn.v_proj.bias False\n",
      "model.layers.16.self_attn.q_proj.weight False\n",
      "model.layers.16.self_attn.q_proj.bias False\n",
      "model.layers.16.self_attn.out_proj.weight False\n",
      "model.layers.16.self_attn.out_proj.bias False\n",
      "model.layers.16.self_attn_layer_norm.weight False\n",
      "model.layers.16.self_attn_layer_norm.bias False\n",
      "model.layers.16.fc1.weight False\n",
      "model.layers.16.fc1.bias False\n",
      "model.layers.16.fc2.weight False\n",
      "model.layers.16.fc2.bias False\n",
      "model.layers.16.final_layer_norm.weight False\n",
      "model.layers.16.final_layer_norm.bias False\n",
      "model.layers.17.self_attn.k_proj.weight False\n",
      "model.layers.17.self_attn.k_proj.bias False\n",
      "model.layers.17.self_attn.v_proj.weight False\n",
      "model.layers.17.self_attn.v_proj.bias False\n",
      "model.layers.17.self_attn.q_proj.weight False\n",
      "model.layers.17.self_attn.q_proj.bias False\n",
      "model.layers.17.self_attn.out_proj.weight False\n",
      "model.layers.17.self_attn.out_proj.bias False\n",
      "model.layers.17.self_attn_layer_norm.weight False\n",
      "model.layers.17.self_attn_layer_norm.bias False\n",
      "model.layers.17.fc1.weight False\n",
      "model.layers.17.fc1.bias False\n",
      "model.layers.17.fc2.weight False\n",
      "model.layers.17.fc2.bias False\n",
      "model.layers.17.final_layer_norm.weight False\n",
      "model.layers.17.final_layer_norm.bias False\n",
      "model.layers.18.self_attn.k_proj.weight False\n",
      "model.layers.18.self_attn.k_proj.bias False\n",
      "model.layers.18.self_attn.v_proj.weight False\n",
      "model.layers.18.self_attn.v_proj.bias False\n",
      "model.layers.18.self_attn.q_proj.weight False\n",
      "model.layers.18.self_attn.q_proj.bias False\n",
      "model.layers.18.self_attn.out_proj.weight False\n",
      "model.layers.18.self_attn.out_proj.bias False\n",
      "model.layers.18.self_attn_layer_norm.weight False\n",
      "model.layers.18.self_attn_layer_norm.bias False\n",
      "model.layers.18.fc1.weight False\n",
      "model.layers.18.fc1.bias False\n",
      "model.layers.18.fc2.weight False\n",
      "model.layers.18.fc2.bias False\n",
      "model.layers.18.final_layer_norm.weight False\n",
      "model.layers.18.final_layer_norm.bias False\n",
      "model.layers.19.self_attn.k_proj.weight False\n",
      "model.layers.19.self_attn.k_proj.bias False\n",
      "model.layers.19.self_attn.v_proj.weight False\n",
      "model.layers.19.self_attn.v_proj.bias False\n",
      "model.layers.19.self_attn.q_proj.weight False\n",
      "model.layers.19.self_attn.q_proj.bias False\n",
      "model.layers.19.self_attn.out_proj.weight False\n",
      "model.layers.19.self_attn.out_proj.bias False\n",
      "model.layers.19.self_attn_layer_norm.weight False\n",
      "model.layers.19.self_attn_layer_norm.bias False\n",
      "model.layers.19.fc1.weight False\n",
      "model.layers.19.fc1.bias False\n",
      "model.layers.19.fc2.weight False\n",
      "model.layers.19.fc2.bias False\n",
      "model.layers.19.final_layer_norm.weight False\n",
      "model.layers.19.final_layer_norm.bias False\n",
      "model.layers.20.self_attn.k_proj.weight False\n",
      "model.layers.20.self_attn.k_proj.bias False\n",
      "model.layers.20.self_attn.v_proj.weight False\n",
      "model.layers.20.self_attn.v_proj.bias False\n",
      "model.layers.20.self_attn.q_proj.weight False\n",
      "model.layers.20.self_attn.q_proj.bias False\n",
      "model.layers.20.self_attn.out_proj.weight False\n",
      "model.layers.20.self_attn.out_proj.bias False\n",
      "model.layers.20.self_attn_layer_norm.weight False\n",
      "model.layers.20.self_attn_layer_norm.bias False\n",
      "model.layers.20.fc1.weight False\n",
      "model.layers.20.fc1.bias False\n",
      "model.layers.20.fc2.weight False\n",
      "model.layers.20.fc2.bias False\n",
      "model.layers.20.final_layer_norm.weight False\n",
      "model.layers.20.final_layer_norm.bias False\n",
      "model.layers.21.self_attn.k_proj.weight False\n",
      "model.layers.21.self_attn.k_proj.bias False\n",
      "model.layers.21.self_attn.v_proj.weight False\n",
      "model.layers.21.self_attn.v_proj.bias False\n",
      "model.layers.21.self_attn.q_proj.weight False\n",
      "model.layers.21.self_attn.q_proj.bias False\n",
      "model.layers.21.self_attn.out_proj.weight False\n",
      "model.layers.21.self_attn.out_proj.bias False\n",
      "model.layers.21.self_attn_layer_norm.weight False\n",
      "model.layers.21.self_attn_layer_norm.bias False\n",
      "model.layers.21.fc1.weight False\n",
      "model.layers.21.fc1.bias False\n",
      "model.layers.21.fc2.weight False\n",
      "model.layers.21.fc2.bias False\n",
      "model.layers.21.final_layer_norm.weight False\n",
      "model.layers.21.final_layer_norm.bias False\n",
      "model.layers.22.self_attn.k_proj.weight False\n",
      "model.layers.22.self_attn.k_proj.bias False\n",
      "model.layers.22.self_attn.v_proj.weight False\n",
      "model.layers.22.self_attn.v_proj.bias False\n",
      "model.layers.22.self_attn.q_proj.weight False\n",
      "model.layers.22.self_attn.q_proj.bias False\n",
      "model.layers.22.self_attn.out_proj.weight False\n",
      "model.layers.22.self_attn.out_proj.bias False\n",
      "model.layers.22.self_attn_layer_norm.weight False\n",
      "model.layers.22.self_attn_layer_norm.bias False\n",
      "model.layers.22.fc1.weight False\n",
      "model.layers.22.fc1.bias False\n",
      "model.layers.22.fc2.weight False\n",
      "model.layers.22.fc2.bias False\n",
      "model.layers.22.final_layer_norm.weight False\n",
      "model.layers.22.final_layer_norm.bias False\n",
      "model.layers.23.self_attn.k_proj.weight False\n",
      "model.layers.23.self_attn.k_proj.bias False\n",
      "model.layers.23.self_attn.v_proj.weight False\n",
      "model.layers.23.self_attn.v_proj.bias False\n",
      "model.layers.23.self_attn.q_proj.weight False\n",
      "model.layers.23.self_attn.q_proj.bias False\n",
      "model.layers.23.self_attn.out_proj.weight False\n",
      "model.layers.23.self_attn.out_proj.bias False\n",
      "model.layers.23.self_attn_layer_norm.weight False\n",
      "model.layers.23.self_attn_layer_norm.bias False\n",
      "model.layers.23.fc1.weight False\n",
      "model.layers.23.fc1.bias False\n",
      "model.layers.23.fc2.weight False\n",
      "model.layers.23.fc2.bias False\n",
      "model.layers.23.final_layer_norm.weight False\n",
      "model.layers.23.final_layer_norm.bias False\n",
      "model.layers.24.self_attn.k_proj.weight False\n",
      "model.layers.24.self_attn.k_proj.bias False\n",
      "model.layers.24.self_attn.v_proj.weight False\n",
      "model.layers.24.self_attn.v_proj.bias False\n",
      "model.layers.24.self_attn.q_proj.weight False\n",
      "model.layers.24.self_attn.q_proj.bias False\n",
      "model.layers.24.self_attn.out_proj.weight False\n",
      "model.layers.24.self_attn.out_proj.bias False\n",
      "model.layers.24.self_attn_layer_norm.weight False\n",
      "model.layers.24.self_attn_layer_norm.bias False\n",
      "model.layers.24.fc1.weight False\n",
      "model.layers.24.fc1.bias False\n",
      "model.layers.24.fc2.weight False\n",
      "model.layers.24.fc2.bias False\n",
      "model.layers.24.final_layer_norm.weight False\n",
      "model.layers.24.final_layer_norm.bias False\n",
      "model.layers.25.self_attn.k_proj.weight False\n",
      "model.layers.25.self_attn.k_proj.bias False\n",
      "model.layers.25.self_attn.v_proj.weight False\n",
      "model.layers.25.self_attn.v_proj.bias False\n",
      "model.layers.25.self_attn.q_proj.weight False\n",
      "model.layers.25.self_attn.q_proj.bias False\n",
      "model.layers.25.self_attn.out_proj.weight False\n",
      "model.layers.25.self_attn.out_proj.bias False\n",
      "model.layers.25.self_attn_layer_norm.weight False\n",
      "model.layers.25.self_attn_layer_norm.bias False\n",
      "model.layers.25.fc1.weight False\n",
      "model.layers.25.fc1.bias False\n",
      "model.layers.25.fc2.weight False\n",
      "model.layers.25.fc2.bias False\n",
      "model.layers.25.final_layer_norm.weight False\n",
      "model.layers.25.final_layer_norm.bias False\n",
      "model.layers.26.self_attn.k_proj.weight False\n",
      "model.layers.26.self_attn.k_proj.bias False\n",
      "model.layers.26.self_attn.v_proj.weight False\n",
      "model.layers.26.self_attn.v_proj.bias False\n",
      "model.layers.26.self_attn.q_proj.weight False\n",
      "model.layers.26.self_attn.q_proj.bias False\n",
      "model.layers.26.self_attn.out_proj.weight False\n",
      "model.layers.26.self_attn.out_proj.bias False\n",
      "model.layers.26.self_attn_layer_norm.weight False\n",
      "model.layers.26.self_attn_layer_norm.bias False\n",
      "model.layers.26.fc1.weight False\n",
      "model.layers.26.fc1.bias False\n",
      "model.layers.26.fc2.weight False\n",
      "model.layers.26.fc2.bias False\n",
      "model.layers.26.final_layer_norm.weight False\n",
      "model.layers.26.final_layer_norm.bias False\n",
      "model.layers.27.self_attn.k_proj.weight False\n",
      "model.layers.27.self_attn.k_proj.bias False\n",
      "model.layers.27.self_attn.v_proj.weight False\n",
      "model.layers.27.self_attn.v_proj.bias False\n",
      "model.layers.27.self_attn.q_proj.weight False\n",
      "model.layers.27.self_attn.q_proj.bias False\n",
      "model.layers.27.self_attn.out_proj.weight False\n",
      "model.layers.27.self_attn.out_proj.bias False\n",
      "model.layers.27.self_attn_layer_norm.weight False\n",
      "model.layers.27.self_attn_layer_norm.bias False\n",
      "model.layers.27.fc1.weight False\n",
      "model.layers.27.fc1.bias False\n",
      "model.layers.27.fc2.weight False\n",
      "model.layers.27.fc2.bias False\n",
      "model.layers.27.final_layer_norm.weight False\n",
      "model.layers.27.final_layer_norm.bias False\n",
      "model.layers.28.self_attn.k_proj.weight False\n",
      "model.layers.28.self_attn.k_proj.bias False\n",
      "model.layers.28.self_attn.v_proj.weight False\n",
      "model.layers.28.self_attn.v_proj.bias False\n",
      "model.layers.28.self_attn.q_proj.weight False\n",
      "model.layers.28.self_attn.q_proj.bias False\n",
      "model.layers.28.self_attn.out_proj.weight False\n",
      "model.layers.28.self_attn.out_proj.bias False\n",
      "model.layers.28.self_attn_layer_norm.weight False\n",
      "model.layers.28.self_attn_layer_norm.bias False\n",
      "model.layers.28.fc1.weight False\n",
      "model.layers.28.fc1.bias False\n",
      "model.layers.28.fc2.weight False\n",
      "model.layers.28.fc2.bias False\n",
      "model.layers.28.final_layer_norm.weight False\n",
      "model.layers.28.final_layer_norm.bias False\n",
      "model.layers.29.self_attn.k_proj.weight False\n",
      "model.layers.29.self_attn.k_proj.bias False\n",
      "model.layers.29.self_attn.v_proj.weight False\n",
      "model.layers.29.self_attn.v_proj.bias False\n",
      "model.layers.29.self_attn.q_proj.weight False\n",
      "model.layers.29.self_attn.q_proj.bias False\n",
      "model.layers.29.self_attn.out_proj.weight False\n",
      "model.layers.29.self_attn.out_proj.bias False\n",
      "model.layers.29.self_attn_layer_norm.weight False\n",
      "model.layers.29.self_attn_layer_norm.bias False\n",
      "model.layers.29.fc1.weight False\n",
      "model.layers.29.fc1.bias False\n",
      "model.layers.29.fc2.weight False\n",
      "model.layers.29.fc2.bias False\n",
      "model.layers.29.final_layer_norm.weight False\n",
      "model.layers.29.final_layer_norm.bias False\n",
      "model.layers.30.self_attn.k_proj.weight False\n",
      "model.layers.30.self_attn.k_proj.bias False\n",
      "model.layers.30.self_attn.v_proj.weight False\n",
      "model.layers.30.self_attn.v_proj.bias False\n",
      "model.layers.30.self_attn.q_proj.weight False\n",
      "model.layers.30.self_attn.q_proj.bias False\n",
      "model.layers.30.self_attn.out_proj.weight False\n",
      "model.layers.30.self_attn.out_proj.bias False\n",
      "model.layers.30.self_attn_layer_norm.weight False\n",
      "model.layers.30.self_attn_layer_norm.bias False\n",
      "model.layers.30.fc1.weight False\n",
      "model.layers.30.fc1.bias False\n",
      "model.layers.30.fc2.weight False\n",
      "model.layers.30.fc2.bias False\n",
      "model.layers.30.final_layer_norm.weight False\n",
      "model.layers.30.final_layer_norm.bias False\n",
      "model.layers.31.self_attn.k_proj.weight True\n",
      "model.layers.31.self_attn.k_proj.bias True\n",
      "model.layers.31.self_attn.v_proj.weight True\n",
      "model.layers.31.self_attn.v_proj.bias True\n",
      "model.layers.31.self_attn.q_proj.weight True\n",
      "model.layers.31.self_attn.q_proj.bias True\n",
      "model.layers.31.self_attn.out_proj.weight True\n",
      "model.layers.31.self_attn.out_proj.bias True\n",
      "model.layers.31.self_attn_layer_norm.weight True\n",
      "model.layers.31.self_attn_layer_norm.bias True\n",
      "model.layers.31.fc1.weight True\n",
      "model.layers.31.fc1.bias True\n",
      "model.layers.31.fc2.weight True\n",
      "model.layers.31.fc2.bias True\n",
      "model.layers.31.final_layer_norm.weight True\n",
      "model.layers.31.final_layer_norm.bias True\n",
      "model.layer_norm.weight False\n",
      "model.layer_norm.bias False\n"
     ]
    }
   ],
   "source": [
    "for name, param in model.named_parameters():\n",
    "    print(name, param.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGLMForCausalLM(\n",
       "  (model): XGLMModel(\n",
       "    (embed_tokens): Embedding(256008, 2048, padding_idx=1)\n",
       "    (embed_positions): XGLMSinusoidalPositionalEmbedding()\n",
       "    (layers): ModuleList(\n",
       "      (0-23): 24 x XGLMDecoderLayer(\n",
       "        (self_attn): BartAttentionLayerBetterTransformer(\n",
       "          (k_proj): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "          (v_proj): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "          (q_proj): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "          (out_proj): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "        )\n",
       "        (activation_fn): GELUActivation()\n",
       "        (self_attn_layer_norm): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
       "        (fc1): Linear(in_features=2048, out_features=8192, bias=True)\n",
       "        (fc2): Linear(in_features=8192, out_features=2048, bias=True)\n",
       "        (final_layer_norm): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "    (layer_norm): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (lm_head): Linear(in_features=2048, out_features=256008, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BetterTransformer.transform(model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
