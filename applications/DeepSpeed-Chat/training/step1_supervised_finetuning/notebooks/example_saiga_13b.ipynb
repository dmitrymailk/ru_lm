{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kosenko/miniconda3/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Loading checkpoint shards: 100%|██████████| 3/3 [00:45<00:00, 15.11s/it]\n",
      "You are using the legacy behaviour of the <class 'transformers.models.llama.tokenization_llama.LlamaTokenizer'>. This means that tokens that come after special tokens will not be properly handled. We recommend you to read the related pull request available at https://github.com/huggingface/transformers/pull/24565\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Напишите интересный пост в блоге о недавней поездке на Гавайи, рассказывая о культурном опыте и достопримечательностях, которые обязательно нужно увидеть.\n",
      "Приветствую вас на моем новом блоге! Я только что вернулся из невероятной поездки на Гавайи, и я хочу поделиться своими впечатлениями с вами.\n",
      "\n",
      "Я прилетел в Гонолулу, столицу штата Гавайи, и сразу был поражен красотой острова. Здесь есть много культурных достопримечательностей, которые вы должны увидеть, если вы посетите.\n",
      "\n",
      "Важным местом для посещения является Национальный парк Воллеса. Это большой национальный парк, который включает в себя вулканические горы, тропические леса и пляжи. Вы можете совершить поход или прогуляться по тропам, чтобы исследовать его.\n",
      "\n",
      "Другой популярный туристический объект - пляж Вайкики. Это один из самых известных пляжей в мире, и это отличное место для плавания, серфинга и других водных видов спорта.\n",
      "\n",
      "Если вы заинтересованы в изучении истории Гавайев, то вы должны посетить Музей Королевства Гавайи. Это музей, посвященный королевской династии Гавайев, которая правила островом с 1810 года до аннексии США в 1893 году.\n",
      "\n",
      "Кроме того, вы также должны посетить Аламоана-Бэй, район в Гонолулу, который известен своим ночным жизнью и ресторанами. Это отличное место для вечеринок и вечернего питания.\n",
      "\n",
      "В целом, Гавайи - это удивительное место, которое предлагает множество культурных достопримечательностей и мероприятий. Если вы ищете отличный отдых, то это идеальное место для этого.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer, GenerationConfig\n",
    "import torch\n",
    "from peft import PeftModel, PeftConfig\n",
    "\n",
    "\n",
    "class GoralConversation:\n",
    "    def __init__(\n",
    "        self,\n",
    "        message_template=\" <s> {role}\\n{content} </s>\\n\",\n",
    "        system_prompt=\"Ты — Горал, русскоязычный автоматический ассистент. Ты разговариваешь с людьми и помогаешь им.\",\n",
    "        start_token_id=1,\n",
    "        bot_token_id=9225,\n",
    "    ):\n",
    "        self.message_template = message_template\n",
    "        self.start_token_id = start_token_id\n",
    "        self.bot_token_id = bot_token_id\n",
    "        self.messages = [{\"role\": \"system\", \"content\": system_prompt}]\n",
    "\n",
    "    def get_start_token_id(self):\n",
    "        return self.start_token_id\n",
    "\n",
    "    def get_bot_token_id(self):\n",
    "        return self.bot_token_id\n",
    "\n",
    "    def add_user_message(self, message):\n",
    "        self.messages.append({\"role\": \"user\", \"content\": message})\n",
    "\n",
    "    def add_bot_message(self, message):\n",
    "        self.messages.append({\"role\": \"bot\", \"content\": message})\n",
    "\n",
    "    def get_prompt(self, tokenizer):\n",
    "        final_text = \"\"\n",
    "        for message in self.messages:\n",
    "            message_text = self.message_template.format(**message)\n",
    "            final_text += message_text\n",
    "        final_text += tokenizer.decode(\n",
    "            [\n",
    "                self.start_token_id,\n",
    "            ]\n",
    "        )\n",
    "        final_text += \" \"\n",
    "        final_text += tokenizer.decode([self.bot_token_id])\n",
    "        return final_text.strip()\n",
    "\n",
    "\n",
    "def generate(model, tokenizer, prompt, generation_config):\n",
    "    data = tokenizer(\n",
    "        prompt,\n",
    "        return_tensors=\"pt\",\n",
    "        truncation=True,\n",
    "        max_length=2048,\n",
    "    )\n",
    "    data = {k: v.to(model.device) for k, v in data.items()}\n",
    "    output_ids = model.generate(**data, generation_config=generation_config)[0]\n",
    "    output_ids = output_ids[len(data[\"input_ids\"][0]) :]\n",
    "    output = tokenizer.decode(output_ids, skip_special_tokens=True)\n",
    "    return output.strip()\n",
    "\n",
    "\n",
    "# weights_path = \"/home/kosenko/deepspeed/DeepSpeedExamples/applications/DeepSpeed-Chat/training/step1_supervised_finetuning/rulm/rulm2/rulm/self_instruct/models/saiga2_13b_v4\"\n",
    "weights_path = \"dim/llama2_13b_dolly_oasst1_chip2\"\n",
    "access_token = \"\"\n",
    "\n",
    "config = PeftConfig.from_pretrained(weights_path)\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    config.base_model_name_or_path,\n",
    "    load_in_8bit=True,\n",
    "    torch_dtype=torch.float16,\n",
    "    device_map={\"\": 0},\n",
    "    token=access_token,\n",
    ")\n",
    "model = PeftModel.from_pretrained(\n",
    "    model,\n",
    "    weights_path,\n",
    "    torch_dtype=torch.float16,\n",
    ")\n",
    "model.eval()\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(weights_path)\n",
    "generation_config = GenerationConfig.from_pretrained(weights_path)\n",
    "generation_config.do_sample = False\n",
    "\n",
    "\n",
    "inp = \"Напишите интересный пост в блоге о недавней поездке на Гавайи, рассказывая о культурном опыте и достопримечательностях, которые обязательно нужно увидеть.\"\n",
    "conversation = GoralConversation(\n",
    "    start_token_id=1,\n",
    "    bot_token_id=9225,\n",
    ")\n",
    "conversation.add_user_message(inp)\n",
    "prompt = conversation.get_prompt(tokenizer)\n",
    "\n",
    "output = generate(model, tokenizer, prompt, generation_config)\n",
    "print(inp)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Push to hub\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "adapter_model.bin: 100%|██████████| 105M/105M [00:21<00:00, 5.00MB/s]\n",
      "Upload 1 LFS files: 100%|██████████| 1/1 [00:21<00:00, 21.44s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/dim/llama2_13b_dolly_oasst1_chip2/commit/399a0cf9afb8ded90be9bca1f688480e1c05d0ac', commit_message='Upload model', commit_description='', oid='399a0cf9afb8ded90be9bca1f688480e1c05d0ac', pr_url=None, pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model.push_to_hub(\"dim/llama2_13b_dolly_oasst1_chip2\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
