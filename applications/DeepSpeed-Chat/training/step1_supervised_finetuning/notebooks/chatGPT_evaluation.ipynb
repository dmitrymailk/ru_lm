{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "openai.api_key = open(\"./chat_gpt_token\").read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "openai.Model.list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello! How can I assist you today?\n"
     ]
    }
   ],
   "source": [
    "def chat_with_chatgpt(prompt, model=\"gpt-3.5-turbo\"):\n",
    "    chat_completion = openai.ChatCompletion.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "        temperature=0.0,\n",
    "    )\n",
    "\n",
    "    return chat_completion[\"choices\"][0][\"message\"][\"content\"].strip()\n",
    "\n",
    "\n",
    "user_prompt = \"Hello world.\"\n",
    "chatbot_response = chat_with_chatgpt(user_prompt, model=\"gpt-4\")\n",
    "print(chatbot_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>prompt</th>\n",
       "      <th>original_answer</th>\n",
       "      <th>xglm-4.5B_ru_v10epoch=0</th>\n",
       "      <th>xglm-4.5B_ru_v10epoch=0_step=102854</th>\n",
       "      <th>xglm-4.5B_ru_v10epoch=0_step=20570</th>\n",
       "      <th>xglm-4.5B_ru_v10epoch=0_step=41141</th>\n",
       "      <th>xglm-4.5B_ru_v10epoch=0_step=61712</th>\n",
       "      <th>xglm-4.5B_ru_v10epoch=0_step=82283</th>\n",
       "      <th>xglm-4.5B_ru_v10epoch=1</th>\n",
       "      <th>...</th>\n",
       "      <th>xglm-4.5B_ru_v10epoch=4</th>\n",
       "      <th>xglm-4.5B_ru_v10epoch=5</th>\n",
       "      <th>xglm-4.5B_ru_v10epoch=5_step=102854</th>\n",
       "      <th>xglm-4.5B_ru_v10epoch=5_step=20570</th>\n",
       "      <th>xglm-4.5B_ru_v10epoch=5_step=41141</th>\n",
       "      <th>xglm-4.5B_ru_v10epoch=5_step=61712</th>\n",
       "      <th>xglm-4.5B_ru_v10epoch=5_step=82283</th>\n",
       "      <th>xglm-4.5B_ru_v10epoch=6_step=20570</th>\n",
       "      <th>xglm-4.5B_ru_v10epoch=6_step=41141</th>\n",
       "      <th>xglm-4.5B_ru_v10epoch=6_step=61712</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Human:\\nНапишите краткое эссе на тему \"История...</td>\n",
       "      <td>История развития компьютерной техники началась...</td>\n",
       "      <td>\\nHuman:\\nНапишите краткое эссе на тему \"Истор...</td>\n",
       "      <td>\\nHuman:\\nНапишите краткое эссе на тему \"Истор...</td>\n",
       "      <td>\\nHuman:\\nНапишите краткое эссе на тему \"Истор...</td>\n",
       "      <td>\\nHuman:\\nНапишите краткое эссе на тему \"Истор...</td>\n",
       "      <td>\\nHuman:\\nНапишите краткое эссе на тему \"Истор...</td>\n",
       "      <td>\\nHuman:\\nНапишите краткое эссе на тему \"Истор...</td>\n",
       "      <td>\\nHuman:\\nНапишите краткое эссе на тему \"Истор...</td>\n",
       "      <td>...</td>\n",
       "      <td>\\nHuman:\\nНапишите краткое эссе на тему \"Истор...</td>\n",
       "      <td>\\nHuman:\\nНапишите краткое эссе на тему \"Истор...</td>\n",
       "      <td>\\nHuman:\\nНапишите краткое эссе на тему \"Истор...</td>\n",
       "      <td>\\nHuman:\\nНапишите краткое эссе на тему \"Истор...</td>\n",
       "      <td>\\nHuman:\\nНапишите краткое эссе на тему \"Истор...</td>\n",
       "      <td>\\nHuman:\\nНапишите краткое эссе на тему \"Истор...</td>\n",
       "      <td>\\nHuman:\\nНапишите краткое эссе на тему \"Истор...</td>\n",
       "      <td>\\nHuman:\\nНапишите краткое эссе на тему \"Истор...</td>\n",
       "      <td>\\nHuman:\\nНапишите краткое эссе на тему \"Истор...</td>\n",
       "      <td>\\nHuman:\\nНапишите краткое эссе на тему \"Истор...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Human:\\nПереведите следующее русское выражение...</td>\n",
       "      <td>\"No pain, no gain.\"</td>\n",
       "      <td>\\nHuman:\\nПереведите следующее русское выражен...</td>\n",
       "      <td>\\nHuman:\\nПереведите следующее русское выражен...</td>\n",
       "      <td>\\nHuman:\\nПереведите следующее русское выражен...</td>\n",
       "      <td>\\nHuman:\\nПереведите следующее русское выражен...</td>\n",
       "      <td>\\nHuman:\\nПереведите следующее русское выражен...</td>\n",
       "      <td>\\nHuman:\\nПереведите следующее русское выражен...</td>\n",
       "      <td>\\nHuman:\\nПереведите следующее русское выражен...</td>\n",
       "      <td>...</td>\n",
       "      <td>\\nHuman:\\nПереведите следующее русское выражен...</td>\n",
       "      <td>\\nHuman:\\nПереведите следующее русское выражен...</td>\n",
       "      <td>\\nHuman:\\nПереведите следующее русское выражен...</td>\n",
       "      <td>\\nHuman:\\nПереведите следующее русское выражен...</td>\n",
       "      <td>\\nHuman:\\nПереведите следующее русское выражен...</td>\n",
       "      <td>\\nHuman:\\nПереведите следующее русское выражен...</td>\n",
       "      <td>\\nHuman:\\nПереведите следующее русское выражен...</td>\n",
       "      <td>\\nHuman:\\nПереведите следующее русское выражен...</td>\n",
       "      <td>\\nHuman:\\nПереведите следующее русское выражен...</td>\n",
       "      <td>\\nHuman:\\nПереведите следующее русское выражен...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Human:\\nОпредели термин: \"инфляция\"\\n\\nAssista...</td>\n",
       "      <td>Инфляция - это общее увеличение уровня цен на ...</td>\n",
       "      <td>\\nHuman:\\nОпредели термин: \"инфляция\"\\n\\nAssis...</td>\n",
       "      <td>\\nHuman:\\nОпредели термин: \"инфляция\"\\n\\nAssis...</td>\n",
       "      <td>\\nHuman:\\nОпредели термин: \"инфляция\"\\n\\nAssis...</td>\n",
       "      <td>\\nHuman:\\nОпредели термин: \"инфляция\"\\n\\nAssis...</td>\n",
       "      <td>\\nHuman:\\nОпредели термин: \"инфляция\"\\n\\nAssis...</td>\n",
       "      <td>\\nHuman:\\nОпредели термин: \"инфляция\"\\n\\nAssis...</td>\n",
       "      <td>\\nHuman:\\nОпредели термин: \"инфляция\"\\n\\nAssis...</td>\n",
       "      <td>...</td>\n",
       "      <td>\\nHuman:\\nОпредели термин: \"инфляция\"\\n\\nAssis...</td>\n",
       "      <td>\\nHuman:\\nОпредели термин: \"инфляция\"\\n\\nAssis...</td>\n",
       "      <td>\\nHuman:\\nОпредели термин: \"инфляция\"\\n\\nAssis...</td>\n",
       "      <td>\\nHuman:\\nОпредели термин: \"инфляция\"\\n\\nAssis...</td>\n",
       "      <td>\\nHuman:\\nОпредели термин: \"инфляция\"\\n\\nAssis...</td>\n",
       "      <td>\\nHuman:\\nОпредели термин: \"инфляция\"\\n\\nAssis...</td>\n",
       "      <td>\\nHuman:\\nОпредели термин: \"инфляция\"\\n\\nAssis...</td>\n",
       "      <td>\\nHuman:\\nОпредели термин: \"инфляция\"\\n\\nAssis...</td>\n",
       "      <td>\\nHuman:\\nОпредели термин: \"инфляция\"\\n\\nAssis...</td>\n",
       "      <td>\\nHuman:\\nОпредели термин: \"инфляция\"\\n\\nAssis...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                             prompt   \n",
       "0           0  Human:\\nНапишите краткое эссе на тему \"История...  \\\n",
       "1           1  Human:\\nПереведите следующее русское выражение...   \n",
       "2           2  Human:\\nОпредели термин: \"инфляция\"\\n\\nAssista...   \n",
       "\n",
       "                                     original_answer   \n",
       "0  История развития компьютерной техники началась...  \\\n",
       "1                                \"No pain, no gain.\"   \n",
       "2  Инфляция - это общее увеличение уровня цен на ...   \n",
       "\n",
       "                             xglm-4.5B_ru_v10epoch=0   \n",
       "0  \\nHuman:\\nНапишите краткое эссе на тему \"Истор...  \\\n",
       "1  \\nHuman:\\nПереведите следующее русское выражен...   \n",
       "2  \\nHuman:\\nОпредели термин: \"инфляция\"\\n\\nAssis...   \n",
       "\n",
       "                 xglm-4.5B_ru_v10epoch=0_step=102854   \n",
       "0  \\nHuman:\\nНапишите краткое эссе на тему \"Истор...  \\\n",
       "1  \\nHuman:\\nПереведите следующее русское выражен...   \n",
       "2  \\nHuman:\\nОпредели термин: \"инфляция\"\\n\\nAssis...   \n",
       "\n",
       "                  xglm-4.5B_ru_v10epoch=0_step=20570   \n",
       "0  \\nHuman:\\nНапишите краткое эссе на тему \"Истор...  \\\n",
       "1  \\nHuman:\\nПереведите следующее русское выражен...   \n",
       "2  \\nHuman:\\nОпредели термин: \"инфляция\"\\n\\nAssis...   \n",
       "\n",
       "                  xglm-4.5B_ru_v10epoch=0_step=41141   \n",
       "0  \\nHuman:\\nНапишите краткое эссе на тему \"Истор...  \\\n",
       "1  \\nHuman:\\nПереведите следующее русское выражен...   \n",
       "2  \\nHuman:\\nОпредели термин: \"инфляция\"\\n\\nAssis...   \n",
       "\n",
       "                  xglm-4.5B_ru_v10epoch=0_step=61712   \n",
       "0  \\nHuman:\\nНапишите краткое эссе на тему \"Истор...  \\\n",
       "1  \\nHuman:\\nПереведите следующее русское выражен...   \n",
       "2  \\nHuman:\\nОпредели термин: \"инфляция\"\\n\\nAssis...   \n",
       "\n",
       "                  xglm-4.5B_ru_v10epoch=0_step=82283   \n",
       "0  \\nHuman:\\nНапишите краткое эссе на тему \"Истор...  \\\n",
       "1  \\nHuman:\\nПереведите следующее русское выражен...   \n",
       "2  \\nHuman:\\nОпредели термин: \"инфляция\"\\n\\nAssis...   \n",
       "\n",
       "                             xglm-4.5B_ru_v10epoch=1  ...   \n",
       "0  \\nHuman:\\nНапишите краткое эссе на тему \"Истор...  ...  \\\n",
       "1  \\nHuman:\\nПереведите следующее русское выражен...  ...   \n",
       "2  \\nHuman:\\nОпредели термин: \"инфляция\"\\n\\nAssis...  ...   \n",
       "\n",
       "                             xglm-4.5B_ru_v10epoch=4   \n",
       "0  \\nHuman:\\nНапишите краткое эссе на тему \"Истор...  \\\n",
       "1  \\nHuman:\\nПереведите следующее русское выражен...   \n",
       "2  \\nHuman:\\nОпредели термин: \"инфляция\"\\n\\nAssis...   \n",
       "\n",
       "                             xglm-4.5B_ru_v10epoch=5   \n",
       "0  \\nHuman:\\nНапишите краткое эссе на тему \"Истор...  \\\n",
       "1  \\nHuman:\\nПереведите следующее русское выражен...   \n",
       "2  \\nHuman:\\nОпредели термин: \"инфляция\"\\n\\nAssis...   \n",
       "\n",
       "                 xglm-4.5B_ru_v10epoch=5_step=102854   \n",
       "0  \\nHuman:\\nНапишите краткое эссе на тему \"Истор...  \\\n",
       "1  \\nHuman:\\nПереведите следующее русское выражен...   \n",
       "2  \\nHuman:\\nОпредели термин: \"инфляция\"\\n\\nAssis...   \n",
       "\n",
       "                  xglm-4.5B_ru_v10epoch=5_step=20570   \n",
       "0  \\nHuman:\\nНапишите краткое эссе на тему \"Истор...  \\\n",
       "1  \\nHuman:\\nПереведите следующее русское выражен...   \n",
       "2  \\nHuman:\\nОпредели термин: \"инфляция\"\\n\\nAssis...   \n",
       "\n",
       "                  xglm-4.5B_ru_v10epoch=5_step=41141   \n",
       "0  \\nHuman:\\nНапишите краткое эссе на тему \"Истор...  \\\n",
       "1  \\nHuman:\\nПереведите следующее русское выражен...   \n",
       "2  \\nHuman:\\nОпредели термин: \"инфляция\"\\n\\nAssis...   \n",
       "\n",
       "                  xglm-4.5B_ru_v10epoch=5_step=61712   \n",
       "0  \\nHuman:\\nНапишите краткое эссе на тему \"Истор...  \\\n",
       "1  \\nHuman:\\nПереведите следующее русское выражен...   \n",
       "2  \\nHuman:\\nОпредели термин: \"инфляция\"\\n\\nAssis...   \n",
       "\n",
       "                  xglm-4.5B_ru_v10epoch=5_step=82283   \n",
       "0  \\nHuman:\\nНапишите краткое эссе на тему \"Истор...  \\\n",
       "1  \\nHuman:\\nПереведите следующее русское выражен...   \n",
       "2  \\nHuman:\\nОпредели термин: \"инфляция\"\\n\\nAssis...   \n",
       "\n",
       "                  xglm-4.5B_ru_v10epoch=6_step=20570   \n",
       "0  \\nHuman:\\nНапишите краткое эссе на тему \"Истор...  \\\n",
       "1  \\nHuman:\\nПереведите следующее русское выражен...   \n",
       "2  \\nHuman:\\nОпредели термин: \"инфляция\"\\n\\nAssis...   \n",
       "\n",
       "                  xglm-4.5B_ru_v10epoch=6_step=41141   \n",
       "0  \\nHuman:\\nНапишите краткое эссе на тему \"Истор...  \\\n",
       "1  \\nHuman:\\nПереведите следующее русское выражен...   \n",
       "2  \\nHuman:\\nОпредели термин: \"инфляция\"\\n\\nAssis...   \n",
       "\n",
       "                  xglm-4.5B_ru_v10epoch=6_step=61712  \n",
       "0  \\nHuman:\\nНапишите краткое эссе на тему \"Истор...  \n",
       "1  \\nHuman:\\nПереведите следующее русское выражен...  \n",
       "2  \\nHuman:\\nОпредели термин: \"инфляция\"\\n\\nAssis...  \n",
       "\n",
       "[3 rows x 23 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = pd.read_csv(\"./models/xglm-4.5B_ru_v10/merged_evaluation.csv\")\n",
    "dataset.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "\n",
    "class EvaluationPipeline1:\n",
    "    def __init__(self, eval_prompt_template: str, model_name=\"gpt-3.5-turbo\") -> None:\n",
    "        self.eval_prompt_template = eval_prompt_template\n",
    "        self.model_name = model_name\n",
    "\n",
    "    def extract_task(self, model_name, item):\n",
    "        # вытаскивает из промпта задание\n",
    "        return item[model_name].split(\"\\nAssi\")[0].split(\"Human:\\n\")[1].strip()\n",
    "\n",
    "    def extract_result(self, model_name, item):\n",
    "        # возвращает значение, которое сгенерировала модель\n",
    "        return item[model_name].split(\"Assistant:\\n\")[1].strip()\n",
    "\n",
    "    def extract_names(self, dataset_line):\n",
    "        return [item for item in dataset_line.index.to_list() if \"epoch\" in item]\n",
    "\n",
    "    def shuffle_names(self, model_names, amount=3, debug=False):\n",
    "        # генерирую несколько списков для поиска максимума в разных списках\n",
    "        model_names = sorted(model_names)\n",
    "        shuffled_names_list = []\n",
    "        for i in [2, 234, 56]:\n",
    "            rng = np.random.default_rng(i)\n",
    "            temp_model_names = model_names[:]\n",
    "            rng.shuffle(temp_model_names)\n",
    "            shuffled_names_list.append(temp_model_names)\n",
    "            if debug:\n",
    "                print(temp_model_names)\n",
    "        return shuffled_names_list[:amount]\n",
    "\n",
    "    def evaluation_func(\n",
    "        self,\n",
    "        item: dict,\n",
    "        model_name_1: str,\n",
    "        model_name_2: str,\n",
    "        evaluation_prompt: str,\n",
    "        debug: bool = False,\n",
    "    ):\n",
    "        task = self.extract_task(model_name=model_name_1, item=item)\n",
    "\n",
    "        eval_results = []\n",
    "        model_names = [\n",
    "            [model_name_1, model_name_2],\n",
    "            [model_name_2, model_name_1],\n",
    "        ]\n",
    "\n",
    "        eval_prompts = []\n",
    "\n",
    "        for model_1, model_2 in model_names:\n",
    "            model_name_1_result = self.extract_result(model_name=model_1, item=item)\n",
    "            model_name_2_result = self.extract_result(model_name=model_2, item=item)\n",
    "\n",
    "            evaluation_prompt_temp = evaluation_prompt.format(\n",
    "                task,\n",
    "                model_name_1_result,\n",
    "                model_name_2_result,\n",
    "            )\n",
    "\n",
    "            eval_prompts.append(eval_prompts)\n",
    "\n",
    "            if debug:\n",
    "                print(model_1, model_2)\n",
    "                print(evaluation_prompt_temp)\n",
    "                print(\"-\" * 100)\n",
    "\n",
    "            chatbot_response = chat_with_chatgpt(\n",
    "                evaluation_prompt_temp, model=self.model_name\n",
    "            )\n",
    "\n",
    "            if chatbot_response == \"Model_1\":\n",
    "                eval_results.append(model_1)\n",
    "            elif chatbot_response == \"Model_2\":\n",
    "                eval_results.append(model_2)\n",
    "            else:\n",
    "                eval_results.append(chatbot_response)\n",
    "\n",
    "        if debug:\n",
    "            print(eval_results)\n",
    "\n",
    "        result = {\n",
    "            \"eval_prompts\": eval_prompts,\n",
    "            \"eval_results\": eval_results,\n",
    "            \"winner\": \"\",\n",
    "        }\n",
    "\n",
    "        winner = None\n",
    "        error_string = \"Error\"\n",
    "        super_position = \"SuperPosition\"\n",
    "        # модель корректно выбрала лучшую модель\n",
    "        if eval_results[0] == eval_results[1] and eval_results[0] != error_string:\n",
    "            winner = eval_results[0]\n",
    "        # модель посчитала, что задание не выполнил никто\n",
    "        elif error_string in eval_results:\n",
    "            winner = error_string\n",
    "        # модель два раза выбрала различные модели\n",
    "        elif eval_results[0] != eval_results[1]:\n",
    "            winner = super_position\n",
    "        # другое поведение рассматривается как ошибка\n",
    "        else:\n",
    "            winner = error_string\n",
    "\n",
    "        result[\"winner\"] = winner\n",
    "\n",
    "        return result\n",
    "\n",
    "    def find_best(self, dataset_line):\n",
    "        model_names = self.extract_names(dataset_line=dataset_line)\n",
    "        shuffled_names = self.shuffle_names(model_names=model_names, amount=3)\n",
    "\n",
    "        best_models = []\n",
    "\n",
    "        for shuffled_model_names in shuffled_names:\n",
    "            print(shuffled_model_names)\n",
    "            best_model = shuffled_model_names[0]\n",
    "            # простой линейный поиск\n",
    "            super_positions = 0\n",
    "            model_leaderboard = {name: 0 for name in shuffled_model_names}\n",
    "\n",
    "            for i in range(1, len(shuffled_model_names)):\n",
    "                next_model_name = shuffled_model_names[i]\n",
    "                new_best_model = self.evaluation_func(\n",
    "                    item=dataset_line.to_dict(),\n",
    "                    evaluation_prompt=self.eval_prompt_template,\n",
    "                    model_name_1=best_model,\n",
    "                    model_name_2=next_model_name,\n",
    "                    # debug=True,\n",
    "                )\n",
    "                new_best_model = new_best_model[\"winner\"]\n",
    "\n",
    "                print(\n",
    "                    f\"Best model={best_model}, Compare model={next_model_name}, Winner={new_best_model}\"\n",
    "                )\n",
    "                if new_best_model == \"Error\":\n",
    "                    continue\n",
    "\n",
    "                if new_best_model == \"SuperPosition\":\n",
    "                    model_leaderboard[best_model] += 0.5\n",
    "                    model_leaderboard[next_model_name] += 0.5\n",
    "                    best_model = next_model_name\n",
    "                    super_positions += 1\n",
    "                    continue\n",
    "\n",
    "                if new_best_model != best_model:\n",
    "                    best_model = new_best_model\n",
    "                    model_leaderboard[best_model] += 1\n",
    "                else:\n",
    "                    model_leaderboard[best_model] += 1\n",
    "\n",
    "                time.sleep(2)\n",
    "            super_position_rate = super_positions / (len(shuffled_model_names) - 1)\n",
    "            best_models.append([model_leaderboard, super_position_rate])\n",
    "\n",
    "        # print(best_models)\n",
    "        for best_model in best_models:\n",
    "            best_model_name = max(best_model[0], key=best_model[0].get)\n",
    "            print(f\"best_model_name={best_model_name}\", best_model[1])\n",
    "\n",
    "\n",
    "evaluation_prompt_2 = \"\"\"\n",
    "Выбери какая модель лучше справилась с задачей. В ответе напиши только Model_1 или Model_2.\n",
    "Если задача не выполнена напиши Error.\n",
    "Задача:\n",
    "{}\n",
    "Model_1:\n",
    "{}\n",
    "Model_2:\n",
    "{}\n",
    "Ответ:\n",
    "\"\"\"\n",
    "\n",
    "dataset_line_1 = dataset.iloc[0]\n",
    "eval_pipeline_2 = EvaluationPipeline1(\n",
    "    eval_prompt_template=evaluation_prompt_2, model_name=\"gpt-4\"\n",
    ")\n",
    "eval_pipeline_2.find_best(dataset_line=dataset_line_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'xglm-4.5B_ru_v10epoch=5_step=102854'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Лог экспериментов где при суперпозиции я не меняю модель на новую, оставляю старую\n",
    "\n",
    "Human:\n",
    "Напишите краткое эссе на тему \"История развития компьютерной техники\".\n",
    "\n",
    "['xglm-4.5B_ru_v10epoch=1', 'xglm-4.5B_ru_v10epoch=6_step=41141', 'xglm-4.5B_ru_v10epoch=2', 'xglm-4.5B_ru_v10epoch=4', 'xglm-4.5B_ru_v10epoch=0_step=20570', 'xglm-4.5B_ru_v10epoch=5', 'xglm-4.5B_ru_v10epoch=0', 'xglm-4.5B_ru_v10epoch=6_step=20570', 'xglm-4.5B_ru_v10epoch=6_step=61712', 'xglm-4.5B_ru_v10epoch=5_step=82283', 'xglm-4.5B_ru_v10epoch=3_step=82283', 'xglm-4.5B_ru_v10epoch=5_step=102854', 'xglm-4.5B_ru_v10epoch=0_step=82283', 'xglm-4.5B_ru_v10epoch=5_step=61712', 'xglm-4.5B_ru_v10epoch=5_step=20570', 'xglm-4.5B_ru_v10epoch=5_step=41141', 'xglm-4.5B_ru_v10epoch=0_step=41141', 'xglm-4.5B_ru_v10epoch=0_step=61712', 'xglm-4.5B_ru_v10epoch=3', 'xglm-4.5B_ru_v10epoch=0_step=102854']\n",
    "Best model=xglm-4.5B_ru_v10epoch=1, Compare model=xglm-4.5B_ru_v10epoch=6_step=41141, Winner=xglm-4.5B_ru_v10epoch=6_step=41141\n",
    "Best model=xglm-4.5B_ru_v10epoch=6_step=41141, Compare model=xglm-4.5B_ru_v10epoch=2, Winner=xglm-4.5B_ru_v10epoch=6_step=41141\n",
    "Best model=xglm-4.5B_ru_v10epoch=6_step=41141, Compare model=xglm-4.5B_ru_v10epoch=4, Winner=SuperPosition\n",
    "Best model=xglm-4.5B_ru_v10epoch=6_step=41141, Compare model=xglm-4.5B_ru_v10epoch=0_step=20570, Winner=xglm-4.5B_ru_v10epoch=6_step=41141\n",
    "Best model=xglm-4.5B_ru_v10epoch=6_step=41141, Compare model=xglm-4.5B_ru_v10epoch=5, Winner=xglm-4.5B_ru_v10epoch=6_step=41141\n",
    "Best model=xglm-4.5B_ru_v10epoch=6_step=41141, Compare model=xglm-4.5B_ru_v10epoch=0, Winner=xglm-4.5B_ru_v10epoch=6_step=41141\n",
    "Best model=xglm-4.5B_ru_v10epoch=6_step=41141, Compare model=xglm-4.5B_ru_v10epoch=6_step=20570, Winner=xglm-4.5B_ru_v10epoch=6_step=41141\n",
    "Best model=xglm-4.5B_ru_v10epoch=6_step=41141, Compare model=xglm-4.5B_ru_v10epoch=6_step=61712, Winner=SuperPosition\n",
    "Best model=xglm-4.5B_ru_v10epoch=6_step=41141, Compare model=xglm-4.5B_ru_v10epoch=5_step=82283, Winner=xglm-4.5B_ru_v10epoch=6_step=41141\n",
    "Best model=xglm-4.5B_ru_v10epoch=6_step=41141, Compare model=xglm-4.5B_ru_v10epoch=3_step=82283, Winner=xglm-4.5B_ru_v10epoch=6_step=41141\n",
    "Best model=xglm-4.5B_ru_v10epoch=6_step=41141, Compare model=xglm-4.5B_ru_v10epoch=5_step=102854, Winner=xglm-4.5B_ru_v10epoch=6_step=41141\n",
    "Best model=xglm-4.5B_ru_v10epoch=6_step=41141, Compare model=xglm-4.5B_ru_v10epoch=0_step=82283, Winner=xglm-4.5B_ru_v10epoch=6_step=41141\n",
    "Best model=xglm-4.5B_ru_v10epoch=6_step=41141, Compare model=xglm-4.5B_ru_v10epoch=5_step=61712, Winner=xglm-4.5B_ru_v10epoch=6_step=41141\n",
    "Best model=xglm-4.5B_ru_v10epoch=6_step=41141, Compare model=xglm-4.5B_ru_v10epoch=5_step=20570, Winner=SuperPosition\n",
    "Best model=xglm-4.5B_ru_v10epoch=6_step=41141, Compare model=xglm-4.5B_ru_v10epoch=5_step=41141, Winner=xglm-4.5B_ru_v10epoch=6_step=41141\n",
    "Best model=xglm-4.5B_ru_v10epoch=6_step=41141, Compare model=xglm-4.5B_ru_v10epoch=0_step=41141, Winner=xglm-4.5B_ru_v10epoch=6_step=41141\n",
    "Best model=xglm-4.5B_ru_v10epoch=6_step=41141, Compare model=xglm-4.5B_ru_v10epoch=0_step=61712, Winner=xglm-4.5B_ru_v10epoch=6_step=41141\n",
    "Best model=xglm-4.5B_ru_v10epoch=6_step=41141, Compare model=xglm-4.5B_ru_v10epoch=3, Winner=xglm-4.5B_ru_v10epoch=6_step=41141\n",
    "Best model=xglm-4.5B_ru_v10epoch=6_step=41141, Compare model=xglm-4.5B_ru_v10epoch=0_step=102854, Winner=xglm-4.5B_ru_v10epoch=6_step=41141\n",
    "['xglm-4.5B_ru_v10epoch=3', 'xglm-4.5B_ru_v10epoch=5_step=82283', 'xglm-4.5B_ru_v10epoch=0_step=82283', 'xglm-4.5B_ru_v10epoch=0_step=102854', 'xglm-4.5B_ru_v10epoch=5_step=41141', 'xglm-4.5B_ru_v10epoch=6_step=20570', 'xglm-4.5B_ru_v10epoch=1', 'xglm-4.5B_ru_v10epoch=0_step=20570', 'xglm-4.5B_ru_v10epoch=2', 'xglm-4.5B_ru_v10epoch=0_step=41141', 'xglm-4.5B_ru_v10epoch=6_step=41141', 'xglm-4.5B_ru_v10epoch=5_step=102854', 'xglm-4.5B_ru_v10epoch=5_step=20570', 'xglm-4.5B_ru_v10epoch=0_step=61712', 'xglm-4.5B_ru_v10epoch=5_step=61712', 'xglm-4.5B_ru_v10epoch=0', 'xglm-4.5B_ru_v10epoch=6_step=61712', 'xglm-4.5B_ru_v10epoch=5', 'xglm-4.5B_ru_v10epoch=3_step=82283', 'xglm-4.5B_ru_v10epoch=4']\n",
    "Best model=xglm-4.5B_ru_v10epoch=3, Compare model=xglm-4.5B_ru_v10epoch=5_step=82283, Winner=xglm-4.5B_ru_v10epoch=5_step=82283\n",
    "Best model=xglm-4.5B_ru_v10epoch=5_step=82283, Compare model=xglm-4.5B_ru_v10epoch=0_step=82283, Winner=xglm-4.5B_ru_v10epoch=0_step=82283\n",
    "Best model=xglm-4.5B_ru_v10epoch=0_step=82283, Compare model=xglm-4.5B_ru_v10epoch=0_step=102854, Winner=xglm-4.5B_ru_v10epoch=0_step=102854\n",
    "Best model=xglm-4.5B_ru_v10epoch=0_step=102854, Compare model=xglm-4.5B_ru_v10epoch=5_step=41141, Winner=xglm-4.5B_ru_v10epoch=0_step=102854\n",
    "Best model=xglm-4.5B_ru_v10epoch=0_step=102854, Compare model=xglm-4.5B_ru_v10epoch=6_step=20570, Winner=xglm-4.5B_ru_v10epoch=0_step=102854\n",
    "Best model=xglm-4.5B_ru_v10epoch=0_step=102854, Compare model=xglm-4.5B_ru_v10epoch=1, Winner=SuperPosition\n",
    "Best model=xglm-4.5B_ru_v10epoch=0_step=102854, Compare model=xglm-4.5B_ru_v10epoch=0_step=20570, Winner=xglm-4.5B_ru_v10epoch=0_step=102854\n",
    "Best model=xglm-4.5B_ru_v10epoch=0_step=102854, Compare model=xglm-4.5B_ru_v10epoch=2, Winner=SuperPosition\n",
    "Best model=xglm-4.5B_ru_v10epoch=0_step=102854, Compare model=xglm-4.5B_ru_v10epoch=0_step=41141, Winner=SuperPosition\n",
    "Best model=xglm-4.5B_ru_v10epoch=0_step=102854, Compare model=xglm-4.5B_ru_v10epoch=6_step=41141, Winner=SuperPosition\n",
    "Best model=xglm-4.5B_ru_v10epoch=0_step=102854, Compare model=xglm-4.5B_ru_v10epoch=5_step=102854, Winner=xglm-4.5B_ru_v10epoch=0_step=102854\n",
    "Best model=xglm-4.5B_ru_v10epoch=0_step=102854, Compare model=xglm-4.5B_ru_v10epoch=5_step=20570, Winner=xglm-4.5B_ru_v10epoch=0_step=102854\n",
    "Best model=xglm-4.5B_ru_v10epoch=0_step=102854, Compare model=xglm-4.5B_ru_v10epoch=0_step=61712, Winner=xglm-4.5B_ru_v10epoch=0_step=102854\n",
    "Best model=xglm-4.5B_ru_v10epoch=0_step=102854, Compare model=xglm-4.5B_ru_v10epoch=5_step=61712, Winner=SuperPosition\n",
    "Best model=xglm-4.5B_ru_v10epoch=0_step=102854, Compare model=xglm-4.5B_ru_v10epoch=0, Winner=SuperPosition\n",
    "Best model=xglm-4.5B_ru_v10epoch=0_step=102854, Compare model=xglm-4.5B_ru_v10epoch=6_step=61712, Winner=xglm-4.5B_ru_v10epoch=0_step=102854\n",
    "Best model=xglm-4.5B_ru_v10epoch=0_step=102854, Compare model=xglm-4.5B_ru_v10epoch=5, Winner=SuperPosition\n",
    "Best model=xglm-4.5B_ru_v10epoch=0_step=102854, Compare model=xglm-4.5B_ru_v10epoch=3_step=82283, Winner=xglm-4.5B_ru_v10epoch=0_step=102854\n",
    "Best model=xglm-4.5B_ru_v10epoch=0_step=102854, Compare model=xglm-4.5B_ru_v10epoch=4, Winner=SuperPosition\n",
    "['xglm-4.5B_ru_v10epoch=0_step=61712', 'xglm-4.5B_ru_v10epoch=3', 'xglm-4.5B_ru_v10epoch=0_step=20570', 'xglm-4.5B_ru_v10epoch=6_step=41141', 'xglm-4.5B_ru_v10epoch=2', 'xglm-4.5B_ru_v10epoch=5_step=102854', 'xglm-4.5B_ru_v10epoch=5_step=61712', 'xglm-4.5B_ru_v10epoch=6_step=61712', 'xglm-4.5B_ru_v10epoch=5_step=41141', 'xglm-4.5B_ru_v10epoch=5_step=20570', 'xglm-4.5B_ru_v10epoch=1', 'xglm-4.5B_ru_v10epoch=0_step=41141', 'xglm-4.5B_ru_v10epoch=0', 'xglm-4.5B_ru_v10epoch=0_step=82283', 'xglm-4.5B_ru_v10epoch=5_step=82283', 'xglm-4.5B_ru_v10epoch=4', 'xglm-4.5B_ru_v10epoch=6_step=20570', 'xglm-4.5B_ru_v10epoch=0_step=102854', 'xglm-4.5B_ru_v10epoch=3_step=82283', 'xglm-4.5B_ru_v10epoch=5']\n",
    "Best model=xglm-4.5B_ru_v10epoch=0_step=61712, Compare model=xglm-4.5B_ru_v10epoch=3, Winner=xglm-4.5B_ru_v10epoch=3\n",
    "Best model=xglm-4.5B_ru_v10epoch=3, Compare model=xglm-4.5B_ru_v10epoch=0_step=20570, Winner=xglm-4.5B_ru_v10epoch=3\n",
    "Best model=xglm-4.5B_ru_v10epoch=3, Compare model=xglm-4.5B_ru_v10epoch=6_step=41141, Winner=SuperPosition\n",
    "Best model=xglm-4.5B_ru_v10epoch=3, Compare model=xglm-4.5B_ru_v10epoch=2, Winner=SuperPosition\n",
    "Best model=xglm-4.5B_ru_v10epoch=3, Compare model=xglm-4.5B_ru_v10epoch=5_step=102854, Winner=SuperPosition\n",
    "Best model=xglm-4.5B_ru_v10epoch=3, Compare model=xglm-4.5B_ru_v10epoch=5_step=61712, Winner=SuperPosition\n",
    "Best model=xglm-4.5B_ru_v10epoch=3, Compare model=xglm-4.5B_ru_v10epoch=6_step=61712, Winner=xglm-4.5B_ru_v10epoch=6_step=61712\n",
    "Best model=xglm-4.5B_ru_v10epoch=6_step=61712, Compare model=xglm-4.5B_ru_v10epoch=5_step=41141, Winner=xglm-4.5B_ru_v10epoch=6_step=61712\n",
    "Best model=xglm-4.5B_ru_v10epoch=6_step=61712, Compare model=xglm-4.5B_ru_v10epoch=5_step=20570, Winner=xglm-4.5B_ru_v10epoch=6_step=61712\n",
    "Best model=xglm-4.5B_ru_v10epoch=6_step=61712, Compare model=xglm-4.5B_ru_v10epoch=1, Winner=SuperPosition\n",
    "Best model=xglm-4.5B_ru_v10epoch=6_step=61712, Compare model=xglm-4.5B_ru_v10epoch=0_step=41141, Winner=xglm-4.5B_ru_v10epoch=6_step=61712\n",
    "Best model=xglm-4.5B_ru_v10epoch=6_step=61712, Compare model=xglm-4.5B_ru_v10epoch=0, Winner=xglm-4.5B_ru_v10epoch=0\n",
    "Best model=xglm-4.5B_ru_v10epoch=0, Compare model=xglm-4.5B_ru_v10epoch=0_step=82283, Winner=xglm-4.5B_ru_v10epoch=0\n",
    "Best model=xglm-4.5B_ru_v10epoch=0, Compare model=xglm-4.5B_ru_v10epoch=5_step=82283, Winner=SuperPosition\n",
    "Best model=xglm-4.5B_ru_v10epoch=0, Compare model=xglm-4.5B_ru_v10epoch=4, Winner=SuperPosition\n",
    "Best model=xglm-4.5B_ru_v10epoch=0, Compare model=xglm-4.5B_ru_v10epoch=6_step=20570, Winner=xglm-4.5B_ru_v10epoch=0\n",
    "Best model=xglm-4.5B_ru_v10epoch=0, Compare model=xglm-4.5B_ru_v10epoch=0_step=102854, Winner=SuperPosition\n",
    "Best model=xglm-4.5B_ru_v10epoch=0, Compare model=xglm-4.5B_ru_v10epoch=3_step=82283, Winner=xglm-4.5B_ru_v10epoch=0\n",
    "Best model=xglm-4.5B_ru_v10epoch=0, Compare model=xglm-4.5B_ru_v10epoch=5, Winner=SuperPosition\n",
    "best_model_name=xglm-4.5B_ru_v10epoch=6_step=41141 0.0\n",
    "best_model_name=xglm-4.5B_ru_v10epoch=0_step=102854 0.0\n",
    "best_model_name=xglm-4.5B_ru_v10epoch=0 0.0\n",
    "\n",
    "Human:\n",
    "Напиши пять примеров химических элементов, начинающихся на букву \"С\".\n",
    "\n",
    "['xglm-4.5B_ru_v10epoch=1', 'xglm-4.5B_ru_v10epoch=6_step=41141', 'xglm-4.5B_ru_v10epoch=2', 'xglm-4.5B_ru_v10epoch=4', 'xglm-4.5B_ru_v10epoch=0_step=20570', 'xglm-4.5B_ru_v10epoch=5', 'xglm-4.5B_ru_v10epoch=0', 'xglm-4.5B_ru_v10epoch=6_step=20570', 'xglm-4.5B_ru_v10epoch=6_step=61712', 'xglm-4.5B_ru_v10epoch=5_step=82283', 'xglm-4.5B_ru_v10epoch=3_step=82283', 'xglm-4.5B_ru_v10epoch=5_step=102854', 'xglm-4.5B_ru_v10epoch=0_step=82283', 'xglm-4.5B_ru_v10epoch=5_step=61712', 'xglm-4.5B_ru_v10epoch=5_step=20570', 'xglm-4.5B_ru_v10epoch=5_step=41141', 'xglm-4.5B_ru_v10epoch=0_step=41141', 'xglm-4.5B_ru_v10epoch=0_step=61712', 'xglm-4.5B_ru_v10epoch=3', 'xglm-4.5B_ru_v10epoch=0_step=102854']\n",
    "Best model=xglm-4.5B_ru_v10epoch=1, Compare model=xglm-4.5B_ru_v10epoch=6_step=41141, Winner=SuperPosition\n",
    "Best model=xglm-4.5B_ru_v10epoch=1, Compare model=xglm-4.5B_ru_v10epoch=2, Winner=SuperPosition\n",
    "Best model=xglm-4.5B_ru_v10epoch=1, Compare model=xglm-4.5B_ru_v10epoch=4, Winner=SuperPosition\n",
    "Best model=xglm-4.5B_ru_v10epoch=1, Compare model=xglm-4.5B_ru_v10epoch=0_step=20570, Winner=xglm-4.5B_ru_v10epoch=1\n",
    "Best model=xglm-4.5B_ru_v10epoch=1, Compare model=xglm-4.5B_ru_v10epoch=5, Winner=SuperPosition\n",
    "Best model=xglm-4.5B_ru_v10epoch=1, Compare model=xglm-4.5B_ru_v10epoch=0, Winner=SuperPosition\n",
    "Best model=xglm-4.5B_ru_v10epoch=1, Compare model=xglm-4.5B_ru_v10epoch=6_step=20570, Winner=xglm-4.5B_ru_v10epoch=1\n",
    "Best model=xglm-4.5B_ru_v10epoch=1, Compare model=xglm-4.5B_ru_v10epoch=6_step=61712, Winner=SuperPosition\n",
    "Best model=xglm-4.5B_ru_v10epoch=1, Compare model=xglm-4.5B_ru_v10epoch=5_step=82283, Winner=SuperPosition\n",
    "Best model=xglm-4.5B_ru_v10epoch=1, Compare model=xglm-4.5B_ru_v10epoch=3_step=82283, Winner=SuperPosition\n",
    "Best model=xglm-4.5B_ru_v10epoch=1, Compare model=xglm-4.5B_ru_v10epoch=5_step=102854, Winner=SuperPosition\n",
    "Best model=xglm-4.5B_ru_v10epoch=1, Compare model=xglm-4.5B_ru_v10epoch=0_step=82283, Winner=xglm-4.5B_ru_v10epoch=0_step=82283\n",
    "Best model=xglm-4.5B_ru_v10epoch=0_step=82283, Compare model=xglm-4.5B_ru_v10epoch=5_step=61712, Winner=xglm-4.5B_ru_v10epoch=5_step=61712\n",
    "Best model=xglm-4.5B_ru_v10epoch=5_step=61712, Compare model=xglm-4.5B_ru_v10epoch=5_step=20570, Winner=SuperPosition\n",
    "Best model=xglm-4.5B_ru_v10epoch=5_step=61712, Compare model=xglm-4.5B_ru_v10epoch=5_step=41141, Winner=xglm-4.5B_ru_v10epoch=5_step=61712\n",
    "Best model=xglm-4.5B_ru_v10epoch=5_step=61712, Compare model=xglm-4.5B_ru_v10epoch=0_step=41141, Winner=xglm-4.5B_ru_v10epoch=5_step=61712\n",
    "Best model=xglm-4.5B_ru_v10epoch=5_step=61712, Compare model=xglm-4.5B_ru_v10epoch=0_step=61712, Winner=xglm-4.5B_ru_v10epoch=5_step=61712\n",
    "Best model=xglm-4.5B_ru_v10epoch=5_step=61712, Compare model=xglm-4.5B_ru_v10epoch=3, Winner=xglm-4.5B_ru_v10epoch=5_step=61712\n",
    "Best model=xglm-4.5B_ru_v10epoch=5_step=61712, Compare model=xglm-4.5B_ru_v10epoch=0_step=102854, Winner=SuperPosition\n",
    "['xglm-4.5B_ru_v10epoch=3', 'xglm-4.5B_ru_v10epoch=5_step=82283', 'xglm-4.5B_ru_v10epoch=0_step=82283', 'xglm-4.5B_ru_v10epoch=0_step=102854', 'xglm-4.5B_ru_v10epoch=5_step=41141', 'xglm-4.5B_ru_v10epoch=6_step=20570', 'xglm-4.5B_ru_v10epoch=1', 'xglm-4.5B_ru_v10epoch=0_step=20570', 'xglm-4.5B_ru_v10epoch=2', 'xglm-4.5B_ru_v10epoch=0_step=41141', 'xglm-4.5B_ru_v10epoch=6_step=41141', 'xglm-4.5B_ru_v10epoch=5_step=102854', 'xglm-4.5B_ru_v10epoch=5_step=20570', 'xglm-4.5B_ru_v10epoch=0_step=61712', 'xglm-4.5B_ru_v10epoch=5_step=61712', 'xglm-4.5B_ru_v10epoch=0', 'xglm-4.5B_ru_v10epoch=6_step=61712', 'xglm-4.5B_ru_v10epoch=5', 'xglm-4.5B_ru_v10epoch=3_step=82283', 'xglm-4.5B_ru_v10epoch=4']\n",
    "Best model=xglm-4.5B_ru_v10epoch=3, Compare model=xglm-4.5B_ru_v10epoch=5_step=82283, Winner=xglm-4.5B_ru_v10epoch=3\n",
    "Best model=xglm-4.5B_ru_v10epoch=3, Compare model=xglm-4.5B_ru_v10epoch=0_step=82283, Winner=xglm-4.5B_ru_v10epoch=3\n",
    "Best model=xglm-4.5B_ru_v10epoch=3, Compare model=xglm-4.5B_ru_v10epoch=0_step=102854, Winner=SuperPosition\n",
    "Best model=xglm-4.5B_ru_v10epoch=3, Compare model=xglm-4.5B_ru_v10epoch=5_step=41141, Winner=xglm-4.5B_ru_v10epoch=3\n",
    "Best model=xglm-4.5B_ru_v10epoch=3, Compare model=xglm-4.5B_ru_v10epoch=6_step=20570, Winner=xglm-4.5B_ru_v10epoch=3\n",
    "Best model=xglm-4.5B_ru_v10epoch=3, Compare model=xglm-4.5B_ru_v10epoch=1, Winner=SuperPosition\n",
    "Best model=xglm-4.5B_ru_v10epoch=3, Compare model=xglm-4.5B_ru_v10epoch=0_step=20570, Winner=xglm-4.5B_ru_v10epoch=3\n",
    "Best model=xglm-4.5B_ru_v10epoch=3, Compare model=xglm-4.5B_ru_v10epoch=2, Winner=xglm-4.5B_ru_v10epoch=3\n",
    "Best model=xglm-4.5B_ru_v10epoch=3, Compare model=xglm-4.5B_ru_v10epoch=0_step=41141, Winner=xglm-4.5B_ru_v10epoch=3\n",
    "Best model=xglm-4.5B_ru_v10epoch=3, Compare model=xglm-4.5B_ru_v10epoch=6_step=41141, Winner=SuperPosition\n",
    "Best model=xglm-4.5B_ru_v10epoch=3, Compare model=xglm-4.5B_ru_v10epoch=5_step=102854, Winner=SuperPosition\n",
    "Best model=xglm-4.5B_ru_v10epoch=3, Compare model=xglm-4.5B_ru_v10epoch=5_step=20570, Winner=xglm-4.5B_ru_v10epoch=3\n",
    "Best model=xglm-4.5B_ru_v10epoch=3, Compare model=xglm-4.5B_ru_v10epoch=0_step=61712, Winner=xglm-4.5B_ru_v10epoch=3\n",
    "Best model=xglm-4.5B_ru_v10epoch=3, Compare model=xglm-4.5B_ru_v10epoch=5_step=61712, Winner=SuperPosition\n",
    "Best model=xglm-4.5B_ru_v10epoch=3, Compare model=xglm-4.5B_ru_v10epoch=0, Winner=SuperPosition\n",
    "Best model=xglm-4.5B_ru_v10epoch=3, Compare model=xglm-4.5B_ru_v10epoch=6_step=61712, Winner=xglm-4.5B_ru_v10epoch=3\n",
    "Best model=xglm-4.5B_ru_v10epoch=3, Compare model=xglm-4.5B_ru_v10epoch=5, Winner=SuperPosition\n",
    "Best model=xglm-4.5B_ru_v10epoch=3, Compare model=xglm-4.5B_ru_v10epoch=3_step=82283, Winner=SuperPosition\n",
    "Best model=xglm-4.5B_ru_v10epoch=3, Compare model=xglm-4.5B_ru_v10epoch=4, Winner=SuperPosition\n",
    "['xglm-4.5B_ru_v10epoch=0_step=61712', 'xglm-4.5B_ru_v10epoch=3', 'xglm-4.5B_ru_v10epoch=0_step=20570', 'xglm-4.5B_ru_v10epoch=6_step=41141', 'xglm-4.5B_ru_v10epoch=2', 'xglm-4.5B_ru_v10epoch=5_step=102854', 'xglm-4.5B_ru_v10epoch=5_step=61712', 'xglm-4.5B_ru_v10epoch=6_step=61712', 'xglm-4.5B_ru_v10epoch=5_step=41141', 'xglm-4.5B_ru_v10epoch=5_step=20570', 'xglm-4.5B_ru_v10epoch=1', 'xglm-4.5B_ru_v10epoch=0_step=41141', 'xglm-4.5B_ru_v10epoch=0', 'xglm-4.5B_ru_v10epoch=0_step=82283', 'xglm-4.5B_ru_v10epoch=5_step=82283', 'xglm-4.5B_ru_v10epoch=4', 'xglm-4.5B_ru_v10epoch=6_step=20570', 'xglm-4.5B_ru_v10epoch=0_step=102854', 'xglm-4.5B_ru_v10epoch=3_step=82283', 'xglm-4.5B_ru_v10epoch=5']\n",
    "Best model=xglm-4.5B_ru_v10epoch=0_step=61712, Compare model=xglm-4.5B_ru_v10epoch=3, Winner=xglm-4.5B_ru_v10epoch=3\n",
    "Best model=xglm-4.5B_ru_v10epoch=3, Compare model=xglm-4.5B_ru_v10epoch=0_step=20570, Winner=xglm-4.5B_ru_v10epoch=3\n",
    "Best model=xglm-4.5B_ru_v10epoch=3, Compare model=xglm-4.5B_ru_v10epoch=6_step=41141, Winner=SuperPosition\n",
    "Best model=xglm-4.5B_ru_v10epoch=3, Compare model=xglm-4.5B_ru_v10epoch=2, Winner=xglm-4.5B_ru_v10epoch=3\n",
    "Best model=xglm-4.5B_ru_v10epoch=3, Compare model=xglm-4.5B_ru_v10epoch=5_step=102854, Winner=xglm-4.5B_ru_v10epoch=3\n",
    "Best model=xglm-4.5B_ru_v10epoch=3, Compare model=xglm-4.5B_ru_v10epoch=5_step=61712, Winner=xglm-4.5B_ru_v10epoch=5_step=61712\n",
    "Best model=xglm-4.5B_ru_v10epoch=5_step=61712, Compare model=xglm-4.5B_ru_v10epoch=6_step=61712, Winner=SuperPosition\n",
    "Best model=xglm-4.5B_ru_v10epoch=5_step=61712, Compare model=xglm-4.5B_ru_v10epoch=5_step=41141, Winner=SuperPosition\n",
    "Best model=xglm-4.5B_ru_v10epoch=5_step=61712, Compare model=xglm-4.5B_ru_v10epoch=5_step=20570, Winner=SuperPosition\n",
    "Best model=xglm-4.5B_ru_v10epoch=5_step=61712, Compare model=xglm-4.5B_ru_v10epoch=1, Winner=SuperPosition\n",
    "Best model=xglm-4.5B_ru_v10epoch=5_step=61712, Compare model=xglm-4.5B_ru_v10epoch=0_step=41141, Winner=xglm-4.5B_ru_v10epoch=5_step=61712\n",
    "Best model=xglm-4.5B_ru_v10epoch=5_step=61712, Compare model=xglm-4.5B_ru_v10epoch=0, Winner=SuperPosition\n",
    "Best model=xglm-4.5B_ru_v10epoch=5_step=61712, Compare model=xglm-4.5B_ru_v10epoch=0_step=82283, Winner=xglm-4.5B_ru_v10epoch=5_step=61712\n",
    "Best model=xglm-4.5B_ru_v10epoch=5_step=61712, Compare model=xglm-4.5B_ru_v10epoch=5_step=82283, Winner=SuperPosition\n",
    "Best model=xglm-4.5B_ru_v10epoch=5_step=61712, Compare model=xglm-4.5B_ru_v10epoch=4, Winner=SuperPosition\n",
    "Best model=xglm-4.5B_ru_v10epoch=5_step=61712, Compare model=xglm-4.5B_ru_v10epoch=6_step=20570, Winner=Error\n",
    "Best model=xglm-4.5B_ru_v10epoch=5_step=61712, Compare model=xglm-4.5B_ru_v10epoch=0_step=102854, Winner=SuperPosition\n",
    "Best model=xglm-4.5B_ru_v10epoch=5_step=61712, Compare model=xglm-4.5B_ru_v10epoch=3_step=82283, Winner=SuperPosition\n",
    "Best model=xglm-4.5B_ru_v10epoch=5_step=61712, Compare model=xglm-4.5B_ru_v10epoch=5, Winner=SuperPosition\n",
    "best_model_name=xglm-4.5B_ru_v10epoch=1 0.5789473684210527\n",
    "best_model_name=xglm-4.5B_ru_v10epoch=3 0.47368421052631576\n",
    "best_model_name=xglm-4.5B_ru_v10epoch=5_step=61712 0.5789473684210527\n",
    "\n",
    "При суперпозиции заменяю лучшую модель на новую \n",
    "\n",
    "Human:\n",
    "Напишите краткое эссе на тему \"История развития компьютерной техники\".\n",
    "\n",
    "['xglm-4.5B_ru_v10epoch=1', 'xglm-4.5B_ru_v10epoch=6_step=41141', 'xglm-4.5B_ru_v10epoch=2', 'xglm-4.5B_ru_v10epoch=4', 'xglm-4.5B_ru_v10epoch=0_step=20570', 'xglm-4.5B_ru_v10epoch=5', 'xglm-4.5B_ru_v10epoch=0', 'xglm-4.5B_ru_v10epoch=6_step=20570', 'xglm-4.5B_ru_v10epoch=6_step=61712', 'xglm-4.5B_ru_v10epoch=5_step=82283', 'xglm-4.5B_ru_v10epoch=3_step=82283', 'xglm-4.5B_ru_v10epoch=5_step=102854', 'xglm-4.5B_ru_v10epoch=0_step=82283', 'xglm-4.5B_ru_v10epoch=5_step=61712', 'xglm-4.5B_ru_v10epoch=5_step=20570', 'xglm-4.5B_ru_v10epoch=5_step=41141', 'xglm-4.5B_ru_v10epoch=0_step=41141', 'xglm-4.5B_ru_v10epoch=0_step=61712', 'xglm-4.5B_ru_v10epoch=3', 'xglm-4.5B_ru_v10epoch=0_step=102854']\n",
    "Best model=xglm-4.5B_ru_v10epoch=1, Compare model=xglm-4.5B_ru_v10epoch=6_step=41141, Winner=xglm-4.5B_ru_v10epoch=6_step=41141\n",
    "Best model=xglm-4.5B_ru_v10epoch=6_step=41141, Compare model=xglm-4.5B_ru_v10epoch=2, Winner=SuperPosition\n",
    "Best model=xglm-4.5B_ru_v10epoch=2, Compare model=xglm-4.5B_ru_v10epoch=4, Winner=xglm-4.5B_ru_v10epoch=4\n",
    "Best model=xglm-4.5B_ru_v10epoch=4, Compare model=xglm-4.5B_ru_v10epoch=0_step=20570, Winner=xglm-4.5B_ru_v10epoch=4\n",
    "Best model=xglm-4.5B_ru_v10epoch=4, Compare model=xglm-4.5B_ru_v10epoch=5, Winner=xglm-4.5B_ru_v10epoch=4\n",
    "Best model=xglm-4.5B_ru_v10epoch=4, Compare model=xglm-4.5B_ru_v10epoch=0, Winner=xglm-4.5B_ru_v10epoch=0\n",
    "Best model=xglm-4.5B_ru_v10epoch=0, Compare model=xglm-4.5B_ru_v10epoch=6_step=20570, Winner=xglm-4.5B_ru_v10epoch=0\n",
    "Best model=xglm-4.5B_ru_v10epoch=0, Compare model=xglm-4.5B_ru_v10epoch=6_step=61712, Winner=xglm-4.5B_ru_v10epoch=0\n",
    "Best model=xglm-4.5B_ru_v10epoch=0, Compare model=xglm-4.5B_ru_v10epoch=5_step=82283, Winner=Error\n",
    "Best model=xglm-4.5B_ru_v10epoch=0, Compare model=xglm-4.5B_ru_v10epoch=3_step=82283, Winner=xglm-4.5B_ru_v10epoch=0\n",
    "Best model=xglm-4.5B_ru_v10epoch=0, Compare model=xglm-4.5B_ru_v10epoch=5_step=102854, Winner=SuperPosition\n",
    "Best model=xglm-4.5B_ru_v10epoch=5_step=102854, Compare model=xglm-4.5B_ru_v10epoch=0_step=82283, Winner=SuperPosition\n",
    "Best model=xglm-4.5B_ru_v10epoch=0_step=82283, Compare model=xglm-4.5B_ru_v10epoch=5_step=61712, Winner=xglm-4.5B_ru_v10epoch=0_step=82283\n",
    "Best model=xglm-4.5B_ru_v10epoch=0_step=82283, Compare model=xglm-4.5B_ru_v10epoch=5_step=20570, Winner=xglm-4.5B_ru_v10epoch=5_step=20570\n",
    "Best model=xglm-4.5B_ru_v10epoch=5_step=20570, Compare model=xglm-4.5B_ru_v10epoch=5_step=41141, Winner=xglm-4.5B_ru_v10epoch=5_step=20570\n",
    "Best model=xglm-4.5B_ru_v10epoch=5_step=20570, Compare model=xglm-4.5B_ru_v10epoch=0_step=41141, Winner=xglm-4.5B_ru_v10epoch=5_step=20570\n",
    "Best model=xglm-4.5B_ru_v10epoch=5_step=20570, Compare model=xglm-4.5B_ru_v10epoch=0_step=61712, Winner=xglm-4.5B_ru_v10epoch=5_step=20570\n",
    "Best model=xglm-4.5B_ru_v10epoch=5_step=20570, Compare model=xglm-4.5B_ru_v10epoch=3, Winner=SuperPosition\n",
    "Best model=xglm-4.5B_ru_v10epoch=3, Compare model=xglm-4.5B_ru_v10epoch=0_step=102854, Winner=xglm-4.5B_ru_v10epoch=0_step=102854\n",
    "['xglm-4.5B_ru_v10epoch=3', 'xglm-4.5B_ru_v10epoch=5_step=82283', 'xglm-4.5B_ru_v10epoch=0_step=82283', 'xglm-4.5B_ru_v10epoch=0_step=102854', 'xglm-4.5B_ru_v10epoch=5_step=41141', 'xglm-4.5B_ru_v10epoch=6_step=20570', 'xglm-4.5B_ru_v10epoch=1', 'xglm-4.5B_ru_v10epoch=0_step=20570', 'xglm-4.5B_ru_v10epoch=2', 'xglm-4.5B_ru_v10epoch=0_step=41141', 'xglm-4.5B_ru_v10epoch=6_step=41141', 'xglm-4.5B_ru_v10epoch=5_step=102854', 'xglm-4.5B_ru_v10epoch=5_step=20570', 'xglm-4.5B_ru_v10epoch=0_step=61712', 'xglm-4.5B_ru_v10epoch=5_step=61712', 'xglm-4.5B_ru_v10epoch=0', 'xglm-4.5B_ru_v10epoch=6_step=61712', 'xglm-4.5B_ru_v10epoch=5', 'xglm-4.5B_ru_v10epoch=3_step=82283', 'xglm-4.5B_ru_v10epoch=4']\n",
    "Best model=xglm-4.5B_ru_v10epoch=3, Compare model=xglm-4.5B_ru_v10epoch=5_step=82283, Winner=SuperPosition\n",
    "Best model=xglm-4.5B_ru_v10epoch=5_step=82283, Compare model=xglm-4.5B_ru_v10epoch=0_step=82283, Winner=SuperPosition\n",
    "Best model=xglm-4.5B_ru_v10epoch=0_step=82283, Compare model=xglm-4.5B_ru_v10epoch=0_step=102854, Winner=xglm-4.5B_ru_v10epoch=0_step=102854\n",
    "Best model=xglm-4.5B_ru_v10epoch=0_step=102854, Compare model=xglm-4.5B_ru_v10epoch=5_step=41141, Winner=xglm-4.5B_ru_v10epoch=0_step=102854\n",
    "Best model=xglm-4.5B_ru_v10epoch=0_step=102854, Compare model=xglm-4.5B_ru_v10epoch=6_step=20570, Winner=xglm-4.5B_ru_v10epoch=0_step=102854\n",
    "Best model=xglm-4.5B_ru_v10epoch=0_step=102854, Compare model=xglm-4.5B_ru_v10epoch=1, Winner=xglm-4.5B_ru_v10epoch=0_step=102854\n",
    "Best model=xglm-4.5B_ru_v10epoch=0_step=102854, Compare model=xglm-4.5B_ru_v10epoch=0_step=20570, Winner=xglm-4.5B_ru_v10epoch=0_step=102854\n",
    "Best model=xglm-4.5B_ru_v10epoch=0_step=102854, Compare model=xglm-4.5B_ru_v10epoch=2, Winner=SuperPosition\n",
    "Best model=xglm-4.5B_ru_v10epoch=2, Compare model=xglm-4.5B_ru_v10epoch=0_step=41141, Winner=xglm-4.5B_ru_v10epoch=2\n",
    "Best model=xglm-4.5B_ru_v10epoch=2, Compare model=xglm-4.5B_ru_v10epoch=6_step=41141, Winner=xglm-4.5B_ru_v10epoch=6_step=41141\n",
    "Best model=xglm-4.5B_ru_v10epoch=6_step=41141, Compare model=xglm-4.5B_ru_v10epoch=5_step=102854, Winner=xglm-4.5B_ru_v10epoch=6_step=41141\n",
    "Best model=xglm-4.5B_ru_v10epoch=6_step=41141, Compare model=xglm-4.5B_ru_v10epoch=5_step=20570, Winner=SuperPosition\n",
    "Best model=xglm-4.5B_ru_v10epoch=5_step=20570, Compare model=xglm-4.5B_ru_v10epoch=0_step=61712, Winner=xglm-4.5B_ru_v10epoch=5_step=20570\n",
    "Best model=xglm-4.5B_ru_v10epoch=5_step=20570, Compare model=xglm-4.5B_ru_v10epoch=5_step=61712, Winner=xglm-4.5B_ru_v10epoch=5_step=20570\n",
    "Best model=xglm-4.5B_ru_v10epoch=5_step=20570, Compare model=xglm-4.5B_ru_v10epoch=0, Winner=SuperPosition\n",
    "Best model=xglm-4.5B_ru_v10epoch=0, Compare model=xglm-4.5B_ru_v10epoch=6_step=61712, Winner=xglm-4.5B_ru_v10epoch=0\n",
    "Best model=xglm-4.5B_ru_v10epoch=0, Compare model=xglm-4.5B_ru_v10epoch=5, Winner=SuperPosition\n",
    "Best model=xglm-4.5B_ru_v10epoch=5, Compare model=xglm-4.5B_ru_v10epoch=3_step=82283, Winner=xglm-4.5B_ru_v10epoch=5\n",
    "Best model=xglm-4.5B_ru_v10epoch=5, Compare model=xglm-4.5B_ru_v10epoch=4, Winner=SuperPosition\n",
    "['xglm-4.5B_ru_v10epoch=0_step=61712', 'xglm-4.5B_ru_v10epoch=3', 'xglm-4.5B_ru_v10epoch=0_step=20570', 'xglm-4.5B_ru_v10epoch=6_step=41141', 'xglm-4.5B_ru_v10epoch=2', 'xglm-4.5B_ru_v10epoch=5_step=102854', 'xglm-4.5B_ru_v10epoch=5_step=61712', 'xglm-4.5B_ru_v10epoch=6_step=61712', 'xglm-4.5B_ru_v10epoch=5_step=41141', 'xglm-4.5B_ru_v10epoch=5_step=20570', 'xglm-4.5B_ru_v10epoch=1', 'xglm-4.5B_ru_v10epoch=0_step=41141', 'xglm-4.5B_ru_v10epoch=0', 'xglm-4.5B_ru_v10epoch=0_step=82283', 'xglm-4.5B_ru_v10epoch=5_step=82283', 'xglm-4.5B_ru_v10epoch=4', 'xglm-4.5B_ru_v10epoch=6_step=20570', 'xglm-4.5B_ru_v10epoch=0_step=102854', 'xglm-4.5B_ru_v10epoch=3_step=82283', 'xglm-4.5B_ru_v10epoch=5']\n",
    "Best model=xglm-4.5B_ru_v10epoch=0_step=61712, Compare model=xglm-4.5B_ru_v10epoch=3, Winner=SuperPosition\n",
    "Best model=xglm-4.5B_ru_v10epoch=3, Compare model=xglm-4.5B_ru_v10epoch=0_step=20570, Winner=xglm-4.5B_ru_v10epoch=3\n",
    "Best model=xglm-4.5B_ru_v10epoch=3, Compare model=xglm-4.5B_ru_v10epoch=6_step=41141, Winner=xglm-4.5B_ru_v10epoch=6_step=41141\n",
    "Best model=xglm-4.5B_ru_v10epoch=6_step=41141, Compare model=xglm-4.5B_ru_v10epoch=2, Winner=xglm-4.5B_ru_v10epoch=6_step=41141\n",
    "Best model=xglm-4.5B_ru_v10epoch=6_step=41141, Compare model=xglm-4.5B_ru_v10epoch=5_step=102854, Winner=SuperPosition\n",
    "Best model=xglm-4.5B_ru_v10epoch=5_step=102854, Compare model=xglm-4.5B_ru_v10epoch=5_step=61712, Winner=xglm-4.5B_ru_v10epoch=5_step=61712\n",
    "Best model=xglm-4.5B_ru_v10epoch=5_step=61712, Compare model=xglm-4.5B_ru_v10epoch=6_step=61712, Winner=SuperPosition\n",
    "Best model=xglm-4.5B_ru_v10epoch=6_step=61712, Compare model=xglm-4.5B_ru_v10epoch=5_step=41141, Winner=xglm-4.5B_ru_v10epoch=6_step=61712\n",
    "Best model=xglm-4.5B_ru_v10epoch=6_step=61712, Compare model=xglm-4.5B_ru_v10epoch=5_step=20570, Winner=xglm-4.5B_ru_v10epoch=5_step=20570\n",
    "Best model=xglm-4.5B_ru_v10epoch=5_step=20570, Compare model=xglm-4.5B_ru_v10epoch=1, Winner=SuperPosition\n",
    "Best model=xglm-4.5B_ru_v10epoch=1, Compare model=xglm-4.5B_ru_v10epoch=0_step=41141, Winner=SuperPosition\n",
    "Best model=xglm-4.5B_ru_v10epoch=0_step=41141, Compare model=xglm-4.5B_ru_v10epoch=0, Winner=SuperPosition\n",
    "Best model=xglm-4.5B_ru_v10epoch=0, Compare model=xglm-4.5B_ru_v10epoch=0_step=82283, Winner=xglm-4.5B_ru_v10epoch=0\n",
    "Best model=xglm-4.5B_ru_v10epoch=0, Compare model=xglm-4.5B_ru_v10epoch=5_step=82283, Winner=xglm-4.5B_ru_v10epoch=0\n",
    "Best model=xglm-4.5B_ru_v10epoch=0, Compare model=xglm-4.5B_ru_v10epoch=4, Winner=SuperPosition\n",
    "Best model=xglm-4.5B_ru_v10epoch=4, Compare model=xglm-4.5B_ru_v10epoch=6_step=20570, Winner=xglm-4.5B_ru_v10epoch=4\n",
    "Best model=xglm-4.5B_ru_v10epoch=4, Compare model=xglm-4.5B_ru_v10epoch=0_step=102854, Winner=xglm-4.5B_ru_v10epoch=4\n",
    "Best model=xglm-4.5B_ru_v10epoch=4, Compare model=xglm-4.5B_ru_v10epoch=3_step=82283, Winner=SuperPosition\n",
    "Best model=xglm-4.5B_ru_v10epoch=3_step=82283, Compare model=xglm-4.5B_ru_v10epoch=5, Winner=SuperPosition\n",
    "best_model_name=xglm-4.5B_ru_v10epoch=0 0.21052631578947367\n",
    "best_model_name=xglm-4.5B_ru_v10epoch=0_step=102854 0.3684210526315789\n",
    "best_model_name=xglm-4.5B_ru_v10epoch=0 0.47368421052631576\n",
    "\n",
    "Human:\n",
    "Напиши пять примеров химических элементов, начинающихся на букву \"С\".\n",
    "\n",
    "['xglm-4.5B_ru_v10epoch=1', 'xglm-4.5B_ru_v10epoch=6_step=41141', 'xglm-4.5B_ru_v10epoch=2', 'xglm-4.5B_ru_v10epoch=4', 'xglm-4.5B_ru_v10epoch=0_step=20570', 'xglm-4.5B_ru_v10epoch=5', 'xglm-4.5B_ru_v10epoch=0', 'xglm-4.5B_ru_v10epoch=6_step=20570', 'xglm-4.5B_ru_v10epoch=6_step=61712', 'xglm-4.5B_ru_v10epoch=5_step=82283', 'xglm-4.5B_ru_v10epoch=3_step=82283', 'xglm-4.5B_ru_v10epoch=5_step=102854', 'xglm-4.5B_ru_v10epoch=0_step=82283', 'xglm-4.5B_ru_v10epoch=5_step=61712', 'xglm-4.5B_ru_v10epoch=5_step=20570', 'xglm-4.5B_ru_v10epoch=5_step=41141', 'xglm-4.5B_ru_v10epoch=0_step=41141', 'xglm-4.5B_ru_v10epoch=0_step=61712', 'xglm-4.5B_ru_v10epoch=3', 'xglm-4.5B_ru_v10epoch=0_step=102854']\n",
    "Best model=xglm-4.5B_ru_v10epoch=1, Compare model=xglm-4.5B_ru_v10epoch=6_step=41141, Winner=SuperPosition\n",
    "Best model=xglm-4.5B_ru_v10epoch=6_step=41141, Compare model=xglm-4.5B_ru_v10epoch=2, Winner=SuperPosition\n",
    "Best model=xglm-4.5B_ru_v10epoch=2, Compare model=xglm-4.5B_ru_v10epoch=4, Winner=xglm-4.5B_ru_v10epoch=4\n",
    "Best model=xglm-4.5B_ru_v10epoch=4, Compare model=xglm-4.5B_ru_v10epoch=0_step=20570, Winner=xglm-4.5B_ru_v10epoch=4\n",
    "Best model=xglm-4.5B_ru_v10epoch=4, Compare model=xglm-4.5B_ru_v10epoch=5, Winner=SuperPosition\n",
    "Best model=xglm-4.5B_ru_v10epoch=5, Compare model=xglm-4.5B_ru_v10epoch=0, Winner=SuperPosition\n",
    "Best model=xglm-4.5B_ru_v10epoch=0, Compare model=xglm-4.5B_ru_v10epoch=6_step=20570, Winner=Error\n",
    "Best model=xglm-4.5B_ru_v10epoch=0, Compare model=xglm-4.5B_ru_v10epoch=6_step=61712, Winner=SuperPosition\n",
    "Best model=xglm-4.5B_ru_v10epoch=6_step=61712, Compare model=xglm-4.5B_ru_v10epoch=5_step=82283, Winner=xglm-4.5B_ru_v10epoch=5_step=82283\n",
    "Best model=xglm-4.5B_ru_v10epoch=5_step=82283, Compare model=xglm-4.5B_ru_v10epoch=3_step=82283, Winner=xglm-4.5B_ru_v10epoch=3_step=82283\n",
    "Best model=xglm-4.5B_ru_v10epoch=3_step=82283, Compare model=xglm-4.5B_ru_v10epoch=5_step=102854, Winner=SuperPosition\n",
    "Best model=xglm-4.5B_ru_v10epoch=5_step=102854, Compare model=xglm-4.5B_ru_v10epoch=0_step=82283, Winner=SuperPosition\n",
    "Best model=xglm-4.5B_ru_v10epoch=0_step=82283, Compare model=xglm-4.5B_ru_v10epoch=5_step=61712, Winner=SuperPosition\n",
    "Best model=xglm-4.5B_ru_v10epoch=5_step=61712, Compare model=xglm-4.5B_ru_v10epoch=5_step=20570, Winner=SuperPosition\n",
    "Best model=xglm-4.5B_ru_v10epoch=5_step=20570, Compare model=xglm-4.5B_ru_v10epoch=5_step=41141, Winner=SuperPosition\n",
    "Best model=xglm-4.5B_ru_v10epoch=5_step=41141, Compare model=xglm-4.5B_ru_v10epoch=0_step=41141, Winner=xglm-4.5B_ru_v10epoch=5_step=41141\n",
    "Best model=xglm-4.5B_ru_v10epoch=5_step=41141, Compare model=xglm-4.5B_ru_v10epoch=0_step=61712, Winner=xglm-4.5B_ru_v10epoch=5_step=41141\n",
    "Best model=xglm-4.5B_ru_v10epoch=5_step=41141, Compare model=xglm-4.5B_ru_v10epoch=3, Winner=xglm-4.5B_ru_v10epoch=3\n",
    "Best model=xglm-4.5B_ru_v10epoch=3, Compare model=xglm-4.5B_ru_v10epoch=0_step=102854, Winner=SuperPosition\n",
    "['xglm-4.5B_ru_v10epoch=3', 'xglm-4.5B_ru_v10epoch=5_step=82283', 'xglm-4.5B_ru_v10epoch=0_step=82283', 'xglm-4.5B_ru_v10epoch=0_step=102854', 'xglm-4.5B_ru_v10epoch=5_step=41141', 'xglm-4.5B_ru_v10epoch=6_step=20570', 'xglm-4.5B_ru_v10epoch=1', 'xglm-4.5B_ru_v10epoch=0_step=20570', 'xglm-4.5B_ru_v10epoch=2', 'xglm-4.5B_ru_v10epoch=0_step=41141', 'xglm-4.5B_ru_v10epoch=6_step=41141', 'xglm-4.5B_ru_v10epoch=5_step=102854', 'xglm-4.5B_ru_v10epoch=5_step=20570', 'xglm-4.5B_ru_v10epoch=0_step=61712', 'xglm-4.5B_ru_v10epoch=5_step=61712', 'xglm-4.5B_ru_v10epoch=0', 'xglm-4.5B_ru_v10epoch=6_step=61712', 'xglm-4.5B_ru_v10epoch=5', 'xglm-4.5B_ru_v10epoch=3_step=82283', 'xglm-4.5B_ru_v10epoch=4']\n",
    "Best model=xglm-4.5B_ru_v10epoch=3, Compare model=xglm-4.5B_ru_v10epoch=5_step=82283, Winner=xglm-4.5B_ru_v10epoch=3\n",
    "Best model=xglm-4.5B_ru_v10epoch=3, Compare model=xglm-4.5B_ru_v10epoch=0_step=82283, Winner=Error\n",
    "Best model=xglm-4.5B_ru_v10epoch=3, Compare model=xglm-4.5B_ru_v10epoch=0_step=102854, Winner=xglm-4.5B_ru_v10epoch=3\n",
    "Best model=xglm-4.5B_ru_v10epoch=3, Compare model=xglm-4.5B_ru_v10epoch=5_step=41141, Winner=xglm-4.5B_ru_v10epoch=3\n",
    "Best model=xglm-4.5B_ru_v10epoch=3, Compare model=xglm-4.5B_ru_v10epoch=6_step=20570, Winner=xglm-4.5B_ru_v10epoch=3\n",
    "Best model=xglm-4.5B_ru_v10epoch=3, Compare model=xglm-4.5B_ru_v10epoch=1, Winner=SuperPosition\n",
    "Best model=xglm-4.5B_ru_v10epoch=1, Compare model=xglm-4.5B_ru_v10epoch=0_step=20570, Winner=xglm-4.5B_ru_v10epoch=1\n",
    "Best model=xglm-4.5B_ru_v10epoch=1, Compare model=xglm-4.5B_ru_v10epoch=2, Winner=SuperPosition\n",
    "Best model=xglm-4.5B_ru_v10epoch=2, Compare model=xglm-4.5B_ru_v10epoch=0_step=41141, Winner=xglm-4.5B_ru_v10epoch=2\n",
    "Best model=xglm-4.5B_ru_v10epoch=2, Compare model=xglm-4.5B_ru_v10epoch=6_step=41141, Winner=xglm-4.5B_ru_v10epoch=2\n",
    "Best model=xglm-4.5B_ru_v10epoch=2, Compare model=xglm-4.5B_ru_v10epoch=5_step=102854, Winner=SuperPosition\n",
    "Best model=xglm-4.5B_ru_v10epoch=5_step=102854, Compare model=xglm-4.5B_ru_v10epoch=5_step=20570, Winner=SuperPosition\n",
    "Best model=xglm-4.5B_ru_v10epoch=5_step=20570, Compare model=xglm-4.5B_ru_v10epoch=0_step=61712, Winner=xglm-4.5B_ru_v10epoch=5_step=20570\n",
    "Best model=xglm-4.5B_ru_v10epoch=5_step=20570, Compare model=xglm-4.5B_ru_v10epoch=5_step=61712, Winner=SuperPosition\n",
    "Best model=xglm-4.5B_ru_v10epoch=5_step=61712, Compare model=xglm-4.5B_ru_v10epoch=0, Winner=SuperPosition\n",
    "Best model=xglm-4.5B_ru_v10epoch=0, Compare model=xglm-4.5B_ru_v10epoch=6_step=61712, Winner=SuperPosition\n",
    "Best model=xglm-4.5B_ru_v10epoch=6_step=61712, Compare model=xglm-4.5B_ru_v10epoch=5, Winner=SuperPosition\n",
    "Best model=xglm-4.5B_ru_v10epoch=5, Compare model=xglm-4.5B_ru_v10epoch=3_step=82283, Winner=SuperPosition\n",
    "Best model=xglm-4.5B_ru_v10epoch=3_step=82283, Compare model=xglm-4.5B_ru_v10epoch=4, Winner=SuperPosition\n",
    "['xglm-4.5B_ru_v10epoch=0_step=61712', 'xglm-4.5B_ru_v10epoch=3', 'xglm-4.5B_ru_v10epoch=0_step=20570', 'xglm-4.5B_ru_v10epoch=6_step=41141', 'xglm-4.5B_ru_v10epoch=2', 'xglm-4.5B_ru_v10epoch=5_step=102854', 'xglm-4.5B_ru_v10epoch=5_step=61712', 'xglm-4.5B_ru_v10epoch=6_step=61712', 'xglm-4.5B_ru_v10epoch=5_step=41141', 'xglm-4.5B_ru_v10epoch=5_step=20570', 'xglm-4.5B_ru_v10epoch=1', 'xglm-4.5B_ru_v10epoch=0_step=41141', 'xglm-4.5B_ru_v10epoch=0', 'xglm-4.5B_ru_v10epoch=0_step=82283', 'xglm-4.5B_ru_v10epoch=5_step=82283', 'xglm-4.5B_ru_v10epoch=4', 'xglm-4.5B_ru_v10epoch=6_step=20570', 'xglm-4.5B_ru_v10epoch=0_step=102854', 'xglm-4.5B_ru_v10epoch=3_step=82283', 'xglm-4.5B_ru_v10epoch=5']\n",
    "Best model=xglm-4.5B_ru_v10epoch=0_step=61712, Compare model=xglm-4.5B_ru_v10epoch=3, Winner=xglm-4.5B_ru_v10epoch=3\n",
    "Best model=xglm-4.5B_ru_v10epoch=3, Compare model=xglm-4.5B_ru_v10epoch=0_step=20570, Winner=xglm-4.5B_ru_v10epoch=3\n",
    "Best model=xglm-4.5B_ru_v10epoch=3, Compare model=xglm-4.5B_ru_v10epoch=6_step=41141, Winner=SuperPosition\n",
    "Best model=xglm-4.5B_ru_v10epoch=6_step=41141, Compare model=xglm-4.5B_ru_v10epoch=2, Winner=Error\n",
    "Best model=xglm-4.5B_ru_v10epoch=6_step=41141, Compare model=xglm-4.5B_ru_v10epoch=5_step=102854, Winner=SuperPosition\n",
    "Best model=xglm-4.5B_ru_v10epoch=5_step=102854, Compare model=xglm-4.5B_ru_v10epoch=5_step=61712, Winner=SuperPosition\n",
    "Best model=xglm-4.5B_ru_v10epoch=5_step=61712, Compare model=xglm-4.5B_ru_v10epoch=6_step=61712, Winner=xglm-4.5B_ru_v10epoch=5_step=61712\n",
    "Best model=xglm-4.5B_ru_v10epoch=5_step=61712, Compare model=xglm-4.5B_ru_v10epoch=5_step=41141, Winner=xglm-4.5B_ru_v10epoch=5_step=61712\n",
    "Best model=xglm-4.5B_ru_v10epoch=5_step=61712, Compare model=xglm-4.5B_ru_v10epoch=5_step=20570, Winner=xglm-4.5B_ru_v10epoch=5_step=20570\n",
    "Best model=xglm-4.5B_ru_v10epoch=5_step=20570, Compare model=xglm-4.5B_ru_v10epoch=1, Winner=SuperPosition\n",
    "Best model=xglm-4.5B_ru_v10epoch=1, Compare model=xglm-4.5B_ru_v10epoch=0_step=41141, Winner=xglm-4.5B_ru_v10epoch=1\n",
    "Best model=xglm-4.5B_ru_v10epoch=1, Compare model=xglm-4.5B_ru_v10epoch=0, Winner=xglm-4.5B_ru_v10epoch=0\n",
    "Best model=xglm-4.5B_ru_v10epoch=0, Compare model=xglm-4.5B_ru_v10epoch=0_step=82283, Winner=Error\n",
    "Best model=xglm-4.5B_ru_v10epoch=0, Compare model=xglm-4.5B_ru_v10epoch=5_step=82283, Winner=SuperPosition\n",
    "Best model=xglm-4.5B_ru_v10epoch=5_step=82283, Compare model=xglm-4.5B_ru_v10epoch=4, Winner=xglm-4.5B_ru_v10epoch=4\n",
    "Best model=xglm-4.5B_ru_v10epoch=4, Compare model=xglm-4.5B_ru_v10epoch=6_step=20570, Winner=xglm-4.5B_ru_v10epoch=4\n",
    "Best model=xglm-4.5B_ru_v10epoch=4, Compare model=xglm-4.5B_ru_v10epoch=0_step=102854, Winner=xglm-4.5B_ru_v10epoch=4\n",
    "Best model=xglm-4.5B_ru_v10epoch=4, Compare model=xglm-4.5B_ru_v10epoch=3_step=82283, Winner=SuperPosition\n",
    "Best model=xglm-4.5B_ru_v10epoch=3_step=82283, Compare model=xglm-4.5B_ru_v10epoch=5, Winner=SuperPosition\n",
    "best_model_name=xglm-4.5B_ru_v10epoch=4 0.5789473684210527\n",
    "best_model_name=xglm-4.5B_ru_v10epoch=3 0.5263157894736842\n",
    "best_model_name=xglm-4.5B_ru_v10epoch=4 0.3684210526315789\n",
    "\n",
    "Изменил параметр температуры, равным 0\n",
    "['xglm-4.5B_ru_v10epoch=1', 'xglm-4.5B_ru_v10epoch=6_step=41141', 'xglm-4.5B_ru_v10epoch=2', 'xglm-4.5B_ru_v10epoch=4', 'xglm-4.5B_ru_v10epoch=0_step=20570', 'xglm-4.5B_ru_v10epoch=5', 'xglm-4.5B_ru_v10epoch=0', 'xglm-4.5B_ru_v10epoch=6_step=20570', 'xglm-4.5B_ru_v10epoch=6_step=61712', 'xglm-4.5B_ru_v10epoch=5_step=82283', 'xglm-4.5B_ru_v10epoch=3_step=82283', 'xglm-4.5B_ru_v10epoch=5_step=102854', 'xglm-4.5B_ru_v10epoch=0_step=82283', 'xglm-4.5B_ru_v10epoch=5_step=61712', 'xglm-4.5B_ru_v10epoch=5_step=20570', 'xglm-4.5B_ru_v10epoch=5_step=41141', 'xglm-4.5B_ru_v10epoch=0_step=41141', 'xglm-4.5B_ru_v10epoch=0_step=61712', 'xglm-4.5B_ru_v10epoch=3', 'xglm-4.5B_ru_v10epoch=0_step=102854']\n",
    "Best model=xglm-4.5B_ru_v10epoch=1, Compare model=xglm-4.5B_ru_v10epoch=6_step=41141, Winner=SuperPosition\n",
    "Best model=xglm-4.5B_ru_v10epoch=6_step=41141, Compare model=xglm-4.5B_ru_v10epoch=2, Winner=xglm-4.5B_ru_v10epoch=2\n",
    "Best model=xglm-4.5B_ru_v10epoch=2, Compare model=xglm-4.5B_ru_v10epoch=4, Winner=SuperPosition\n",
    "Best model=xglm-4.5B_ru_v10epoch=4, Compare model=xglm-4.5B_ru_v10epoch=0_step=20570, Winner=xglm-4.5B_ru_v10epoch=4\n",
    "Best model=xglm-4.5B_ru_v10epoch=4, Compare model=xglm-4.5B_ru_v10epoch=5, Winner=SuperPosition\n",
    "Best model=xglm-4.5B_ru_v10epoch=5, Compare model=xglm-4.5B_ru_v10epoch=0, Winner=SuperPosition\n",
    "Best model=xglm-4.5B_ru_v10epoch=0, Compare model=xglm-4.5B_ru_v10epoch=6_step=20570, Winner=xglm-4.5B_ru_v10epoch=0\n",
    "Best model=xglm-4.5B_ru_v10epoch=0, Compare model=xglm-4.5B_ru_v10epoch=6_step=61712, Winner=SuperPosition\n",
    "Best model=xglm-4.5B_ru_v10epoch=6_step=61712, Compare model=xglm-4.5B_ru_v10epoch=5_step=82283, Winner=SuperPosition\n",
    "Best model=xglm-4.5B_ru_v10epoch=5_step=82283, Compare model=xglm-4.5B_ru_v10epoch=3_step=82283, Winner=SuperPosition\n",
    "Best model=xglm-4.5B_ru_v10epoch=3_step=82283, Compare model=xglm-4.5B_ru_v10epoch=5_step=102854, Winner=SuperPosition\n",
    "Best model=xglm-4.5B_ru_v10epoch=5_step=102854, Compare model=xglm-4.5B_ru_v10epoch=0_step=82283, Winner=SuperPosition\n",
    "Best model=xglm-4.5B_ru_v10epoch=0_step=82283, Compare model=xglm-4.5B_ru_v10epoch=5_step=61712, Winner=SuperPosition\n",
    "Best model=xglm-4.5B_ru_v10epoch=5_step=61712, Compare model=xglm-4.5B_ru_v10epoch=5_step=20570, Winner=SuperPosition\n",
    "Best model=xglm-4.5B_ru_v10epoch=5_step=20570, Compare model=xglm-4.5B_ru_v10epoch=5_step=41141, Winner=SuperPosition\n",
    "Best model=xglm-4.5B_ru_v10epoch=5_step=41141, Compare model=xglm-4.5B_ru_v10epoch=0_step=41141, Winner=SuperPosition\n",
    "Best model=xglm-4.5B_ru_v10epoch=0_step=41141, Compare model=xglm-4.5B_ru_v10epoch=0_step=61712, Winner=xglm-4.5B_ru_v10epoch=0_step=41141\n",
    "Best model=xglm-4.5B_ru_v10epoch=0_step=41141, Compare model=xglm-4.5B_ru_v10epoch=3, Winner=xglm-4.5B_ru_v10epoch=3\n",
    "Best model=xglm-4.5B_ru_v10epoch=3, Compare model=xglm-4.5B_ru_v10epoch=0_step=102854, Winner=SuperPosition\n",
    "['xglm-4.5B_ru_v10epoch=3', 'xglm-4.5B_ru_v10epoch=5_step=82283', 'xglm-4.5B_ru_v10epoch=0_step=82283', 'xglm-4.5B_ru_v10epoch=0_step=102854', 'xglm-4.5B_ru_v10epoch=5_step=41141', 'xglm-4.5B_ru_v10epoch=6_step=20570', 'xglm-4.5B_ru_v10epoch=1', 'xglm-4.5B_ru_v10epoch=0_step=20570', 'xglm-4.5B_ru_v10epoch=2', 'xglm-4.5B_ru_v10epoch=0_step=41141', 'xglm-4.5B_ru_v10epoch=6_step=41141', 'xglm-4.5B_ru_v10epoch=5_step=102854', 'xglm-4.5B_ru_v10epoch=5_step=20570', 'xglm-4.5B_ru_v10epoch=0_step=61712', 'xglm-4.5B_ru_v10epoch=5_step=61712', 'xglm-4.5B_ru_v10epoch=0', 'xglm-4.5B_ru_v10epoch=6_step=61712', 'xglm-4.5B_ru_v10epoch=5', 'xglm-4.5B_ru_v10epoch=3_step=82283', 'xglm-4.5B_ru_v10epoch=4']\n",
    "Best model=xglm-4.5B_ru_v10epoch=3, Compare model=xglm-4.5B_ru_v10epoch=5_step=82283, Winner=xglm-4.5B_ru_v10epoch=3\n",
    "Best model=xglm-4.5B_ru_v10epoch=3, Compare model=xglm-4.5B_ru_v10epoch=0_step=82283, Winner=xglm-4.5B_ru_v10epoch=3\n",
    "Best model=xglm-4.5B_ru_v10epoch=3, Compare model=xglm-4.5B_ru_v10epoch=0_step=102854, Winner=SuperPosition\n",
    "Best model=xglm-4.5B_ru_v10epoch=0_step=102854, Compare model=xglm-4.5B_ru_v10epoch=5_step=41141, Winner=SuperPosition\n",
    "Best model=xglm-4.5B_ru_v10epoch=5_step=41141, Compare model=xglm-4.5B_ru_v10epoch=6_step=20570, Winner=xglm-4.5B_ru_v10epoch=5_step=41141\n",
    "Best model=xglm-4.5B_ru_v10epoch=5_step=41141, Compare model=xglm-4.5B_ru_v10epoch=1, Winner=SuperPosition\n",
    "Best model=xglm-4.5B_ru_v10epoch=1, Compare model=xglm-4.5B_ru_v10epoch=0_step=20570, Winner=xglm-4.5B_ru_v10epoch=1\n",
    "Best model=xglm-4.5B_ru_v10epoch=1, Compare model=xglm-4.5B_ru_v10epoch=2, Winner=SuperPosition\n",
    "Best model=xglm-4.5B_ru_v10epoch=2, Compare model=xglm-4.5B_ru_v10epoch=0_step=41141, Winner=xglm-4.5B_ru_v10epoch=2\n",
    "Best model=xglm-4.5B_ru_v10epoch=2, Compare model=xglm-4.5B_ru_v10epoch=6_step=41141, Winner=xglm-4.5B_ru_v10epoch=2\n",
    "Best model=xglm-4.5B_ru_v10epoch=2, Compare model=xglm-4.5B_ru_v10epoch=5_step=102854, Winner=SuperPosition\n",
    "Best model=xglm-4.5B_ru_v10epoch=5_step=102854, Compare model=xglm-4.5B_ru_v10epoch=5_step=20570, Winner=SuperPosition\n",
    "Best model=xglm-4.5B_ru_v10epoch=5_step=20570, Compare model=xglm-4.5B_ru_v10epoch=0_step=61712, Winner=xglm-4.5B_ru_v10epoch=5_step=20570\n",
    "Best model=xglm-4.5B_ru_v10epoch=5_step=20570, Compare model=xglm-4.5B_ru_v10epoch=5_step=61712, Winner=SuperPosition\n",
    "Best model=xglm-4.5B_ru_v10epoch=5_step=61712, Compare model=xglm-4.5B_ru_v10epoch=0, Winner=SuperPosition\n",
    "Best model=xglm-4.5B_ru_v10epoch=0, Compare model=xglm-4.5B_ru_v10epoch=6_step=61712, Winner=SuperPosition\n",
    "Best model=xglm-4.5B_ru_v10epoch=6_step=61712, Compare model=xglm-4.5B_ru_v10epoch=5, Winner=SuperPosition\n",
    "Best model=xglm-4.5B_ru_v10epoch=5, Compare model=xglm-4.5B_ru_v10epoch=3_step=82283, Winner=SuperPosition\n",
    "Best model=xglm-4.5B_ru_v10epoch=3_step=82283, Compare model=xglm-4.5B_ru_v10epoch=4, Winner=SuperPosition\n",
    "['xglm-4.5B_ru_v10epoch=0_step=61712', 'xglm-4.5B_ru_v10epoch=3', 'xglm-4.5B_ru_v10epoch=0_step=20570', 'xglm-4.5B_ru_v10epoch=6_step=41141', 'xglm-4.5B_ru_v10epoch=2', 'xglm-4.5B_ru_v10epoch=5_step=102854', 'xglm-4.5B_ru_v10epoch=5_step=61712', 'xglm-4.5B_ru_v10epoch=6_step=61712', 'xglm-4.5B_ru_v10epoch=5_step=41141', 'xglm-4.5B_ru_v10epoch=5_step=20570', 'xglm-4.5B_ru_v10epoch=1', 'xglm-4.5B_ru_v10epoch=0_step=41141', 'xglm-4.5B_ru_v10epoch=0', 'xglm-4.5B_ru_v10epoch=0_step=82283', 'xglm-4.5B_ru_v10epoch=5_step=82283', 'xglm-4.5B_ru_v10epoch=4', 'xglm-4.5B_ru_v10epoch=6_step=20570', 'xglm-4.5B_ru_v10epoch=0_step=102854', 'xglm-4.5B_ru_v10epoch=3_step=82283', 'xglm-4.5B_ru_v10epoch=5']\n",
    "Best model=xglm-4.5B_ru_v10epoch=0_step=61712, Compare model=xglm-4.5B_ru_v10epoch=3, Winner=xglm-4.5B_ru_v10epoch=3\n",
    "Best model=xglm-4.5B_ru_v10epoch=3, Compare model=xglm-4.5B_ru_v10epoch=0_step=20570, Winner=xglm-4.5B_ru_v10epoch=3\n",
    "Best model=xglm-4.5B_ru_v10epoch=3, Compare model=xglm-4.5B_ru_v10epoch=6_step=41141, Winner=SuperPosition\n",
    "Best model=xglm-4.5B_ru_v10epoch=6_step=41141, Compare model=xglm-4.5B_ru_v10epoch=2, Winner=xglm-4.5B_ru_v10epoch=2\n",
    "Best model=xglm-4.5B_ru_v10epoch=2, Compare model=xglm-4.5B_ru_v10epoch=5_step=102854, Winner=SuperPosition\n",
    "Best model=xglm-4.5B_ru_v10epoch=5_step=102854, Compare model=xglm-4.5B_ru_v10epoch=5_step=61712, Winner=SuperPosition\n",
    "Best model=xglm-4.5B_ru_v10epoch=5_step=61712, Compare model=xglm-4.5B_ru_v10epoch=6_step=61712, Winner=SuperPosition\n",
    "Best model=xglm-4.5B_ru_v10epoch=6_step=61712, Compare model=xglm-4.5B_ru_v10epoch=5_step=41141, Winner=SuperPosition\n",
    "Best model=xglm-4.5B_ru_v10epoch=5_step=41141, Compare model=xglm-4.5B_ru_v10epoch=5_step=20570, Winner=SuperPosition\n",
    "Best model=xglm-4.5B_ru_v10epoch=5_step=20570, Compare model=xglm-4.5B_ru_v10epoch=1, Winner=SuperPosition\n",
    "Best model=xglm-4.5B_ru_v10epoch=1, Compare model=xglm-4.5B_ru_v10epoch=0_step=41141, Winner=xglm-4.5B_ru_v10epoch=1\n",
    "Best model=xglm-4.5B_ru_v10epoch=1, Compare model=xglm-4.5B_ru_v10epoch=0, Winner=SuperPosition\n",
    "Best model=xglm-4.5B_ru_v10epoch=0, Compare model=xglm-4.5B_ru_v10epoch=0_step=82283, Winner=SuperPosition\n",
    "Best model=xglm-4.5B_ru_v10epoch=0_step=82283, Compare model=xglm-4.5B_ru_v10epoch=5_step=82283, Winner=SuperPosition\n",
    "Best model=xglm-4.5B_ru_v10epoch=5_step=82283, Compare model=xglm-4.5B_ru_v10epoch=4, Winner=xglm-4.5B_ru_v10epoch=4\n",
    "Best model=xglm-4.5B_ru_v10epoch=4, Compare model=xglm-4.5B_ru_v10epoch=6_step=20570, Winner=xglm-4.5B_ru_v10epoch=4\n",
    "Best model=xglm-4.5B_ru_v10epoch=4, Compare model=xglm-4.5B_ru_v10epoch=0_step=102854, Winner=SuperPosition\n",
    "Best model=xglm-4.5B_ru_v10epoch=0_step=102854, Compare model=xglm-4.5B_ru_v10epoch=3_step=82283, Winner=SuperPosition\n",
    "Best model=xglm-4.5B_ru_v10epoch=3_step=82283, Compare model=xglm-4.5B_ru_v10epoch=5, Winner=SuperPosition\n",
    "best_model_name=xglm-4.5B_ru_v10epoch=4 0.7368421052631579\n",
    "best_model_name=xglm-4.5B_ru_v10epoch=2 0.631578947368421\n",
    "best_model_name=xglm-4.5B_ru_v10epoch=3 0.6842105263157895\n",
    "\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Подобно как в статье LLM-EVAL: Unified Multi-Dimensional Automatic Evaluation for Open-Domain Conversations with Large Language Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model=xglm-4.5B_ru_v10epoch=0 result=90\n",
      "model=xglm-4.5B_ru_v10epoch=0_step=102854 result=90\n",
      "model=xglm-4.5B_ru_v10epoch=0_step=20570 result=80\n",
      "model=xglm-4.5B_ru_v10epoch=0_step=41141 result=80\n",
      "model=xglm-4.5B_ru_v10epoch=0_step=61712 result=90\n",
      "model=xglm-4.5B_ru_v10epoch=0_step=82283 result=90\n",
      "model=xglm-4.5B_ru_v10epoch=1 result=90\n",
      "model=xglm-4.5B_ru_v10epoch=2 result=90\n",
      "model=xglm-4.5B_ru_v10epoch=3 result=90\n",
      "model=xglm-4.5B_ru_v10epoch=3_step=82283 result=90\n",
      "model=xglm-4.5B_ru_v10epoch=4 result=90\n",
      "model=xglm-4.5B_ru_v10epoch=5 result=90\n",
      "model=xglm-4.5B_ru_v10epoch=5_step=102854 result=90\n",
      "model=xglm-4.5B_ru_v10epoch=5_step=20570 result=90\n",
      "model=xglm-4.5B_ru_v10epoch=5_step=41141 result=90\n",
      "model=xglm-4.5B_ru_v10epoch=5_step=61712 result=80\n",
      "model=xglm-4.5B_ru_v10epoch=5_step=82283 result=80\n",
      "model=xglm-4.5B_ru_v10epoch=6_step=20570 result=90\n",
      "model=xglm-4.5B_ru_v10epoch=6_step=41141 result=90\n",
      "model=xglm-4.5B_ru_v10epoch=6_step=61712 result=90\n",
      "----------------------------------------------------------------------------------------------------\n",
      "model=xglm-4.5B_ru_v10epoch=0 result=95\n",
      "model=xglm-4.5B_ru_v10epoch=0_step=102854 result=95\n",
      "model=xglm-4.5B_ru_v10epoch=0_step=20570 result=100\n",
      "model=xglm-4.5B_ru_v10epoch=0_step=41141 result=95\n",
      "model=xglm-4.5B_ru_v10epoch=0_step=61712 result=95\n",
      "model=xglm-4.5B_ru_v10epoch=0_step=82283 result=95\n",
      "model=xglm-4.5B_ru_v10epoch=1 result=90\n",
      "model=xglm-4.5B_ru_v10epoch=2 result=90\n",
      "model=xglm-4.5B_ru_v10epoch=3 result=90\n",
      "model=xglm-4.5B_ru_v10epoch=3_step=82283 result=90\n",
      "model=xglm-4.5B_ru_v10epoch=4 result=90\n",
      "model=xglm-4.5B_ru_v10epoch=5 result=90\n",
      "model=xglm-4.5B_ru_v10epoch=5_step=102854 result=90\n",
      "model=xglm-4.5B_ru_v10epoch=5_step=20570 result=95\n",
      "model=xglm-4.5B_ru_v10epoch=5_step=41141 result=95\n",
      "model=xglm-4.5B_ru_v10epoch=5_step=61712 result=95\n",
      "model=xglm-4.5B_ru_v10epoch=5_step=82283 result=90\n",
      "model=xglm-4.5B_ru_v10epoch=6_step=20570 result=90\n",
      "model=xglm-4.5B_ru_v10epoch=6_step=41141 result=95\n",
      "model=xglm-4.5B_ru_v10epoch=6_step=61712 result=95\n",
      "----------------------------------------------------------------------------------------------------\n",
      "model=xglm-4.5B_ru_v10epoch=0 result=100\n",
      "model=xglm-4.5B_ru_v10epoch=0_step=102854 result=100\n",
      "model=xglm-4.5B_ru_v10epoch=0_step=20570 result=95\n",
      "model=xglm-4.5B_ru_v10epoch=0_step=41141 result=100\n",
      "model=xglm-4.5B_ru_v10epoch=0_step=61712 result=95\n",
      "model=xglm-4.5B_ru_v10epoch=0_step=82283 result=95\n",
      "model=xglm-4.5B_ru_v10epoch=1 result=100\n",
      "model=xglm-4.5B_ru_v10epoch=2 result=100\n",
      "model=xglm-4.5B_ru_v10epoch=3 result=100\n",
      "model=xglm-4.5B_ru_v10epoch=3_step=82283 result=100\n",
      "model=xglm-4.5B_ru_v10epoch=4 result=100\n",
      "model=xglm-4.5B_ru_v10epoch=5 result=100\n",
      "model=xglm-4.5B_ru_v10epoch=5_step=102854 result=100\n",
      "model=xglm-4.5B_ru_v10epoch=5_step=20570 result=100\n",
      "model=xglm-4.5B_ru_v10epoch=5_step=41141 result=100\n",
      "model=xglm-4.5B_ru_v10epoch=5_step=61712 result=100\n",
      "model=xglm-4.5B_ru_v10epoch=5_step=82283 result=100\n",
      "model=xglm-4.5B_ru_v10epoch=6_step=20570 result=95\n",
      "model=xglm-4.5B_ru_v10epoch=6_step=41141 result=100\n",
      "model=xglm-4.5B_ru_v10epoch=6_step=61712 result=100\n",
      "----------------------------------------------------------------------------------------------------\n",
      "model=xglm-4.5B_ru_v10epoch=0 result=90\n",
      "model=xglm-4.5B_ru_v10epoch=0_step=102854 result=90\n",
      "model=xglm-4.5B_ru_v10epoch=0_step=20570 result=95\n",
      "model=xglm-4.5B_ru_v10epoch=0_step=41141 result=90\n",
      "model=xglm-4.5B_ru_v10epoch=0_step=61712 result=90\n",
      "model=xglm-4.5B_ru_v10epoch=0_step=82283 result=90\n",
      "model=xglm-4.5B_ru_v10epoch=1 result=90\n",
      "model=xglm-4.5B_ru_v10epoch=2 result=90\n",
      "model=xglm-4.5B_ru_v10epoch=3 result=90\n",
      "model=xglm-4.5B_ru_v10epoch=3_step=82283 result=90\n",
      "model=xglm-4.5B_ru_v10epoch=4 result=90\n",
      "model=xglm-4.5B_ru_v10epoch=5 result=90\n",
      "model=xglm-4.5B_ru_v10epoch=5_step=102854 result=90\n",
      "model=xglm-4.5B_ru_v10epoch=5_step=20570 result=95\n",
      "model=xglm-4.5B_ru_v10epoch=5_step=41141 result=90\n",
      "model=xglm-4.5B_ru_v10epoch=5_step=61712 result=90\n",
      "model=xglm-4.5B_ru_v10epoch=5_step=82283 result=90\n",
      "model=xglm-4.5B_ru_v10epoch=6_step=20570 result=90\n",
      "model=xglm-4.5B_ru_v10epoch=6_step=41141 result=90\n",
      "model=xglm-4.5B_ru_v10epoch=6_step=61712 result=80\n",
      "----------------------------------------------------------------------------------------------------\n",
      "model=xglm-4.5B_ru_v10epoch=0 result=100\n",
      "model=xglm-4.5B_ru_v10epoch=0_step=102854 result=100\n",
      "model=xglm-4.5B_ru_v10epoch=0_step=20570 result=80\n",
      "model=xglm-4.5B_ru_v10epoch=0_step=41141 result=80\n",
      "model=xglm-4.5B_ru_v10epoch=0_step=61712 result=100\n",
      "model=xglm-4.5B_ru_v10epoch=0_step=82283 result=100\n",
      "model=xglm-4.5B_ru_v10epoch=1 result=80\n",
      "model=xglm-4.5B_ru_v10epoch=2 result=100\n",
      "model=xglm-4.5B_ru_v10epoch=3 result=100\n",
      "model=xglm-4.5B_ru_v10epoch=3_step=82283 result=100\n",
      "model=xglm-4.5B_ru_v10epoch=4 result=100\n",
      "model=xglm-4.5B_ru_v10epoch=5 result=80\n",
      "model=xglm-4.5B_ru_v10epoch=5_step=102854 result=80\n",
      "model=xglm-4.5B_ru_v10epoch=5_step=20570 result=100\n",
      "model=xglm-4.5B_ru_v10epoch=5_step=41141 result=80\n",
      "model=xglm-4.5B_ru_v10epoch=5_step=61712 result=100\n",
      "model=xglm-4.5B_ru_v10epoch=5_step=82283 result=50\n",
      "model=xglm-4.5B_ru_v10epoch=6_step=20570 result=80\n",
      "model=xglm-4.5B_ru_v10epoch=6_step=41141 result=80\n",
      "model=xglm-4.5B_ru_v10epoch=6_step=61712 result=100\n",
      "----------------------------------------------------------------------------------------------------\n",
      "model=xglm-4.5B_ru_v10epoch=0 result=90\n",
      "model=xglm-4.5B_ru_v10epoch=0_step=102854 result=90\n",
      "model=xglm-4.5B_ru_v10epoch=0_step=20570 result=0\n",
      "model=xglm-4.5B_ru_v10epoch=0_step=41141 result=80\n",
      "model=xglm-4.5B_ru_v10epoch=0_step=61712 result=70\n",
      "model=xglm-4.5B_ru_v10epoch=0_step=82283 result=90\n",
      "model=xglm-4.5B_ru_v10epoch=1 result=90\n",
      "model=xglm-4.5B_ru_v10epoch=2 result=90\n",
      "model=xglm-4.5B_ru_v10epoch=3 result=90\n",
      "model=xglm-4.5B_ru_v10epoch=3_step=82283 result=90\n",
      "model=xglm-4.5B_ru_v10epoch=4 result=90\n",
      "model=xglm-4.5B_ru_v10epoch=5 result=90\n",
      "model=xglm-4.5B_ru_v10epoch=5_step=102854 result=90\n",
      "model=xglm-4.5B_ru_v10epoch=5_step=20570 result=90\n",
      "model=xglm-4.5B_ru_v10epoch=5_step=41141 result=90\n",
      "model=xglm-4.5B_ru_v10epoch=5_step=61712 result=90\n",
      "model=xglm-4.5B_ru_v10epoch=5_step=82283 result=90\n",
      "model=xglm-4.5B_ru_v10epoch=6_step=20570 result=90\n",
      "model=xglm-4.5B_ru_v10epoch=6_step=41141 result=90\n",
      "model=xglm-4.5B_ru_v10epoch=6_step=61712 result=90\n",
      "----------------------------------------------------------------------------------------------------\n",
      "model=xglm-4.5B_ru_v10epoch=0 result=100\n",
      "model=xglm-4.5B_ru_v10epoch=0_step=102854 result=100\n",
      "model=xglm-4.5B_ru_v10epoch=0_step=20570 result=100\n",
      "model=xglm-4.5B_ru_v10epoch=0_step=41141 result=95\n",
      "model=xglm-4.5B_ru_v10epoch=0_step=61712 result=95\n",
      "model=xglm-4.5B_ru_v10epoch=0_step=82283 result=100\n",
      "model=xglm-4.5B_ru_v10epoch=1 result=100\n",
      "model=xglm-4.5B_ru_v10epoch=2 result=95\n",
      "model=xglm-4.5B_ru_v10epoch=3 result=100\n",
      "model=xglm-4.5B_ru_v10epoch=3_step=82283 result=100\n",
      "model=xglm-4.5B_ru_v10epoch=4 result=100\n",
      "model=xglm-4.5B_ru_v10epoch=5 result=95\n",
      "model=xglm-4.5B_ru_v10epoch=5_step=102854 result=95\n",
      "model=xglm-4.5B_ru_v10epoch=5_step=20570 result=95\n",
      "model=xglm-4.5B_ru_v10epoch=5_step=41141 result=100\n",
      "model=xglm-4.5B_ru_v10epoch=5_step=61712 result=95\n",
      "model=xglm-4.5B_ru_v10epoch=5_step=82283 result=95\n",
      "model=xglm-4.5B_ru_v10epoch=6_step=20570 result=95\n",
      "model=xglm-4.5B_ru_v10epoch=6_step=41141 result=95\n",
      "The server is overloaded or not ready yet.\n",
      "model=xglm-4.5B_ru_v10epoch=6_step=61712 result=95\n",
      "----------------------------------------------------------------------------------------------------\n",
      "model=xglm-4.5B_ru_v10epoch=0 result=85\n",
      "model=xglm-4.5B_ru_v10epoch=0_step=102854 result=85\n",
      "model=xglm-4.5B_ru_v10epoch=0_step=20570 result=90\n",
      "model=xglm-4.5B_ru_v10epoch=0_step=41141 result=0\n",
      "model=xglm-4.5B_ru_v10epoch=0_step=61712 result=80\n",
      "model=xglm-4.5B_ru_v10epoch=0_step=82283 result=90\n",
      "model=xglm-4.5B_ru_v10epoch=1 result=70\n",
      "model=xglm-4.5B_ru_v10epoch=2 result=80\n",
      "model=xglm-4.5B_ru_v10epoch=3 result=90\n",
      "model=xglm-4.5B_ru_v10epoch=3_step=82283 result=90\n",
      "model=xglm-4.5B_ru_v10epoch=4 result=90\n",
      "model=xglm-4.5B_ru_v10epoch=5 result=80\n",
      "model=xglm-4.5B_ru_v10epoch=5_step=102854 result=80\n",
      "model=xglm-4.5B_ru_v10epoch=5_step=20570 result=80\n",
      "model=xglm-4.5B_ru_v10epoch=5_step=41141 result=80\n",
      "model=xglm-4.5B_ru_v10epoch=5_step=61712 result=10\n",
      "model=xglm-4.5B_ru_v10epoch=5_step=82283 result=70\n",
      "model=xglm-4.5B_ru_v10epoch=6_step=20570 result=80\n",
      "model=xglm-4.5B_ru_v10epoch=6_step=41141 result=85\n",
      "model=xglm-4.5B_ru_v10epoch=6_step=61712 result=90\n",
      "----------------------------------------------------------------------------------------------------\n",
      "model=xglm-4.5B_ru_v10epoch=0 result=100\n",
      "model=xglm-4.5B_ru_v10epoch=0_step=102854 result=100\n",
      "model=xglm-4.5B_ru_v10epoch=0_step=20570 result=95\n",
      "model=xglm-4.5B_ru_v10epoch=0_step=41141 result=100\n",
      "model=xglm-4.5B_ru_v10epoch=0_step=61712 result=100\n",
      "model=xglm-4.5B_ru_v10epoch=0_step=82283 result=90\n",
      "model=xglm-4.5B_ru_v10epoch=1 result=70\n",
      "model=xglm-4.5B_ru_v10epoch=2 result=100\n",
      "model=xglm-4.5B_ru_v10epoch=3 result=100\n",
      "model=xglm-4.5B_ru_v10epoch=3_step=82283 result=100\n",
      "model=xglm-4.5B_ru_v10epoch=4 result=70\n",
      "model=xglm-4.5B_ru_v10epoch=5 result=90\n",
      "model=xglm-4.5B_ru_v10epoch=5_step=102854 result=90\n",
      "model=xglm-4.5B_ru_v10epoch=5_step=20570 result=100\n",
      "model=xglm-4.5B_ru_v10epoch=5_step=41141 result=90\n",
      "model=xglm-4.5B_ru_v10epoch=5_step=61712 result=95\n",
      "model=xglm-4.5B_ru_v10epoch=5_step=82283 result=90\n",
      "model=xglm-4.5B_ru_v10epoch=6_step=20570 result=90\n",
      "model=xglm-4.5B_ru_v10epoch=6_step=41141 result=90\n",
      "model=xglm-4.5B_ru_v10epoch=6_step=61712 result=100\n",
      "----------------------------------------------------------------------------------------------------\n",
      "model=xglm-4.5B_ru_v10epoch=0 result=90\n",
      "model=xglm-4.5B_ru_v10epoch=0_step=102854 result=90\n",
      "model=xglm-4.5B_ru_v10epoch=0_step=20570 result=90\n",
      "model=xglm-4.5B_ru_v10epoch=0_step=41141 result=90\n",
      "model=xglm-4.5B_ru_v10epoch=0_step=61712 result=90\n",
      "model=xglm-4.5B_ru_v10epoch=0_step=82283 result=90\n",
      "model=xglm-4.5B_ru_v10epoch=1 result=90\n",
      "model=xglm-4.5B_ru_v10epoch=2 result=90\n",
      "model=xglm-4.5B_ru_v10epoch=3 result=90\n",
      "model=xglm-4.5B_ru_v10epoch=3_step=82283 result=90\n",
      "model=xglm-4.5B_ru_v10epoch=4 result=90\n",
      "model=xglm-4.5B_ru_v10epoch=5 result=90\n",
      "model=xglm-4.5B_ru_v10epoch=5_step=102854 result=90\n",
      "model=xglm-4.5B_ru_v10epoch=5_step=20570 result=90\n",
      "model=xglm-4.5B_ru_v10epoch=5_step=41141 result=90\n",
      "model=xglm-4.5B_ru_v10epoch=5_step=61712 result=90\n",
      "model=xglm-4.5B_ru_v10epoch=5_step=82283 result=100\n",
      "model=xglm-4.5B_ru_v10epoch=6_step=20570 result=90\n",
      "model=xglm-4.5B_ru_v10epoch=6_step=41141 result=95\n",
      "model=xglm-4.5B_ru_v10epoch=6_step=61712 result=90\n",
      "----------------------------------------------------------------------------------------------------\n",
      "model=xglm-4.5B_ru_v10epoch=0 result=95\n",
      "model=xglm-4.5B_ru_v10epoch=0_step=102854 result=95\n",
      "model=xglm-4.5B_ru_v10epoch=0_step=20570 result=95\n",
      "model=xglm-4.5B_ru_v10epoch=0_step=41141 result=90\n",
      "model=xglm-4.5B_ru_v10epoch=0_step=61712 result=95\n",
      "model=xglm-4.5B_ru_v10epoch=0_step=82283 result=90\n",
      "model=xglm-4.5B_ru_v10epoch=1 result=90\n",
      "model=xglm-4.5B_ru_v10epoch=2 result=95\n",
      "model=xglm-4.5B_ru_v10epoch=3 result=95\n",
      "model=xglm-4.5B_ru_v10epoch=3_step=82283 result=90\n",
      "model=xglm-4.5B_ru_v10epoch=4 result=100\n",
      "model=xglm-4.5B_ru_v10epoch=5 result=100\n",
      "model=xglm-4.5B_ru_v10epoch=5_step=102854 result=100\n",
      "model=xglm-4.5B_ru_v10epoch=5_step=20570 result=95\n",
      "model=xglm-4.5B_ru_v10epoch=5_step=41141 result=100\n",
      "model=xglm-4.5B_ru_v10epoch=5_step=61712 result=90\n",
      "model=xglm-4.5B_ru_v10epoch=5_step=82283 result=95\n",
      "model=xglm-4.5B_ru_v10epoch=6_step=20570 result=95\n",
      "model=xglm-4.5B_ru_v10epoch=6_step=41141 result=95\n",
      "model=xglm-4.5B_ru_v10epoch=6_step=61712 result=100\n",
      "----------------------------------------------------------------------------------------------------\n",
      "model=xglm-4.5B_ru_v10epoch=0 result=100\n",
      "model=xglm-4.5B_ru_v10epoch=0_step=102854 result=100\n",
      "model=xglm-4.5B_ru_v10epoch=0_step=20570 result=100\n",
      "model=xglm-4.5B_ru_v10epoch=0_step=41141 result=60\n",
      "model=xglm-4.5B_ru_v10epoch=0_step=61712 result=0\n",
      "model=xglm-4.5B_ru_v10epoch=0_step=82283 result=90\n",
      "model=xglm-4.5B_ru_v10epoch=1 result=100\n",
      "model=xglm-4.5B_ru_v10epoch=2 result=100\n",
      "model=xglm-4.5B_ru_v10epoch=3 result=100\n",
      "model=xglm-4.5B_ru_v10epoch=3_step=82283 result=100\n",
      "model=xglm-4.5B_ru_v10epoch=4 result=100\n",
      "model=xglm-4.5B_ru_v10epoch=5 result=100\n",
      "model=xglm-4.5B_ru_v10epoch=5_step=102854 result=100\n",
      "model=xglm-4.5B_ru_v10epoch=5_step=20570 result=100\n",
      "model=xglm-4.5B_ru_v10epoch=5_step=41141 result=100\n",
      "model=xglm-4.5B_ru_v10epoch=5_step=61712 result=10\n",
      "model=xglm-4.5B_ru_v10epoch=5_step=82283 result=100\n",
      "model=xglm-4.5B_ru_v10epoch=6_step=20570 result=0\n",
      "model=xglm-4.5B_ru_v10epoch=6_step=41141 result=100\n",
      "model=xglm-4.5B_ru_v10epoch=6_step=61712 result=90\n",
      "----------------------------------------------------------------------------------------------------\n",
      "model=xglm-4.5B_ru_v10epoch=0 result=80\n",
      "The server is overloaded or not ready yet.\n",
      "model=xglm-4.5B_ru_v10epoch=0_step=102854 result=80\n",
      "model=xglm-4.5B_ru_v10epoch=0_step=20570 result=90\n",
      "model=xglm-4.5B_ru_v10epoch=0_step=41141 result=85\n",
      "model=xglm-4.5B_ru_v10epoch=0_step=61712 result=90\n",
      "model=xglm-4.5B_ru_v10epoch=0_step=82283 result=90\n",
      "model=xglm-4.5B_ru_v10epoch=1 result=90\n",
      "model=xglm-4.5B_ru_v10epoch=2 result=90\n",
      "model=xglm-4.5B_ru_v10epoch=3 result=90\n",
      "model=xglm-4.5B_ru_v10epoch=3_step=82283 result=80\n",
      "model=xglm-4.5B_ru_v10epoch=4 result=90\n",
      "model=xglm-4.5B_ru_v10epoch=5 result=90\n",
      "model=xglm-4.5B_ru_v10epoch=5_step=102854 result=90\n",
      "model=xglm-4.5B_ru_v10epoch=5_step=20570 result=90\n",
      "model=xglm-4.5B_ru_v10epoch=5_step=41141 result=90\n",
      "model=xglm-4.5B_ru_v10epoch=5_step=61712 result=90\n",
      "model=xglm-4.5B_ru_v10epoch=5_step=82283 result=90\n",
      "model=xglm-4.5B_ru_v10epoch=6_step=20570 result=95\n",
      "model=xglm-4.5B_ru_v10epoch=6_step=41141 result=90\n",
      "model=xglm-4.5B_ru_v10epoch=6_step=61712 result=90\n",
      "----------------------------------------------------------------------------------------------------\n",
      "model=xglm-4.5B_ru_v10epoch=0 result=90\n",
      "model=xglm-4.5B_ru_v10epoch=0_step=102854 result=90\n",
      "model=xglm-4.5B_ru_v10epoch=0_step=20570 result=90\n",
      "model=xglm-4.5B_ru_v10epoch=0_step=41141 result=80\n",
      "model=xglm-4.5B_ru_v10epoch=0_step=61712 result=80\n",
      "model=xglm-4.5B_ru_v10epoch=0_step=82283 result=100\n",
      "model=xglm-4.5B_ru_v10epoch=1 result=80\n",
      "model=xglm-4.5B_ru_v10epoch=2 result=80\n",
      "model=xglm-4.5B_ru_v10epoch=3 result=80\n",
      "model=xglm-4.5B_ru_v10epoch=3_step=82283 result=100\n",
      "model=xglm-4.5B_ru_v10epoch=4 result=90\n",
      "model=xglm-4.5B_ru_v10epoch=5 result=80\n",
      "model=xglm-4.5B_ru_v10epoch=5_step=102854 result=80\n",
      "model=xglm-4.5B_ru_v10epoch=5_step=20570 result=100\n",
      "model=xglm-4.5B_ru_v10epoch=5_step=41141 result=90\n",
      "model=xglm-4.5B_ru_v10epoch=5_step=61712 result=100\n",
      "model=xglm-4.5B_ru_v10epoch=5_step=82283 result=100\n",
      "model=xglm-4.5B_ru_v10epoch=6_step=20570 result=90\n",
      "model=xglm-4.5B_ru_v10epoch=6_step=41141 result=90\n",
      "model=xglm-4.5B_ru_v10epoch=6_step=61712 result=90\n",
      "----------------------------------------------------------------------------------------------------\n",
      "model=xglm-4.5B_ru_v10epoch=0 result=90\n",
      "model=xglm-4.5B_ru_v10epoch=0_step=102854 result=90\n",
      "model=xglm-4.5B_ru_v10epoch=0_step=20570 result=90\n",
      "model=xglm-4.5B_ru_v10epoch=0_step=41141 result=90\n",
      "model=xglm-4.5B_ru_v10epoch=0_step=61712 result=95\n",
      "model=xglm-4.5B_ru_v10epoch=0_step=82283 result=100\n",
      "model=xglm-4.5B_ru_v10epoch=1 result=90\n",
      "model=xglm-4.5B_ru_v10epoch=2 result=90\n",
      "model=xglm-4.5B_ru_v10epoch=3 result=90\n",
      "model=xglm-4.5B_ru_v10epoch=3_step=82283 result=90\n",
      "model=xglm-4.5B_ru_v10epoch=4 result=95\n",
      "model=xglm-4.5B_ru_v10epoch=5 result=90\n",
      "model=xglm-4.5B_ru_v10epoch=5_step=102854 result=90\n",
      "model=xglm-4.5B_ru_v10epoch=5_step=20570 result=90\n",
      "model=xglm-4.5B_ru_v10epoch=5_step=41141 result=90\n",
      "model=xglm-4.5B_ru_v10epoch=5_step=61712 result=90\n",
      "model=xglm-4.5B_ru_v10epoch=5_step=82283 result=90\n",
      "model=xglm-4.5B_ru_v10epoch=6_step=20570 result=90\n",
      "model=xglm-4.5B_ru_v10epoch=6_step=41141 result=100\n",
      "model=xglm-4.5B_ru_v10epoch=6_step=61712 result=90\n",
      "----------------------------------------------------------------------------------------------------\n",
      "model=xglm-4.5B_ru_v10epoch=0 result=90\n",
      "model=xglm-4.5B_ru_v10epoch=0_step=102854 result=90\n",
      "model=xglm-4.5B_ru_v10epoch=0_step=20570 result=95\n",
      "model=xglm-4.5B_ru_v10epoch=0_step=41141 result=90\n",
      "model=xglm-4.5B_ru_v10epoch=0_step=61712 result=90\n",
      "model=xglm-4.5B_ru_v10epoch=0_step=82283 result=90\n",
      "model=xglm-4.5B_ru_v10epoch=1 result=90\n",
      "model=xglm-4.5B_ru_v10epoch=2 result=90\n",
      "model=xglm-4.5B_ru_v10epoch=3 result=90\n",
      "The server is overloaded or not ready yet.\n",
      "model=xglm-4.5B_ru_v10epoch=3_step=82283 result=95\n",
      "model=xglm-4.5B_ru_v10epoch=4 result=95\n",
      "model=xglm-4.5B_ru_v10epoch=5 result=90\n",
      "model=xglm-4.5B_ru_v10epoch=5_step=102854 result=90\n",
      "model=xglm-4.5B_ru_v10epoch=5_step=20570 result=90\n",
      "model=xglm-4.5B_ru_v10epoch=5_step=41141 result=95\n",
      "model=xglm-4.5B_ru_v10epoch=5_step=61712 result=90\n",
      "model=xglm-4.5B_ru_v10epoch=5_step=82283 result=90\n",
      "model=xglm-4.5B_ru_v10epoch=6_step=20570 result=90\n",
      "model=xglm-4.5B_ru_v10epoch=6_step=41141 result=90\n",
      "model=xglm-4.5B_ru_v10epoch=6_step=61712 result=90\n",
      "----------------------------------------------------------------------------------------------------\n",
      "model=xglm-4.5B_ru_v10epoch=0 result=0\n",
      "model=xglm-4.5B_ru_v10epoch=0_step=102854 result=0\n",
      "model=xglm-4.5B_ru_v10epoch=0_step=20570 result=80\n",
      "model=xglm-4.5B_ru_v10epoch=0_step=41141 result=80\n",
      "model=xglm-4.5B_ru_v10epoch=0_step=61712 result=0\n",
      "model=xglm-4.5B_ru_v10epoch=0_step=82283 result=0\n",
      "model=xglm-4.5B_ru_v10epoch=1 result=0\n",
      "model=xglm-4.5B_ru_v10epoch=2 result=0\n",
      "model=xglm-4.5B_ru_v10epoch=3 result=100\n",
      "model=xglm-4.5B_ru_v10epoch=3_step=82283 result=80\n",
      "model=xglm-4.5B_ru_v10epoch=4 result=0\n",
      "model=xglm-4.5B_ru_v10epoch=5 result=0\n",
      "model=xglm-4.5B_ru_v10epoch=5_step=102854 result=0\n",
      "model=xglm-4.5B_ru_v10epoch=5_step=20570 result=0\n",
      "model=xglm-4.5B_ru_v10epoch=5_step=41141 result=0\n",
      "model=xglm-4.5B_ru_v10epoch=5_step=61712 result=0\n",
      "model=xglm-4.5B_ru_v10epoch=5_step=82283 result=0\n",
      "model=xglm-4.5B_ru_v10epoch=6_step=20570 result=0\n",
      "model=xglm-4.5B_ru_v10epoch=6_step=41141 result=0\n",
      "model=xglm-4.5B_ru_v10epoch=6_step=61712 result=0\n",
      "----------------------------------------------------------------------------------------------------\n",
      "model=xglm-4.5B_ru_v10epoch=0 result=90\n",
      "model=xglm-4.5B_ru_v10epoch=0_step=102854 result=90\n",
      "model=xglm-4.5B_ru_v10epoch=0_step=20570 result=100\n",
      "model=xglm-4.5B_ru_v10epoch=0_step=41141 result=90\n",
      "model=xglm-4.5B_ru_v10epoch=0_step=61712 result=90\n",
      "model=xglm-4.5B_ru_v10epoch=0_step=82283 result=90\n",
      "model=xglm-4.5B_ru_v10epoch=1 result=90\n",
      "model=xglm-4.5B_ru_v10epoch=2 result=80\n",
      "model=xglm-4.5B_ru_v10epoch=3 result=100\n",
      "model=xglm-4.5B_ru_v10epoch=3_step=82283 result=90\n",
      "model=xglm-4.5B_ru_v10epoch=4 result=100\n",
      "model=xglm-4.5B_ru_v10epoch=5 result=90\n",
      "model=xglm-4.5B_ru_v10epoch=5_step=102854 result=80\n",
      "model=xglm-4.5B_ru_v10epoch=5_step=20570 result=100\n",
      "model=xglm-4.5B_ru_v10epoch=5_step=41141 result=100\n",
      "model=xglm-4.5B_ru_v10epoch=5_step=61712 result=95\n",
      "model=xglm-4.5B_ru_v10epoch=5_step=82283 result=90\n",
      "model=xglm-4.5B_ru_v10epoch=6_step=20570 result=90\n",
      "model=xglm-4.5B_ru_v10epoch=6_step=41141 result=90\n",
      "model=xglm-4.5B_ru_v10epoch=6_step=61712 result=100\n",
      "----------------------------------------------------------------------------------------------------\n",
      "model=xglm-4.5B_ru_v10epoch=0 result=90\n",
      "model=xglm-4.5B_ru_v10epoch=0_step=102854 result=90\n",
      "model=xglm-4.5B_ru_v10epoch=0_step=20570 result=50\n",
      "model=xglm-4.5B_ru_v10epoch=0_step=41141 result=70\n",
      "model=xglm-4.5B_ru_v10epoch=0_step=61712 result=85\n",
      "model=xglm-4.5B_ru_v10epoch=0_step=82283 result=90\n",
      "model=xglm-4.5B_ru_v10epoch=1 result=80\n",
      "model=xglm-4.5B_ru_v10epoch=2 result=90\n",
      "model=xglm-4.5B_ru_v10epoch=3 result=90\n",
      "model=xglm-4.5B_ru_v10epoch=3_step=82283 result=90\n",
      "model=xglm-4.5B_ru_v10epoch=4 result=90\n",
      "model=xglm-4.5B_ru_v10epoch=5 result=85\n",
      "model=xglm-4.5B_ru_v10epoch=5_step=102854 result=85\n",
      "model=xglm-4.5B_ru_v10epoch=5_step=20570 result=90\n",
      "model=xglm-4.5B_ru_v10epoch=5_step=41141 result=85\n",
      "model=xglm-4.5B_ru_v10epoch=5_step=61712 result=90\n",
      "model=xglm-4.5B_ru_v10epoch=5_step=82283 result=100\n",
      "model=xglm-4.5B_ru_v10epoch=6_step=20570 result=85\n",
      "model=xglm-4.5B_ru_v10epoch=6_step=41141 result=90\n",
      "model=xglm-4.5B_ru_v10epoch=6_step=61712 result=90\n",
      "----------------------------------------------------------------------------------------------------\n",
      "model=xglm-4.5B_ru_v10epoch=0 result=90\n",
      "model=xglm-4.5B_ru_v10epoch=0_step=102854 result=90\n",
      "model=xglm-4.5B_ru_v10epoch=0_step=20570 result=90\n",
      "model=xglm-4.5B_ru_v10epoch=0_step=41141 result=90\n",
      "model=xglm-4.5B_ru_v10epoch=0_step=61712 result=85\n",
      "model=xglm-4.5B_ru_v10epoch=0_step=82283 result=90\n",
      "model=xglm-4.5B_ru_v10epoch=1 result=90\n",
      "model=xglm-4.5B_ru_v10epoch=2 result=90\n",
      "model=xglm-4.5B_ru_v10epoch=3 result=80\n",
      "model=xglm-4.5B_ru_v10epoch=3_step=82283 result=80\n",
      "model=xglm-4.5B_ru_v10epoch=4 result=90\n",
      "model=xglm-4.5B_ru_v10epoch=5 result=90\n",
      "model=xglm-4.5B_ru_v10epoch=5_step=102854 result=90\n",
      "model=xglm-4.5B_ru_v10epoch=5_step=20570 result=50\n",
      "model=xglm-4.5B_ru_v10epoch=5_step=41141 result=85\n",
      "model=xglm-4.5B_ru_v10epoch=5_step=61712 result=90\n",
      "model=xglm-4.5B_ru_v10epoch=5_step=82283 result=80\n",
      "model=xglm-4.5B_ru_v10epoch=6_step=20570 result=80\n",
      "model=xglm-4.5B_ru_v10epoch=6_step=41141 result=90\n",
      "model=xglm-4.5B_ru_v10epoch=6_step=61712 result=90\n",
      "----------------------------------------------------------------------------------------------------\n",
      "model=xglm-4.5B_ru_v10epoch=0 result=100\n",
      "model=xglm-4.5B_ru_v10epoch=0_step=102854 result=100\n",
      "model=xglm-4.5B_ru_v10epoch=0_step=20570 result=100\n",
      "model=xglm-4.5B_ru_v10epoch=0_step=41141 result=100\n",
      "model=xglm-4.5B_ru_v10epoch=0_step=61712 result=100\n",
      "model=xglm-4.5B_ru_v10epoch=0_step=82283 result=90\n",
      "model=xglm-4.5B_ru_v10epoch=1 result=90\n",
      "model=xglm-4.5B_ru_v10epoch=2 result=90\n",
      "model=xglm-4.5B_ru_v10epoch=3 result=80\n",
      "model=xglm-4.5B_ru_v10epoch=3_step=82283 result=80\n",
      "model=xglm-4.5B_ru_v10epoch=4 result=90\n",
      "model=xglm-4.5B_ru_v10epoch=5 result=90\n",
      "model=xglm-4.5B_ru_v10epoch=5_step=102854 result=90\n",
      "model=xglm-4.5B_ru_v10epoch=5_step=20570 result=90\n",
      "model=xglm-4.5B_ru_v10epoch=5_step=41141 result=90\n",
      "model=xglm-4.5B_ru_v10epoch=5_step=61712 result=90\n",
      "model=xglm-4.5B_ru_v10epoch=5_step=82283 result=90\n",
      "model=xglm-4.5B_ru_v10epoch=6_step=20570 result=90\n",
      "model=xglm-4.5B_ru_v10epoch=6_step=41141 result=90\n",
      "model=xglm-4.5B_ru_v10epoch=6_step=61712 result=100\n",
      "----------------------------------------------------------------------------------------------------\n",
      "model=xglm-4.5B_ru_v10epoch=0 result=100\n",
      "model=xglm-4.5B_ru_v10epoch=0_step=102854 result=95\n",
      "model=xglm-4.5B_ru_v10epoch=0_step=20570 result=100\n",
      "model=xglm-4.5B_ru_v10epoch=0_step=41141 result=100\n",
      "model=xglm-4.5B_ru_v10epoch=0_step=61712 result=100\n",
      "model=xglm-4.5B_ru_v10epoch=0_step=82283 result=100\n",
      "model=xglm-4.5B_ru_v10epoch=1 result=95\n",
      "model=xglm-4.5B_ru_v10epoch=2 result=100\n",
      "model=xglm-4.5B_ru_v10epoch=3 result=90\n",
      "model=xglm-4.5B_ru_v10epoch=3_step=82283 result=90\n",
      "model=xglm-4.5B_ru_v10epoch=4 result=90\n",
      "model=xglm-4.5B_ru_v10epoch=5 result=100\n",
      "model=xglm-4.5B_ru_v10epoch=5_step=102854 result=100\n",
      "model=xglm-4.5B_ru_v10epoch=5_step=20570 result=100\n",
      "model=xglm-4.5B_ru_v10epoch=5_step=41141 result=90\n",
      "model=xglm-4.5B_ru_v10epoch=5_step=61712 result=90\n",
      "model=xglm-4.5B_ru_v10epoch=5_step=82283 result=90\n",
      "model=xglm-4.5B_ru_v10epoch=6_step=20570 result=95\n",
      "model=xglm-4.5B_ru_v10epoch=6_step=41141 result=100\n",
      "model=xglm-4.5B_ru_v10epoch=6_step=61712 result=100\n",
      "----------------------------------------------------------------------------------------------------\n",
      "model=xglm-4.5B_ru_v10epoch=0 result=80\n",
      "model=xglm-4.5B_ru_v10epoch=0_step=102854 result=80\n",
      "model=xglm-4.5B_ru_v10epoch=0_step=20570 result=50\n",
      "model=xglm-4.5B_ru_v10epoch=0_step=41141 result=0\n",
      "model=xglm-4.5B_ru_v10epoch=0_step=61712 result=80\n",
      "model=xglm-4.5B_ru_v10epoch=0_step=82283 result=80\n",
      "model=xglm-4.5B_ru_v10epoch=1 result=0\n",
      "model=xglm-4.5B_ru_v10epoch=2 result=90\n",
      "model=xglm-4.5B_ru_v10epoch=3 result=100\n",
      "model=xglm-4.5B_ru_v10epoch=3_step=82283 result=80\n",
      "model=xglm-4.5B_ru_v10epoch=4 result=90\n",
      "model=xglm-4.5B_ru_v10epoch=5 result=90\n",
      "model=xglm-4.5B_ru_v10epoch=5_step=102854 result=90\n",
      "model=xglm-4.5B_ru_v10epoch=5_step=20570 result=100\n",
      "model=xglm-4.5B_ru_v10epoch=5_step=41141 result=90\n",
      "model=xglm-4.5B_ru_v10epoch=5_step=61712 result=90\n",
      "model=xglm-4.5B_ru_v10epoch=5_step=82283 result=100\n",
      "model=xglm-4.5B_ru_v10epoch=6_step=20570 result=0\n",
      "model=xglm-4.5B_ru_v10epoch=6_step=41141 result=90\n",
      "model=xglm-4.5B_ru_v10epoch=6_step=61712 result=80\n",
      "----------------------------------------------------------------------------------------------------\n",
      "model=xglm-4.5B_ru_v10epoch=0 result=90\n",
      "model=xglm-4.5B_ru_v10epoch=0_step=102854 result=90\n",
      "model=xglm-4.5B_ru_v10epoch=0_step=20570 result=90\n",
      "model=xglm-4.5B_ru_v10epoch=0_step=41141 result=85\n",
      "model=xglm-4.5B_ru_v10epoch=0_step=61712 result=95\n",
      "model=xglm-4.5B_ru_v10epoch=0_step=82283 result=90\n",
      "model=xglm-4.5B_ru_v10epoch=1 result=95\n",
      "model=xglm-4.5B_ru_v10epoch=2 result=100\n",
      "model=xglm-4.5B_ru_v10epoch=3 result=95\n",
      "model=xglm-4.5B_ru_v10epoch=3_step=82283 result=95\n",
      "model=xglm-4.5B_ru_v10epoch=4 result=95\n",
      "model=xglm-4.5B_ru_v10epoch=5 result=95\n",
      "model=xglm-4.5B_ru_v10epoch=5_step=102854 result=95\n",
      "model=xglm-4.5B_ru_v10epoch=5_step=20570 result=95\n",
      "model=xglm-4.5B_ru_v10epoch=5_step=41141 result=90\n",
      "model=xglm-4.5B_ru_v10epoch=5_step=61712 result=95\n",
      "model=xglm-4.5B_ru_v10epoch=5_step=82283 result=90\n",
      "model=xglm-4.5B_ru_v10epoch=6_step=20570 result=95\n",
      "model=xglm-4.5B_ru_v10epoch=6_step=41141 result=90\n",
      "model=xglm-4.5B_ru_v10epoch=6_step=61712 result=95\n",
      "----------------------------------------------------------------------------------------------------\n",
      "model=xglm-4.5B_ru_v10epoch=0 result=70\n",
      "The server is overloaded or not ready yet.\n",
      "model=xglm-4.5B_ru_v10epoch=0_step=102854 result=70\n",
      "model=xglm-4.5B_ru_v10epoch=0_step=20570 result=70\n",
      "model=xglm-4.5B_ru_v10epoch=0_step=41141 result=70\n",
      "model=xglm-4.5B_ru_v10epoch=0_step=61712 result=70\n",
      "model=xglm-4.5B_ru_v10epoch=0_step=82283 result=85\n",
      "model=xglm-4.5B_ru_v10epoch=1 result=50\n",
      "model=xglm-4.5B_ru_v10epoch=2 result=80\n",
      "model=xglm-4.5B_ru_v10epoch=3 result=80\n",
      "model=xglm-4.5B_ru_v10epoch=3_step=82283 result=85\n",
      "model=xglm-4.5B_ru_v10epoch=4 result=85\n",
      "model=xglm-4.5B_ru_v10epoch=5 result=85\n",
      "model=xglm-4.5B_ru_v10epoch=5_step=102854 result=85\n",
      "model=xglm-4.5B_ru_v10epoch=5_step=20570 result=70\n",
      "model=xglm-4.5B_ru_v10epoch=5_step=41141 result=85\n",
      "model=xglm-4.5B_ru_v10epoch=5_step=61712 result=90\n",
      "model=xglm-4.5B_ru_v10epoch=5_step=82283 result=80\n",
      "model=xglm-4.5B_ru_v10epoch=6_step=20570 result=90\n",
      "model=xglm-4.5B_ru_v10epoch=6_step=41141 result=80\n",
      "model=xglm-4.5B_ru_v10epoch=6_step=61712 result=85\n",
      "----------------------------------------------------------------------------------------------------\n",
      "model=xglm-4.5B_ru_v10epoch=0 result=95\n",
      "model=xglm-4.5B_ru_v10epoch=0_step=102854 result=95\n",
      "model=xglm-4.5B_ru_v10epoch=0_step=20570 result=90\n",
      "model=xglm-4.5B_ru_v10epoch=0_step=41141 result=90\n",
      "model=xglm-4.5B_ru_v10epoch=0_step=61712 result=95\n",
      "model=xglm-4.5B_ru_v10epoch=0_step=82283 result=95\n",
      "model=xglm-4.5B_ru_v10epoch=1 result=95\n",
      "model=xglm-4.5B_ru_v10epoch=2 result=95\n",
      "model=xglm-4.5B_ru_v10epoch=3 result=95\n",
      "model=xglm-4.5B_ru_v10epoch=3_step=82283 result=95\n",
      "model=xglm-4.5B_ru_v10epoch=4 result=100\n",
      "model=xglm-4.5B_ru_v10epoch=5 result=90\n",
      "model=xglm-4.5B_ru_v10epoch=5_step=102854 result=90\n",
      "model=xglm-4.5B_ru_v10epoch=5_step=20570 result=100\n",
      "model=xglm-4.5B_ru_v10epoch=5_step=41141 result=95\n",
      "model=xglm-4.5B_ru_v10epoch=5_step=61712 result=95\n",
      "model=xglm-4.5B_ru_v10epoch=5_step=82283 result=95\n",
      "model=xglm-4.5B_ru_v10epoch=6_step=20570 result=100\n",
      "model=xglm-4.5B_ru_v10epoch=6_step=41141 result=95\n",
      "model=xglm-4.5B_ru_v10epoch=6_step=61712 result=95\n",
      "----------------------------------------------------------------------------------------------------\n",
      "model=xglm-4.5B_ru_v10epoch=0 result=95\n",
      "model=xglm-4.5B_ru_v10epoch=0_step=102854 result=95\n",
      "model=xglm-4.5B_ru_v10epoch=0_step=20570 result=95\n",
      "model=xglm-4.5B_ru_v10epoch=0_step=41141 result=90\n",
      "model=xglm-4.5B_ru_v10epoch=0_step=61712 result=95\n",
      "model=xglm-4.5B_ru_v10epoch=0_step=82283 result=95\n",
      "model=xglm-4.5B_ru_v10epoch=1 result=90\n",
      "model=xglm-4.5B_ru_v10epoch=2 result=95\n",
      "model=xglm-4.5B_ru_v10epoch=3 result=95\n",
      "model=xglm-4.5B_ru_v10epoch=3_step=82283 result=95\n",
      "model=xglm-4.5B_ru_v10epoch=4 result=90\n",
      "model=xglm-4.5B_ru_v10epoch=5 result=95\n",
      "model=xglm-4.5B_ru_v10epoch=5_step=102854 result=95\n",
      "model=xglm-4.5B_ru_v10epoch=5_step=20570 result=95\n",
      "model=xglm-4.5B_ru_v10epoch=5_step=41141 result=95\n",
      "model=xglm-4.5B_ru_v10epoch=5_step=61712 result=90\n",
      "model=xglm-4.5B_ru_v10epoch=5_step=82283 result=90\n",
      "model=xglm-4.5B_ru_v10epoch=6_step=20570 result=95\n",
      "model=xglm-4.5B_ru_v10epoch=6_step=41141 result=90\n",
      "model=xglm-4.5B_ru_v10epoch=6_step=61712 result=90\n",
      "----------------------------------------------------------------------------------------------------\n",
      "model=xglm-4.5B_ru_v10epoch=0 result=50\n",
      "model=xglm-4.5B_ru_v10epoch=0_step=102854 result=50\n",
      "model=xglm-4.5B_ru_v10epoch=0_step=20570 result=85\n",
      "model=xglm-4.5B_ru_v10epoch=0_step=41141 result=70\n",
      "model=xglm-4.5B_ru_v10epoch=0_step=61712 result=70\n",
      "model=xglm-4.5B_ru_v10epoch=0_step=82283 result=85\n",
      "model=xglm-4.5B_ru_v10epoch=1 result=80\n",
      "model=xglm-4.5B_ru_v10epoch=2 result=85\n",
      "model=xglm-4.5B_ru_v10epoch=3 result=70\n",
      "model=xglm-4.5B_ru_v10epoch=3_step=82283 result=80\n",
      "model=xglm-4.5B_ru_v10epoch=4 result=85\n",
      "model=xglm-4.5B_ru_v10epoch=5 result=85\n",
      "model=xglm-4.5B_ru_v10epoch=5_step=102854 result=85\n",
      "model=xglm-4.5B_ru_v10epoch=5_step=20570 result=80\n",
      "model=xglm-4.5B_ru_v10epoch=5_step=41141 result=80\n",
      "model=xglm-4.5B_ru_v10epoch=5_step=61712 result=90\n",
      "model=xglm-4.5B_ru_v10epoch=5_step=82283 result=85\n",
      "model=xglm-4.5B_ru_v10epoch=6_step=20570 result=90\n",
      "model=xglm-4.5B_ru_v10epoch=6_step=41141 result=85\n",
      "model=xglm-4.5B_ru_v10epoch=6_step=61712 result=70\n",
      "----------------------------------------------------------------------------------------------------\n",
      "model=xglm-4.5B_ru_v10epoch=0 result=90\n",
      "model=xglm-4.5B_ru_v10epoch=0_step=102854 result=90\n",
      "model=xglm-4.5B_ru_v10epoch=0_step=20570 result=90\n",
      "model=xglm-4.5B_ru_v10epoch=0_step=41141 result=90\n",
      "model=xglm-4.5B_ru_v10epoch=0_step=61712 result=90\n",
      "model=xglm-4.5B_ru_v10epoch=0_step=82283 result=80\n",
      "model=xglm-4.5B_ru_v10epoch=1 result=90\n",
      "model=xglm-4.5B_ru_v10epoch=2 result=80\n",
      "model=xglm-4.5B_ru_v10epoch=3 result=90\n",
      "model=xglm-4.5B_ru_v10epoch=3_step=82283 result=90\n",
      "model=xglm-4.5B_ru_v10epoch=4 result=90\n",
      "model=xglm-4.5B_ru_v10epoch=5 result=90\n",
      "model=xglm-4.5B_ru_v10epoch=5_step=102854 result=90\n",
      "model=xglm-4.5B_ru_v10epoch=5_step=20570 result=90\n",
      "model=xglm-4.5B_ru_v10epoch=5_step=41141 result=90\n",
      "model=xglm-4.5B_ru_v10epoch=5_step=61712 result=90\n",
      "model=xglm-4.5B_ru_v10epoch=5_step=82283 result=90\n",
      "model=xglm-4.5B_ru_v10epoch=6_step=20570 result=90\n",
      "model=xglm-4.5B_ru_v10epoch=6_step=41141 result=90\n",
      "model=xglm-4.5B_ru_v10epoch=6_step=61712 result=90\n",
      "----------------------------------------------------------------------------------------------------\n",
      "model=xglm-4.5B_ru_v10epoch=0 result=90\n",
      "model=xglm-4.5B_ru_v10epoch=0_step=102854 result=90\n",
      "model=xglm-4.5B_ru_v10epoch=0_step=20570 result=90\n",
      "model=xglm-4.5B_ru_v10epoch=0_step=41141 result=95\n",
      "model=xglm-4.5B_ru_v10epoch=0_step=61712 result=90\n",
      "model=xglm-4.5B_ru_v10epoch=0_step=82283 result=95\n",
      "model=xglm-4.5B_ru_v10epoch=1 result=100\n",
      "model=xglm-4.5B_ru_v10epoch=2 result=95\n",
      "model=xglm-4.5B_ru_v10epoch=3 result=95\n",
      "model=xglm-4.5B_ru_v10epoch=3_step=82283 result=90\n",
      "model=xglm-4.5B_ru_v10epoch=4 result=95\n",
      "model=xglm-4.5B_ru_v10epoch=5 result=85\n",
      "model=xglm-4.5B_ru_v10epoch=5_step=102854 result=85\n",
      "model=xglm-4.5B_ru_v10epoch=5_step=20570 result=90\n",
      "model=xglm-4.5B_ru_v10epoch=5_step=41141 result=70\n",
      "model=xglm-4.5B_ru_v10epoch=5_step=61712 result=95\n",
      "model=xglm-4.5B_ru_v10epoch=5_step=82283 result=95\n",
      "model=xglm-4.5B_ru_v10epoch=6_step=20570 result=95\n",
      "model=xglm-4.5B_ru_v10epoch=6_step=41141 result=95\n",
      "model=xglm-4.5B_ru_v10epoch=6_step=61712 result=90\n",
      "----------------------------------------------------------------------------------------------------\n",
      "model=xglm-4.5B_ru_v10epoch=0 result=90\n",
      "model=xglm-4.5B_ru_v10epoch=0_step=102854 result=90\n",
      "model=xglm-4.5B_ru_v10epoch=0_step=20570 result=80\n",
      "model=xglm-4.5B_ru_v10epoch=0_step=41141 result=80\n",
      "model=xglm-4.5B_ru_v10epoch=0_step=61712 result=90\n",
      "model=xglm-4.5B_ru_v10epoch=0_step=82283 result=90\n",
      "model=xglm-4.5B_ru_v10epoch=1 result=90\n",
      "model=xglm-4.5B_ru_v10epoch=2 result=90\n",
      "model=xglm-4.5B_ru_v10epoch=3 result=90\n",
      "model=xglm-4.5B_ru_v10epoch=3_step=82283 result=90\n",
      "model=xglm-4.5B_ru_v10epoch=4 result=90\n",
      "model=xglm-4.5B_ru_v10epoch=5 result=90\n",
      "model=xglm-4.5B_ru_v10epoch=5_step=102854 result=90\n",
      "model=xglm-4.5B_ru_v10epoch=5_step=20570 result=90\n",
      "model=xglm-4.5B_ru_v10epoch=5_step=41141 result=90\n",
      "model=xglm-4.5B_ru_v10epoch=5_step=61712 result=90\n",
      "model=xglm-4.5B_ru_v10epoch=5_step=82283 result=90\n",
      "model=xglm-4.5B_ru_v10epoch=6_step=20570 result=90\n",
      "model=xglm-4.5B_ru_v10epoch=6_step=41141 result=90\n",
      "model=xglm-4.5B_ru_v10epoch=6_step=61712 result=90\n",
      "----------------------------------------------------------------------------------------------------\n",
      "model=xglm-4.5B_ru_v10epoch=0 result=90\n",
      "model=xglm-4.5B_ru_v10epoch=0_step=102854 result=90\n",
      "model=xglm-4.5B_ru_v10epoch=0_step=20570 result=90\n",
      "model=xglm-4.5B_ru_v10epoch=0_step=41141 result=90\n",
      "model=xglm-4.5B_ru_v10epoch=0_step=61712 result=90\n",
      "model=xglm-4.5B_ru_v10epoch=0_step=82283 result=90\n",
      "model=xglm-4.5B_ru_v10epoch=1 result=90\n",
      "model=xglm-4.5B_ru_v10epoch=2 result=90\n",
      "model=xglm-4.5B_ru_v10epoch=3 result=90\n",
      "model=xglm-4.5B_ru_v10epoch=3_step=82283 result=90\n",
      "model=xglm-4.5B_ru_v10epoch=4 result=90\n",
      "model=xglm-4.5B_ru_v10epoch=5 result=90\n",
      "model=xglm-4.5B_ru_v10epoch=5_step=102854 result=90\n",
      "model=xglm-4.5B_ru_v10epoch=5_step=20570 result=90\n",
      "model=xglm-4.5B_ru_v10epoch=5_step=41141 result=90\n",
      "model=xglm-4.5B_ru_v10epoch=5_step=61712 result=90\n",
      "model=xglm-4.5B_ru_v10epoch=5_step=82283 result=90\n",
      "model=xglm-4.5B_ru_v10epoch=6_step=20570 result=90\n",
      "model=xglm-4.5B_ru_v10epoch=6_step=41141 result=90\n",
      "model=xglm-4.5B_ru_v10epoch=6_step=61712 result=90\n",
      "----------------------------------------------------------------------------------------------------\n",
      "model=xglm-4.5B_ru_v10epoch=0 result=10\n",
      "model=xglm-4.5B_ru_v10epoch=0_step=102854 result=10\n",
      "model=xglm-4.5B_ru_v10epoch=0_step=20570 result=90\n",
      "model=xglm-4.5B_ru_v10epoch=0_step=41141 result=80\n",
      "model=xglm-4.5B_ru_v10epoch=0_step=61712 result=20\n",
      "model=xglm-4.5B_ru_v10epoch=0_step=82283 result=10\n",
      "model=xglm-4.5B_ru_v10epoch=1 result=80\n",
      "model=xglm-4.5B_ru_v10epoch=2 result=100\n",
      "model=xglm-4.5B_ru_v10epoch=3 result=100\n",
      "model=xglm-4.5B_ru_v10epoch=3_step=82283 result=100\n",
      "model=xglm-4.5B_ru_v10epoch=4 result=90\n",
      "model=xglm-4.5B_ru_v10epoch=5 result=90\n",
      "model=xglm-4.5B_ru_v10epoch=5_step=102854 result=90\n",
      "model=xglm-4.5B_ru_v10epoch=5_step=20570 result=90\n",
      "model=xglm-4.5B_ru_v10epoch=5_step=41141 result=90\n",
      "model=xglm-4.5B_ru_v10epoch=5_step=61712 result=90\n",
      "model=xglm-4.5B_ru_v10epoch=5_step=82283 result=100\n",
      "model=xglm-4.5B_ru_v10epoch=6_step=20570 result=90\n",
      "model=xglm-4.5B_ru_v10epoch=6_step=41141 result=100\n",
      "model=xglm-4.5B_ru_v10epoch=6_step=61712 result=100\n",
      "----------------------------------------------------------------------------------------------------\n",
      "model=xglm-4.5B_ru_v10epoch=0 result=80\n",
      "model=xglm-4.5B_ru_v10epoch=0_step=102854 result=85\n",
      "model=xglm-4.5B_ru_v10epoch=0_step=20570 result=90\n",
      "model=xglm-4.5B_ru_v10epoch=0_step=41141 result=85\n",
      "model=xglm-4.5B_ru_v10epoch=0_step=61712 result=80\n",
      "model=xglm-4.5B_ru_v10epoch=0_step=82283 result=80\n",
      "model=xglm-4.5B_ru_v10epoch=1 result=90\n",
      "model=xglm-4.5B_ru_v10epoch=2 result=90\n",
      "model=xglm-4.5B_ru_v10epoch=3 result=90\n",
      "model=xglm-4.5B_ru_v10epoch=3_step=82283 result=90\n",
      "model=xglm-4.5B_ru_v10epoch=4 result=90\n",
      "The server is overloaded or not ready yet.\n",
      "model=xglm-4.5B_ru_v10epoch=5 result=90\n",
      "model=xglm-4.5B_ru_v10epoch=5_step=102854 result=90\n",
      "model=xglm-4.5B_ru_v10epoch=5_step=20570 result=90\n",
      "model=xglm-4.5B_ru_v10epoch=5_step=41141 result=95\n",
      "model=xglm-4.5B_ru_v10epoch=5_step=61712 result=90\n",
      "model=xglm-4.5B_ru_v10epoch=5_step=82283 result=90\n",
      "model=xglm-4.5B_ru_v10epoch=6_step=20570 result=90\n",
      "model=xglm-4.5B_ru_v10epoch=6_step=41141 result=85\n",
      "model=xglm-4.5B_ru_v10epoch=6_step=61712 result=90\n",
      "----------------------------------------------------------------------------------------------------\n",
      "model=xglm-4.5B_ru_v10epoch=0 result=50\n",
      "model=xglm-4.5B_ru_v10epoch=0_step=102854 result=50\n",
      "model=xglm-4.5B_ru_v10epoch=0_step=20570 result=50\n",
      "model=xglm-4.5B_ru_v10epoch=0_step=41141 result=0\n",
      "model=xglm-4.5B_ru_v10epoch=0_step=61712 result=50\n",
      "model=xglm-4.5B_ru_v10epoch=0_step=82283 result=0\n",
      "model=xglm-4.5B_ru_v10epoch=1 result=90\n",
      "model=xglm-4.5B_ru_v10epoch=2 result=90\n",
      "model=xglm-4.5B_ru_v10epoch=3 result=90\n",
      "model=xglm-4.5B_ru_v10epoch=3_step=82283 result=90\n",
      "model=xglm-4.5B_ru_v10epoch=4 result=50\n",
      "model=xglm-4.5B_ru_v10epoch=5 result=80\n",
      "model=xglm-4.5B_ru_v10epoch=5_step=102854 result=80\n",
      "model=xglm-4.5B_ru_v10epoch=5_step=20570 result=100\n",
      "model=xglm-4.5B_ru_v10epoch=5_step=41141 result=90\n",
      "model=xglm-4.5B_ru_v10epoch=5_step=61712 result=100\n",
      "model=xglm-4.5B_ru_v10epoch=5_step=82283 result=90\n",
      "model=xglm-4.5B_ru_v10epoch=6_step=20570 result=100\n",
      "model=xglm-4.5B_ru_v10epoch=6_step=41141 result=100\n",
      "model=xglm-4.5B_ru_v10epoch=6_step=61712 result=100\n",
      "----------------------------------------------------------------------------------------------------\n",
      "model=xglm-4.5B_ru_v10epoch=0 result=90\n",
      "model=xglm-4.5B_ru_v10epoch=0_step=102854 result=90\n",
      "model=xglm-4.5B_ru_v10epoch=0_step=20570 result=90\n",
      "model=xglm-4.5B_ru_v10epoch=0_step=41141 result=90\n",
      "model=xglm-4.5B_ru_v10epoch=0_step=61712 result=80\n",
      "model=xglm-4.5B_ru_v10epoch=0_step=82283 result=90\n",
      "model=xglm-4.5B_ru_v10epoch=1 result=90\n",
      "model=xglm-4.5B_ru_v10epoch=2 result=90\n",
      "model=xglm-4.5B_ru_v10epoch=3 result=90\n",
      "model=xglm-4.5B_ru_v10epoch=3_step=82283 result=90\n",
      "model=xglm-4.5B_ru_v10epoch=4 result=90\n",
      "model=xglm-4.5B_ru_v10epoch=5 result=90\n",
      "model=xglm-4.5B_ru_v10epoch=5_step=102854 result=90\n",
      "model=xglm-4.5B_ru_v10epoch=5_step=20570 result=90\n",
      "model=xglm-4.5B_ru_v10epoch=5_step=41141 result=90\n",
      "model=xglm-4.5B_ru_v10epoch=5_step=61712 result=90\n",
      "model=xglm-4.5B_ru_v10epoch=5_step=82283 result=90\n",
      "model=xglm-4.5B_ru_v10epoch=6_step=20570 result=90\n",
      "model=xglm-4.5B_ru_v10epoch=6_step=41141 result=90\n",
      "model=xglm-4.5B_ru_v10epoch=6_step=61712 result=100\n",
      "----------------------------------------------------------------------------------------------------\n",
      "model=xglm-4.5B_ru_v10epoch=0 result=50\n",
      "model=xglm-4.5B_ru_v10epoch=0_step=102854 result=50\n",
      "model=xglm-4.5B_ru_v10epoch=0_step=20570 result=90\n",
      "model=xglm-4.5B_ru_v10epoch=0_step=41141 result=80\n",
      "model=xglm-4.5B_ru_v10epoch=0_step=61712 result=50\n",
      "model=xglm-4.5B_ru_v10epoch=0_step=82283 result=90\n",
      "model=xglm-4.5B_ru_v10epoch=1 result=70\n",
      "model=xglm-4.5B_ru_v10epoch=2 result=50\n",
      "model=xglm-4.5B_ru_v10epoch=3 result=80\n",
      "model=xglm-4.5B_ru_v10epoch=3_step=82283 result=50\n",
      "model=xglm-4.5B_ru_v10epoch=4 result=80\n",
      "model=xglm-4.5B_ru_v10epoch=5 result=90\n",
      "model=xglm-4.5B_ru_v10epoch=5_step=102854 result=90\n",
      "model=xglm-4.5B_ru_v10epoch=5_step=20570 result=90\n",
      "model=xglm-4.5B_ru_v10epoch=5_step=41141 result=80\n",
      "model=xglm-4.5B_ru_v10epoch=5_step=61712 result=85\n",
      "model=xglm-4.5B_ru_v10epoch=5_step=82283 result=90\n",
      "model=xglm-4.5B_ru_v10epoch=6_step=20570 result=90\n",
      "model=xglm-4.5B_ru_v10epoch=6_step=41141 result=90\n",
      "model=xglm-4.5B_ru_v10epoch=6_step=61712 result=90\n",
      "----------------------------------------------------------------------------------------------------\n",
      "The server is overloaded or not ready yet.\n",
      "model=xglm-4.5B_ru_v10epoch=0 result=95\n",
      "model=xglm-4.5B_ru_v10epoch=0_step=102854 result=95\n",
      "model=xglm-4.5B_ru_v10epoch=0_step=20570 result=80\n",
      "model=xglm-4.5B_ru_v10epoch=0_step=41141 result=90\n",
      "model=xglm-4.5B_ru_v10epoch=0_step=61712 result=80\n",
      "model=xglm-4.5B_ru_v10epoch=0_step=82283 result=95\n",
      "model=xglm-4.5B_ru_v10epoch=1 result=90\n",
      "model=xglm-4.5B_ru_v10epoch=2 result=90\n",
      "model=xglm-4.5B_ru_v10epoch=3 result=90\n",
      "model=xglm-4.5B_ru_v10epoch=3_step=82283 result=80\n",
      "model=xglm-4.5B_ru_v10epoch=4 result=80\n",
      "model=xglm-4.5B_ru_v10epoch=5 result=80\n",
      "model=xglm-4.5B_ru_v10epoch=5_step=102854 result=80\n",
      "model=xglm-4.5B_ru_v10epoch=5_step=20570 result=95\n",
      "model=xglm-4.5B_ru_v10epoch=5_step=41141 result=90\n",
      "model=xglm-4.5B_ru_v10epoch=5_step=61712 result=90\n",
      "The server is overloaded or not ready yet.\n",
      "model=xglm-4.5B_ru_v10epoch=5_step=82283 result=85\n",
      "model=xglm-4.5B_ru_v10epoch=6_step=20570 result=90\n",
      "model=xglm-4.5B_ru_v10epoch=6_step=41141 result=90\n",
      "model=xglm-4.5B_ru_v10epoch=6_step=61712 result=90\n",
      "----------------------------------------------------------------------------------------------------\n",
      "model=xglm-4.5B_ru_v10epoch=0 result=90\n",
      "model=xglm-4.5B_ru_v10epoch=0_step=102854 result=90\n",
      "model=xglm-4.5B_ru_v10epoch=0_step=20570 result=90\n",
      "model=xglm-4.5B_ru_v10epoch=0_step=41141 result=90\n",
      "model=xglm-4.5B_ru_v10epoch=0_step=61712 result=90\n",
      "model=xglm-4.5B_ru_v10epoch=0_step=82283 result=90\n",
      "model=xglm-4.5B_ru_v10epoch=1 result=95\n",
      "model=xglm-4.5B_ru_v10epoch=2 result=80\n",
      "model=xglm-4.5B_ru_v10epoch=3 result=90\n",
      "model=xglm-4.5B_ru_v10epoch=3_step=82283 result=90\n",
      "model=xglm-4.5B_ru_v10epoch=4 result=90\n",
      "model=xglm-4.5B_ru_v10epoch=5 result=90\n",
      "model=xglm-4.5B_ru_v10epoch=5_step=102854 result=90\n",
      "model=xglm-4.5B_ru_v10epoch=5_step=20570 result=90\n",
      "model=xglm-4.5B_ru_v10epoch=5_step=41141 result=80\n",
      "model=xglm-4.5B_ru_v10epoch=5_step=61712 result=90\n",
      "model=xglm-4.5B_ru_v10epoch=5_step=82283 result=90\n",
      "model=xglm-4.5B_ru_v10epoch=6_step=20570 result=90\n",
      "model=xglm-4.5B_ru_v10epoch=6_step=41141 result=90\n",
      "model=xglm-4.5B_ru_v10epoch=6_step=61712 result=80\n",
      "----------------------------------------------------------------------------------------------------\n",
      "model=xglm-4.5B_ru_v10epoch=0 result=100\n",
      "model=xglm-4.5B_ru_v10epoch=0_step=102854 result=100\n",
      "model=xglm-4.5B_ru_v10epoch=0_step=20570 result=90\n",
      "model=xglm-4.5B_ru_v10epoch=0_step=41141 result=100\n",
      "model=xglm-4.5B_ru_v10epoch=0_step=61712 result=95\n",
      "model=xglm-4.5B_ru_v10epoch=0_step=82283 result=100\n",
      "model=xglm-4.5B_ru_v10epoch=1 result=100\n",
      "model=xglm-4.5B_ru_v10epoch=2 result=95\n",
      "model=xglm-4.5B_ru_v10epoch=3 result=100\n",
      "model=xglm-4.5B_ru_v10epoch=3_step=82283 result=90\n",
      "model=xglm-4.5B_ru_v10epoch=4 result=95\n",
      "model=xglm-4.5B_ru_v10epoch=5 result=95\n",
      "model=xglm-4.5B_ru_v10epoch=5_step=102854 result=95\n",
      "model=xglm-4.5B_ru_v10epoch=5_step=20570 result=95\n",
      "model=xglm-4.5B_ru_v10epoch=5_step=41141 result=95\n",
      "model=xglm-4.5B_ru_v10epoch=5_step=61712 result=95\n",
      "model=xglm-4.5B_ru_v10epoch=5_step=82283 result=90\n",
      "model=xglm-4.5B_ru_v10epoch=6_step=20570 result=95\n",
      "model=xglm-4.5B_ru_v10epoch=6_step=41141 result=90\n",
      "model=xglm-4.5B_ru_v10epoch=6_step=61712 result=100\n",
      "----------------------------------------------------------------------------------------------------\n",
      "model=xglm-4.5B_ru_v10epoch=0 result=90\n",
      "model=xglm-4.5B_ru_v10epoch=0_step=102854 result=90\n",
      "model=xglm-4.5B_ru_v10epoch=0_step=20570 result=70\n",
      "model=xglm-4.5B_ru_v10epoch=0_step=41141 result=90\n",
      "model=xglm-4.5B_ru_v10epoch=0_step=61712 result=90\n",
      "model=xglm-4.5B_ru_v10epoch=0_step=82283 result=80\n",
      "model=xglm-4.5B_ru_v10epoch=1 result=90\n",
      "model=xglm-4.5B_ru_v10epoch=2 result=80\n",
      "model=xglm-4.5B_ru_v10epoch=3 result=80\n",
      "model=xglm-4.5B_ru_v10epoch=3_step=82283 result=80\n",
      "model=xglm-4.5B_ru_v10epoch=4 result=90\n",
      "model=xglm-4.5B_ru_v10epoch=5 result=95\n",
      "model=xglm-4.5B_ru_v10epoch=5_step=102854 result=95\n",
      "model=xglm-4.5B_ru_v10epoch=5_step=20570 result=90\n",
      "model=xglm-4.5B_ru_v10epoch=5_step=41141 result=90\n",
      "model=xglm-4.5B_ru_v10epoch=5_step=61712 result=50\n",
      "model=xglm-4.5B_ru_v10epoch=5_step=82283 result=80\n",
      "model=xglm-4.5B_ru_v10epoch=6_step=20570 result=80\n",
      "model=xglm-4.5B_ru_v10epoch=6_step=41141 result=90\n",
      "model=xglm-4.5B_ru_v10epoch=6_step=61712 result=90\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "class EvaluationPipeline2:\n",
    "    def __init__(self, eval_prompt_template: str, model_name=\"gpt-3.5-turbo\") -> None:\n",
    "        self.eval_prompt_template = eval_prompt_template\n",
    "        self.model_name = model_name\n",
    "\n",
    "    def extract_task(self, model_name, item):\n",
    "        # вытаскивает из промпта задание\n",
    "        return item[model_name].split(\"\\nAssi\")[0].split(\"Human:\\n\")[1].strip()\n",
    "\n",
    "    def extract_result(self, model_name, item):\n",
    "        # возвращает значение, которое сгенерировала модель\n",
    "        return item[model_name].split(\"Assistant:\\n\")[1].strip()\n",
    "\n",
    "    def extract_names(self, dataset_line):\n",
    "        return [item for item in dataset_line.index.to_list() if \"epoch\" in item]\n",
    "\n",
    "    def evaluation_func(\n",
    "        self,\n",
    "        item: dict,\n",
    "        model_name_1: str,\n",
    "        evaluation_prompt: str,\n",
    "        debug: bool = False,\n",
    "    ):\n",
    "        task = self.extract_task(model_name=model_name_1, item=item)\n",
    "\n",
    "        model_name_1_result = self.extract_result(\n",
    "            model_name=model_name_1,\n",
    "            item=item,\n",
    "        )\n",
    "\n",
    "        evaluation_prompt_temp = evaluation_prompt.format(\n",
    "            task,\n",
    "            model_name_1_result,\n",
    "        )\n",
    "        if debug:\n",
    "            print(evaluation_prompt_temp)\n",
    "\n",
    "        result = chat_with_chatgpt(\n",
    "            prompt=evaluation_prompt_temp,\n",
    "            model=self.model_name,\n",
    "        )\n",
    "\n",
    "        return result\n",
    "\n",
    "    def find_best(self, dataset_line):\n",
    "        model_names = self.extract_names(dataset_line=dataset_line)\n",
    "\n",
    "        model_evaluations = {}\n",
    "\n",
    "        for model_name in model_names:\n",
    "            repeat = True\n",
    "            while repeat:\n",
    "                try:\n",
    "                    result = self.evaluation_func(\n",
    "                        item=dataset_line.to_dict(),\n",
    "                        model_name_1=model_name,\n",
    "                        evaluation_prompt=self.eval_prompt_template,\n",
    "                        # debug=True\n",
    "                    )\n",
    "                    repeat = False\n",
    "                except Exception as error:\n",
    "                    print(error)\n",
    "                    repeat = True\n",
    "\n",
    "            task = self.extract_task(model_name=model_name, item=dataset_line.to_dict())\n",
    "\n",
    "            model_name_1_result = self.extract_result(\n",
    "                model_name=model_name,\n",
    "                item=dataset_line.to_dict(),\n",
    "            )\n",
    "            evaluation_prompt_temp = self.eval_prompt_template.format(\n",
    "                task,\n",
    "                model_name_1_result,\n",
    "            )\n",
    "            model_evaluations[model_name] = int(result)\n",
    "            model_evaluations[f\"{model_name}__prompt\"] = evaluation_prompt_temp\n",
    "            print(f\"model={model_name} result={result}\")\n",
    "            # time.sleep(10)\n",
    "\n",
    "        # print(model_evaluations)\n",
    "        return model_evaluations\n",
    "\n",
    "\n",
    "evaluation_prompt_2 = \"\"\"\n",
    "Оцени выполненную задачу от 0 до 100. \n",
    "0  значит что модель совершенно не справилась с задачей, грамматическая структура нарушена, получен очень короткий и односложный ответ.  \n",
    "100 значит что модель справилась с задачей, язык соответствует всем грамматическим нормам, получен осмысленный и развернутый ответ.\n",
    "В ответе используй только число.\n",
    "Задача:\n",
    "{}\n",
    "Выполненное задание:\n",
    "{}\n",
    "Оценка:\n",
    "\"\"\"\n",
    "\n",
    "eval_pipeline_2 = EvaluationPipeline2(\n",
    "    eval_prompt_template=evaluation_prompt_2, model_name=\"gpt-4\"\n",
    ")\n",
    "model_ratings = []\n",
    "for i in range(41):\n",
    "    dataset_line_1 = dataset.iloc[i]\n",
    "    result = eval_pipeline_2.find_best(dataset_line=dataset_line_1)\n",
    "    model_ratings.append(result)\n",
    "\n",
    "    print(\"-\" * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(\n",
    "    data=model_ratings,\n",
    ").to_csv(\n",
    "    \"./notebooks/chat_gpt_eval/merged_evaluation_xglm-4.5B_ru_v10__chatgpt_eval__gpt-4.csv\",\n",
    "    index=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets_paths = [\n",
    "    \"./notebooks/chat_gpt_eval/merged_evaluation_xglm-4.5B_ru_v10__chatgpt_eval__1_13.csv\",\n",
    "    \"./notebooks/chat_gpt_eval/merged_evaluation_xglm-4.5B_ru_v10__chatgpt_eval__13_25.csv\",\n",
    "    \"./notebooks/chat_gpt_eval/merged_evaluation_xglm-4.5B_ru_v10__chatgpt_eval__25_28.csv\",\n",
    "]\n",
    "\n",
    "datasets = []\n",
    "for path in datasets_paths:\n",
    "    temp = pd.read_csv(path)\n",
    "    datasets.append(temp)\n",
    "\n",
    "datasets = pd.read_csv(\n",
    "    \"./notebooks/chat_gpt_eval/merged_evaluation_xglm-4.5B_ru_v10__chatgpt_eval__gpt-4.csv\"\n",
    ")\n",
    "# datasets = pd.concat(datasets, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'xglm-4.5B_ru_v10epoch=3'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "names = [item for item in datasets.columns.to_list() if not \"prompt\" in item]\n",
    "names_scores = {name: 0 for name in names}\n",
    "\n",
    "for i in range(len(datasets)):\n",
    "    data_line = datasets.iloc[i]\n",
    "    for name in names:\n",
    "        score = data_line[name]\n",
    "        names_scores[name] += score\n",
    "\n",
    "max(names_scores, key=names_scores.get)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'xglm-4.5B_ru_v10epoch=0': 3450,\n",
       " 'xglm-4.5B_ru_v10epoch=0_step=102854': 3450,\n",
       " 'xglm-4.5B_ru_v10epoch=0_step=20570': 3475,\n",
       " 'xglm-4.5B_ru_v10epoch=0_step=41141': 3300,\n",
       " 'xglm-4.5B_ru_v10epoch=0_step=61712': 3315,\n",
       " 'xglm-4.5B_ru_v10epoch=0_step=82283': 3470,\n",
       " 'xglm-4.5B_ru_v10epoch=1': 3430,\n",
       " 'xglm-4.5B_ru_v10epoch=2': 3585,\n",
       " 'xglm-4.5B_ru_v10epoch=3': 3735,\n",
       " 'xglm-4.5B_ru_v10epoch=3_step=82283': 3655,\n",
       " 'xglm-4.5B_ru_v10epoch=4': 3605,\n",
       " 'xglm-4.5B_ru_v10epoch=5': 3595,\n",
       " 'xglm-4.5B_ru_v10epoch=5_step=102854': 3585,\n",
       " 'xglm-4.5B_ru_v10epoch=5_step=20570': 3660,\n",
       " 'xglm-4.5B_ru_v10epoch=5_step=41141': 3595,\n",
       " 'xglm-4.5B_ru_v10epoch=5_step=61712': 3465,\n",
       " 'xglm-4.5B_ru_v10epoch=5_step=82283': 3580,\n",
       " 'xglm-4.5B_ru_v10epoch=6_step=20570': 3440,\n",
       " 'xglm-4.5B_ru_v10epoch=6_step=41141': 3655,\n",
       " 'xglm-4.5B_ru_v10epoch=6_step=61712': 3675}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "names_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_pipeline_1 = EvaluationPipeline1(eval_prompt_template=evaluation_prompt_2)\n",
    "eval_pipeline_1.extract_names(dataset_line=dataset_line_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "\n",
    "Оцени выполненную задачу от 0 до 100. \n",
    "0  значит что модель совершенно не справилась с задачей, грамматическая структура нарушена, получен очень короткий и односложный ответ.  \n",
    "100 значит что модель справилась с задачей, язык соответствует всем грамматическим нормам, получен осмысленный и развернутый ответ.\n",
    "В ответе используй только число.\n",
    "Задача:\n",
    "Переведите следующее русское выражение на английский язык: \"Без труда не вытащишь и рыбку из пруда.\"\n",
    "Выполненное задание:\n",
    "Без труда не вытащишь и рыбу из пруда.\n",
    "Оценка:\n",
    "\n",
    "model=xglm-4.5B_ru_v10epoch=0 result=90\n",
    "\n",
    "Оцени выполненную задачу от 0 до 100. \n",
    "0  значит что модель совершенно не справилась с задачей, грамматическая структура нарушена, получен очень короткий и односложный ответ.  \n",
    "100 значит что модель справилась с задачей, язык соответствует всем грамматическим нормам, получен осмысленный и развернутый ответ.\n",
    "В ответе используй только число.\n",
    "Задача:\n",
    "Переведите следующее русское выражение на английский язык: \"Без труда не вытащишь и рыбку из пруда.\"\n",
    "Выполненное задание:\n",
    "Без труда не вытащишь и рыбу из пруда.\n",
    "Оценка:\n",
    "\n",
    "model=xglm-4.5B_ru_v10epoch=0_step=102854 result=90\n",
    "\n",
    "Оцени выполненную задачу от 0 до 100. \n",
    "0  значит что модель совершенно не справилась с задачей, грамматическая структура нарушена, получен очень короткий и односложный ответ.  \n",
    "100 значит что модель справилась с задачей, язык соответствует всем грамматическим нормам, получен осмысленный и развернутый ответ.\n",
    "В ответе используй только число.\n",
    "Задача:\n",
    "Переведите следующее русское выражение на английский язык: \"Без труда не вытащишь и рыбку из пруда.\"\n",
    "Выполненное задание:\n",
    "Без труда не вытащишь и рыбку из пруда.\n",
    "Оценка:\n",
    "\n",
    "model=xglm-4.5B_ru_v10epoch=0_step=20570 result=100\n",
    "\n",
    "Оцени выполненную задачу от 0 до 100. \n",
    "0  значит что модель совершенно не справилась с задачей, грамматическая структура нарушена, получен очень короткий и односложный ответ.  \n",
    "100 значит что модель справилась с задачей, язык соответствует всем грамматическим нормам, получен осмысленный и развернутый ответ.\n",
    "В ответе используй только число.\n",
    "Задача:\n",
    "Переведите следующее русское выражение на английский язык: \"Без труда не вытащишь и рыбку из пруда.\"\n",
    "Выполненное задание:\n",
    "Без труда не вытащишь и рыбу из пруда.\n",
    "Оценка:\n",
    "\n",
    "model=xglm-4.5B_ru_v10epoch=0_step=41141 result=90\n",
    "\n",
    "Оцени выполненную задачу от 0 до 100. \n",
    "0  значит что модель совершенно не справилась с задачей, грамматическая структура нарушена, получен очень короткий и односложный ответ.  \n",
    "100 значит что модель справилась с задачей, язык соответствует всем грамматическим нормам, получен осмысленный и развернутый ответ.\n",
    "В ответе используй только число.\n",
    "Задача:\n",
    "Переведите следующее русское выражение на английский язык: \"Без труда не вытащишь и рыбку из пруда.\"\n",
    "Выполненное задание:\n",
    "Без труда не вытащишь и рыбу из пруда.\n",
    "Оценка:\n",
    "\n",
    "model=xglm-4.5B_ru_v10epoch=0_step=61712 result=90\n",
    "\n",
    "Оцени выполненную задачу от 0 до 100. \n",
    "0  значит что модель совершенно не справилась с задачей, грамматическая структура нарушена, получен очень короткий и односложный ответ.  \n",
    "100 значит что модель справилась с задачей, язык соответствует всем грамматическим нормам, получен осмысленный и развернутый ответ.\n",
    "В ответе используй только число.\n",
    "Задача:\n",
    "Переведите следующее русское выражение на английский язык: \"Без труда не вытащишь и рыбку из пруда.\"\n",
    "Выполненное задание:\n",
    "Без труда не вытащишь и рыбу из пруда.\n",
    "Оценка:\n",
    "\n",
    "model=xglm-4.5B_ru_v10epoch=0_step=82283 result=90\n",
    "\n",
    "Оцени выполненную задачу от 0 до 100. \n",
    "0  значит что модель совершенно не справилась с задачей, грамматическая структура нарушена, получен очень короткий и односложный ответ.  \n",
    "100 значит что модель справилась с задачей, язык соответствует всем грамматическим нормам, получен осмысленный и развернутый ответ.\n",
    "В ответе используй только число.\n",
    "Задача:\n",
    "Переведите следующее русское выражение на английский язык: \"Без труда не вытащишь и рыбку из пруда.\"\n",
    "Выполненное задание:\n",
    "Без труда не вытащить и рыбу из пруда.\n",
    "Оценка:\n",
    "\n",
    "model=xglm-4.5B_ru_v10epoch=1 result=90\n",
    "\n",
    "Оцени выполненную задачу от 0 до 100. \n",
    "0  значит что модель совершенно не справилась с задачей, грамматическая структура нарушена, получен очень короткий и односложный ответ.  \n",
    "100 значит что модель справилась с задачей, язык соответствует всем грамматическим нормам, получен осмысленный и развернутый ответ.\n",
    "В ответе используй только число.\n",
    "Задача:\n",
    "Переведите следующее русское выражение на английский язык: \"Без труда не вытащишь и рыбку из пруда.\"\n",
    "Выполненное задание:\n",
    "Без труда не вытащить и рыбу из пруда.\n",
    "Оценка:\n",
    "\n",
    "model=xglm-4.5B_ru_v10epoch=2 result=90\n",
    "\n",
    "Оцени выполненную задачу от 0 до 100. \n",
    "0  значит что модель совершенно не справилась с задачей, грамматическая структура нарушена, получен очень короткий и односложный ответ.  \n",
    "100 значит что модель справилась с задачей, язык соответствует всем грамматическим нормам, получен осмысленный и развернутый ответ.\n",
    "В ответе используй только число.\n",
    "Задача:\n",
    "Переведите следующее русское выражение на английский язык: \"Без труда не вытащишь и рыбку из пруда.\"\n",
    "Выполненное задание:\n",
    "Без усилий не вытащишь и рыбу из пруда.\n",
    "Оценка:\n",
    "\n",
    "model=xglm-4.5B_ru_v10epoch=3 result=90\n",
    "\n",
    "Оцени выполненную задачу от 0 до 100. \n",
    "0  значит что модель совершенно не справилась с задачей, грамматическая структура нарушена, получен очень короткий и односложный ответ.  \n",
    "100 значит что модель справилась с задачей, язык соответствует всем грамматическим нормам, получен осмысленный и развернутый ответ.\n",
    "В ответе используй только число.\n",
    "Задача:\n",
    "Переведите следующее русское выражение на английский язык: \"Без труда не вытащишь и рыбку из пруда.\"\n",
    "Выполненное задание:\n",
    "Без особых усилий не вытащишь и рыбу из пруда.\n",
    "Оценка:\n",
    "\n",
    "model=xglm-4.5B_ru_v10epoch=3_step=82283 result=90\n",
    "\n",
    "Оцени выполненную задачу от 0 до 100. \n",
    "0  значит что модель совершенно не справилась с задачей, грамматическая структура нарушена, получен очень короткий и односложный ответ.  \n",
    "100 значит что модель справилась с задачей, язык соответствует всем грамматическим нормам, получен осмысленный и развернутый ответ.\n",
    "В ответе используй только число.\n",
    "Задача:\n",
    "Переведите следующее русское выражение на английский язык: \"Без труда не вытащишь и рыбку из пруда.\"\n",
    "Выполненное задание:\n",
    "Без усилий не вытащишь и рыбу из пруда.\n",
    "Оценка:\n",
    "\n",
    "model=xglm-4.5B_ru_v10epoch=4 result=90\n",
    "\n",
    "Оцени выполненную задачу от 0 до 100. \n",
    "0  значит что модель совершенно не справилась с задачей, грамматическая структура нарушена, получен очень короткий и односложный ответ.  \n",
    "100 значит что модель справилась с задачей, язык соответствует всем грамматическим нормам, получен осмысленный и развернутый ответ.\n",
    "В ответе используй только число.\n",
    "Задача:\n",
    "Переведите следующее русское выражение на английский язык: \"Без труда не вытащишь и рыбку из пруда.\"\n",
    "Выполненное задание:\n",
    "Без усилий не вытащишь и рыбу из пруда.\n",
    "Оценка:\n",
    "\n",
    "model=xglm-4.5B_ru_v10epoch=5 result=90\n",
    "\n",
    "Оцени выполненную задачу от 0 до 100. \n",
    "0  значит что модель совершенно не справилась с задачей, грамматическая структура нарушена, получен очень короткий и односложный ответ.  \n",
    "100 значит что модель справилась с задачей, язык соответствует всем грамматическим нормам, получен осмысленный и развернутый ответ.\n",
    "В ответе используй только число.\n",
    "Задача:\n",
    "Переведите следующее русское выражение на английский язык: \"Без труда не вытащишь и рыбку из пруда.\"\n",
    "Выполненное задание:\n",
    "Без усилий не вытащишь и рыбу из пруда.\n",
    "Оценка:\n",
    "\n",
    "model=xglm-4.5B_ru_v10epoch=5_step=102854 result=90\n",
    "\n",
    "Оцени выполненную задачу от 0 до 100. \n",
    "0  значит что модель совершенно не справилась с задачей, грамматическая структура нарушена, получен очень короткий и односложный ответ.  \n",
    "100 значит что модель справилась с задачей, язык соответствует всем грамматическим нормам, получен осмысленный и развернутый ответ.\n",
    "В ответе используй только число.\n",
    "Задача:\n",
    "Переведите следующее русское выражение на английский язык: \"Без труда не вытащишь и рыбку из пруда.\"\n",
    "Выполненное задание:\n",
    "Без труда не вытащишь и рыбу из пруда.\n",
    "Оценка:\n",
    "\n",
    "model=xglm-4.5B_ru_v10epoch=5_step=20570 result=90\n",
    "\n",
    "Оцени выполненную задачу от 0 до 100. \n",
    "0  значит что модель совершенно не справилась с задачей, грамматическая структура нарушена, получен очень короткий и односложный ответ.  \n",
    "100 значит что модель справилась с задачей, язык соответствует всем грамматическим нормам, получен осмысленный и развернутый ответ.\n",
    "В ответе используй только число.\n",
    "Задача:\n",
    "Переведите следующее русское выражение на английский язык: \"Без труда не вытащишь и рыбку из пруда.\"\n",
    "Выполненное задание:\n",
    "Без труда не вытащишь и рыбу из пруда.\n",
    "Оценка:\n",
    "\n",
    "model=xglm-4.5B_ru_v10epoch=5_step=41141 result=90\n",
    "\n",
    "Оцени выполненную задачу от 0 до 100. \n",
    "0  значит что модель совершенно не справилась с задачей, грамматическая структура нарушена, получен очень короткий и односложный ответ.  \n",
    "100 значит что модель справилась с задачей, язык соответствует всем грамматическим нормам, получен осмысленный и развернутый ответ.\n",
    "В ответе используй только число.\n",
    "Задача:\n",
    "Переведите следующее русское выражение на английский язык: \"Без труда не вытащишь и рыбку из пруда.\"\n",
    "Выполненное задание:\n",
    "Без труда не вытащишь и рыбу из пруда.\n",
    "Оценка:\n",
    "\n",
    "model=xglm-4.5B_ru_v10epoch=5_step=61712 result=90\n",
    "\n",
    "Оцени выполненную задачу от 0 до 100. \n",
    "0  значит что модель совершенно не справилась с задачей, грамматическая структура нарушена, получен очень короткий и односложный ответ.  \n",
    "100 значит что модель справилась с задачей, язык соответствует всем грамматическим нормам, получен осмысленный и развернутый ответ.\n",
    "В ответе используй только число.\n",
    "Задача:\n",
    "Переведите следующее русское выражение на английский язык: \"Без труда не вытащишь и рыбку из пруда.\"\n",
    "Выполненное задание:\n",
    "Без усилий не вытащишь и рыбу из пруда.\n",
    "Оценка:\n",
    "\n",
    "model=xglm-4.5B_ru_v10epoch=5_step=82283 result=90\n",
    "\n",
    "Оцени выполненную задачу от 0 до 100. \n",
    "0  значит что модель совершенно не справилась с задачей, грамматическая структура нарушена, получен очень короткий и односложный ответ.  \n",
    "100 значит что модель справилась с задачей, язык соответствует всем грамматическим нормам, получен осмысленный и развернутый ответ.\n",
    "В ответе используй только число.\n",
    "Задача:\n",
    "Переведите следующее русское выражение на английский язык: \"Без труда не вытащишь и рыбку из пруда.\"\n",
    "Выполненное задание:\n",
    "Без усилий не вытащишь и рыбу из пруда.\n",
    "Оценка:\n",
    "\n",
    "model=xglm-4.5B_ru_v10epoch=6_step=20570 result=90\n",
    "\n",
    "Оцени выполненную задачу от 0 до 100. \n",
    "0  значит что модель совершенно не справилась с задачей, грамматическая структура нарушена, получен очень короткий и односложный ответ.  \n",
    "100 значит что модель справилась с задачей, язык соответствует всем грамматическим нормам, получен осмысленный и развернутый ответ.\n",
    "В ответе используй только число.\n",
    "Задача:\n",
    "Переведите следующее русское выражение на английский язык: \"Без труда не вытащишь и рыбку из пруда.\"\n",
    "Выполненное задание:\n",
    "Без труда не вытащишь и рыбу из пруда.\n",
    "Оценка:\n",
    "\n",
    "model=xglm-4.5B_ru_v10epoch=6_step=41141 result=90\n",
    "\n",
    "Оцени выполненную задачу от 0 до 100. \n",
    "0  значит что модель совершенно не справилась с задачей, грамматическая структура нарушена, получен очень короткий и односложный ответ.  \n",
    "100 значит что модель справилась с задачей, язык соответствует всем грамматическим нормам, получен осмысленный и развернутый ответ.\n",
    "В ответе используй только число.\n",
    "Задача:\n",
    "Переведите следующее русское выражение на английский язык: \"Без труда не вытащишь и рыбку из пруда.\"\n",
    "Выполненное задание:\n",
    "Без труда не вытащишь и рыбу из пруда.\n",
    "Оценка:\n",
    "\n",
    "model=xglm-4.5B_ru_v10epoch=6_step=61712 result=90\n",
    "-------------------------------------------------------------------\n",
    "\n",
    "\n",
    "Оцени выполненную задачу от 0 до 100. \n",
    "0  значит что модель совершенно не справилась с задачей, грамматическая структура нарушена, получен очень короткий и односложный ответ.  \n",
    "100 значит что модель справилась с задачей, язык соответствует всем грамматическим нормам, получен осмысленный и развернутый ответ.\n",
    "В ответе используй только число.\n",
    "Задача:\n",
    "Напишите краткое эссе на тему \"История развития компьютерной техники\".\n",
    "Выполненное задание:\n",
    "История развития компьютерной техники - это история изобретений, которые привели к созданию компьютера. Первым компьютером был механический калькулятор, изобретенный Чарльзом Бэббиджем в 1822 году. В 1837 году он построил первый электронный компьютер, который назывался Analytical Engine. Аналитический двигатель использовался для вычисления математических функций и был первым компьютером с программируемыми ячейками памяти. В конце 1800-х годов были разработаны первые электронные вычислительные машины, такие как ENIAC (Электронный автоматный комплекс), который был построен в 1946 году. ENIAC был первым компьютером с программируемой памятью, что позволило ему выполнять сложные вычисления. С тех пор было много других разработок, таких как компьютеры общего назначения, персональные компьютеры и Интернет.\n",
    "Оценка:\n",
    "\n",
    "model=xglm-4.5B_ru_v10epoch=0 result=85\n",
    "\n",
    "Оцени выполненную задачу от 0 до 100. \n",
    "0  значит что модель совершенно не справилась с задачей, грамматическая структура нарушена, получен очень короткий и односложный ответ.  \n",
    "100 значит что модель справилась с задачей, язык соответствует всем грамматическим нормам, получен осмысленный и развернутый ответ.\n",
    "В ответе используй только число.\n",
    "Задача:\n",
    "Напишите краткое эссе на тему \"История развития компьютерной техники\".\n",
    "Выполненное задание:\n",
    "История развития компьютерной техники - это история изобретений, которые привели к созданию компьютера. Первым компьютером был механический калькулятор, изобретенный Чарльзом Бэббиджем в 1822 году. В 1837 году он построил первый электронный компьютер, который назывался Analytical Engine. Аналитический двигатель использовался для вычисления математических функций и был первым компьютером с программируемыми ячейками памяти. В конце 1800-х годов были разработаны первые электронные вычислительные машины, такие как ENIAC (Электронный автоматный комплекс), который был построен в 1946 году. ENIAC был первым компьютером с программируемой памятью, что позволило ему выполнять сложные вычисления. С тех пор было много других разработок, таких как компьютеры общего назначения, персональные компьютеры и Интернет.\n",
    "Оценка:\n",
    "\n",
    "model=xglm-4.5B_ru_v10epoch=0_step=102854 result=90\n",
    "\n",
    "Оцени выполненную задачу от 0 до 100. \n",
    "0  значит что модель совершенно не справилась с задачей, грамматическая структура нарушена, получен очень короткий и односложный ответ.  \n",
    "100 значит что модель справилась с задачей, язык соответствует всем грамматическим нормам, получен осмысленный и развернутый ответ.\n",
    "В ответе используй только число.\n",
    "Задача:\n",
    "Напишите краткое эссе на тему \"История развития компьютерной техники\".\n",
    "Выполненное задание:\n",
    "История развития компьютерной техники - это история изобретений, которые привели к созданию компьютера. Первым компьютером был механический калькулятор, который использовался для вычислений в начале 1800-х годов. В конце 1800-х годов были изобретены первые электронные вычислительные машины (ЭВМ), которые позволили людям выполнять более сложные задачи. ЭВМ стали популярными во второй половине 1900-х годов и продолжают развиваться по сей день.\n",
    "Оценка:\n",
    "\n",
    "model=xglm-4.5B_ru_v10epoch=0_step=20570 result=80\n",
    "\n",
    "Оцени выполненную задачу от 0 до 100. \n",
    "0  значит что модель совершенно не справилась с задачей, грамматическая структура нарушена, получен очень короткий и односложный ответ.  \n",
    "100 значит что модель справилась с задачей, язык соответствует всем грамматическим нормам, получен осмысленный и развернутый ответ.\n",
    "В ответе используй только число.\n",
    "Задача:\n",
    "Напишите краткое эссе на тему \"История развития компьютерной техники\".\n",
    "Выполненное задание:\n",
    "История развития компьютерной техники - это история изобретений, которые привели к созданию компьютера. Первым компьютером был механический калькулятор, изобретенный Джоном фон Нейманом в 1822 году. В то время он использовал шестерни и рычаги для выполнения вычислений. Позже он разработал машину с программируемыми вентилями (ПЛК), которая была первой машиной с программируемой логикой. ПЛК позволяла машине выполнять сложные математические операции без необходимости использовать отдельные детали. Машина с программируемыми вентилями также стала первым компьютером, который мог быть подключен к сети. Это позволило людям работать вместе над проектами и обмениваться информацией.\n",
    "Оценка:\n",
    "\n",
    "model=xglm-4.5B_ru_v10epoch=0_step=41141 result=80\n",
    "\n",
    "Оцени выполненную задачу от 0 до 100. \n",
    "0  значит что модель совершенно не справилась с задачей, грамматическая структура нарушена, получен очень короткий и односложный ответ.  \n",
    "100 значит что модель справилась с задачей, язык соответствует всем грамматическим нормам, получен осмысленный и развернутый ответ.\n",
    "В ответе используй только число.\n",
    "Задача:\n",
    "Напишите краткое эссе на тему \"История развития компьютерной техники\".\n",
    "Выполненное задание:\n",
    "История развития компьютерной техники - это история изобретений, разработок и инноваций в области вычислений. Она охватывает период от первых механических компьютеров до современных суперкомпьютеров с миллиардами транзисторов. Компьютерная техника постоянно развивается, предлагая новые возможности для решения проблем и создания новых технологий.\n",
    "Оценка:\n",
    "\n",
    "model=xglm-4.5B_ru_v10epoch=0_step=61712 result=90\n",
    "\n",
    "Оцени выполненную задачу от 0 до 100. \n",
    "0  значит что модель совершенно не справилась с задачей, грамматическая структура нарушена, получен очень короткий и односложный ответ.  \n",
    "100 значит что модель справилась с задачей, язык соответствует всем грамматическим нормам, получен осмысленный и развернутый ответ.\n",
    "В ответе используй только число.\n",
    "Задача:\n",
    "Напишите краткое эссе на тему \"История развития компьютерной техники\".\n",
    "Выполненное задание:\n",
    "Компьютерная техника - это отрасль, которая включает в себя все виды вычислительной техники. Она охватывает такие вещи, как микропроцессоры, память и периферийные устройства, которые используются для выполнения вычислений. История компьютерной техники началась с первых механических компьютеров, построенных в конце 1940-х годов. В 1950-х годах были разработаны первые электронные компьютеры, а в 1960-х годах появились первые программируемые компьютеры. С тех пор компьютерная техника развивалась быстрыми темпами, и сегодня она используется во многих областях, включая здравоохранение, образование, финансы и многое другое.\n",
    "Оценка:\n",
    "\n",
    "model=xglm-4.5B_ru_v10epoch=0_step=82283 result=90\n",
    "\n",
    "Оцени выполненную задачу от 0 до 100. \n",
    "0  значит что модель совершенно не справилась с задачей, грамматическая структура нарушена, получен очень короткий и односложный ответ.  \n",
    "100 значит что модель справилась с задачей, язык соответствует всем грамматическим нормам, получен осмысленный и развернутый ответ.\n",
    "В ответе используй только число.\n",
    "Задача:\n",
    "Напишите краткое эссе на тему \"История развития компьютерной техники\".\n",
    "Выполненное задание:\n",
    "История развития компьютерной техники - это увлекательная и сложная история, которая началась с первых механических вычислительных машин в конце 19-го века. С тех пор компьютеры совершенствовались и развивались, чтобы стать мощными инструментами для решения сложных проблем, таких как обработка данных, анализ больших объемов информации и создание новых приложений. В течение этого периода компьютерные технологии также претерпели значительные изменения, включая появление микропроцессоров, которые позволили компьютерам выполнять более сложные задачи, чем когда-либо прежде. Сегодня компьютеры используются во многих различных областях, от здравоохранения до развлечений, и они продолжают расти и совершенствоваться по мере того, как новые технологии становятся все более доступными.\n",
    "Оценка:\n",
    "\n",
    "model=xglm-4.5B_ru_v10epoch=1 result=90\n",
    "\n",
    "Оцени выполненную задачу от 0 до 100. \n",
    "0  значит что модель совершенно не справилась с задачей, грамматическая структура нарушена, получен очень короткий и односложный ответ.  \n",
    "100 значит что модель справилась с задачей, язык соответствует всем грамматическим нормам, получен осмысленный и развернутый ответ.\n",
    "В ответе используй только число.\n",
    "Задача:\n",
    "Напишите краткое эссе на тему \"История развития компьютерной техники\".\n",
    "Выполненное задание:\n",
    "История развития компьютерной техники - это увлекательный и захватывающий рассказ о том, как технологии развивались с течением времени. С момента изобретения первого компьютера в 1822 году до сегодняшнего дня компьютеры претерпели огромный прогресс, от механических машин до высокотехнологичных систем, которые используются для решения сложных проблем. Впервые разработанные в качестве инструментов для научных исследований, первые компьютеры использовали перфокарты и клавиатуры, чтобы хранить и манипулировать данными. Со временем они совершенствовались, включая использование электронных схем и микропроцессоров, что позволило им выполнять более сложные задачи. Сегодня компьютеры используются по-разному, от игр и развлечений до обработки данных и создания новых технологий. Они также играют важную роль в повседневной жизни, позволяя людям оставаться на связи, получать доступ к информации и совершать покупки.\n",
    "Оценка:\n",
    "\n",
    "model=xglm-4.5B_ru_v10epoch=2 result=90\n",
    "\n",
    "Оцени выполненную задачу от 0 до 100. \n",
    "0  значит что модель совершенно не справилась с задачей, грамматическая структура нарушена, получен очень короткий и односложный ответ.  \n",
    "100 значит что модель справилась с задачей, язык соответствует всем грамматическим нормам, получен осмысленный и развернутый ответ.\n",
    "В ответе используй только число.\n",
    "Задача:\n",
    "Напишите краткое эссе на тему \"История развития компьютерной техники\".\n",
    "Выполненное задание:\n",
    "История развития компьютерной техники - это увлекательный и захватывающий рассказ о том, как технологии развивались с течением времени. С момента изобретения первого компьютера в конце 19-го века компьютерная техника быстро росла и развивалась, чтобы стать неотъемлемой частью нашей повседневной жизни. От первых механических компьютеров до самых современных суперкомпьютеров, история развития компьютерной техники полна достижений и инноваций.\n",
    "Оценка:\n",
    "\n",
    "model=xglm-4.5B_ru_v10epoch=3 result=90\n",
    "\n",
    "Оцени выполненную задачу от 0 до 100. \n",
    "0  значит что модель совершенно не справилась с задачей, грамматическая структура нарушена, получен очень короткий и односложный ответ.  \n",
    "100 значит что модель справилась с задачей, язык соответствует всем грамматическим нормам, получен осмысленный и развернутый ответ.\n",
    "В ответе используй только число.\n",
    "Задача:\n",
    "Напишите краткое эссе на тему \"История развития компьютерной техники\".\n",
    "Выполненное задание:\n",
    "История развития компьютерной техники восходит к изобретению первого механического компьютера, ENIAC, в 1946 году. С тех пор компьютерная техника значительно продвинулась, и сегодня существует широкий спектр различных типов компьютеров, от настольных компьютеров до смартфонов. Компьютеры также используются во многих других областях, таких как здравоохранение, финансы, транспорт и многое другое.\n",
    "Оценка:\n",
    "\n",
    "model=xglm-4.5B_ru_v10epoch=3_step=82283 result=90\n",
    "\n",
    "Оцени выполненную задачу от 0 до 100. \n",
    "0  значит что модель совершенно не справилась с задачей, грамматическая структура нарушена, получен очень короткий и односложный ответ.  \n",
    "100 значит что модель справилась с задачей, язык соответствует всем грамматическим нормам, получен осмысленный и развернутый ответ.\n",
    "В ответе используй только число.\n",
    "Задача:\n",
    "Напишите краткое эссе на тему \"История развития компьютерной техники\".\n",
    "Выполненное задание:\n",
    "История развития компьютерной техники восходит к началу 20-го века, когда были разработаны первые электронные устройства. В начале 1930-х годов были построены первые электронные компьютеры, которые использовали перфокарты для хранения данных и работали с помощью электронных лампочек. К 1950-м годам были разработаны первые программируемые компьютеры, которые могли выполнять вычисления с использованием компьютера. С тех пор компьютерная техника развивалась быстрыми темпами, что привело к появлению таких технологий, как микропроцессоры, графические процессоры и сети. Сегодня компьютеры используются по-разному, от игр до научных исследований и многих других.\n",
    "Оценка:\n",
    "\n",
    "model=xglm-4.5B_ru_v10epoch=4 result=90\n",
    "\n",
    "Оцени выполненную задачу от 0 до 100. \n",
    "0  значит что модель совершенно не справилась с задачей, грамматическая структура нарушена, получен очень короткий и односложный ответ.  \n",
    "100 значит что модель справилась с задачей, язык соответствует всем грамматическим нормам, получен осмысленный и развернутый ответ.\n",
    "В ответе используй только число.\n",
    "Задача:\n",
    "Напишите краткое эссе на тему \"История развития компьютерной техники\".\n",
    "Выполненное задание:\n",
    "История развития компьютерной техники восходит к концу 19-го века, когда были разработаны первые механические компьютеры. В начале 20-го века были созданы первые электронные компьютеры, которые использовали транзисторы и кремниевые пластины для выполнения вычислений. К 1930-м годам были разработаны первые микрокомпьютеры, которые могли выполнять ограниченные вычисления. С тех пор компьютерная техника развивалась быстрыми темпами, с появлением новых технологий, таких как микропроцессоры, графические процессоры и сети. Эти достижения позволили повысить производительность и эффективность компьютерных систем, позволяя им обрабатывать огромные объемы данных и выполнять сложные задачи.\n",
    "Оценка:\n",
    "\n",
    "model=xglm-4.5B_ru_v10epoch=5 result=90\n",
    "\n",
    "Оцени выполненную задачу от 0 до 100. \n",
    "0  значит что модель совершенно не справилась с задачей, грамматическая структура нарушена, получен очень короткий и односложный ответ.  \n",
    "100 значит что модель справилась с задачей, язык соответствует всем грамматическим нормам, получен осмысленный и развернутый ответ.\n",
    "В ответе используй только число.\n",
    "Задача:\n",
    "Напишите краткое эссе на тему \"История развития компьютерной техники\".\n",
    "Выполненное задание:\n",
    "История развития компьютерной техники восходит к концу 19-го века, когда были разработаны первые механические компьютеры. В начале 20-го века были созданы первые электронные компьютеры, которые использовали транзисторы и кремниевые пластины для выполнения вычислений. К 1930-м годам были разработаны первые микрокомпьютеры, которые могли выполнять ограниченные вычисления. С тех пор компьютерная техника развивалась быстрыми темпами, с появлением новых технологий, таких как микропроцессоры, графические процессоры и сети. Эти достижения позволили повысить производительность и эффективность компьютерных систем, позволяя им обрабатывать огромные объемы данных и выполнять сложные задачи.\n",
    "Оценка:\n",
    "\n",
    "model=xglm-4.5B_ru_v10epoch=5_step=102854 result=90\n",
    "\n",
    "Оцени выполненную задачу от 0 до 100. \n",
    "0  значит что модель совершенно не справилась с задачей, грамматическая структура нарушена, получен очень короткий и односложный ответ.  \n",
    "100 значит что модель справилась с задачей, язык соответствует всем грамматическим нормам, получен осмысленный и развернутый ответ.\n",
    "В ответе используй только число.\n",
    "Задача:\n",
    "Напишите краткое эссе на тему \"История развития компьютерной техники\".\n",
    "Выполненное задание:\n",
    "Компьютерная техника - это сложная система, которая использует вычислительные методы для хранения и обработки информации. Она существует уже более 50 лет, с первых электронных компьютеров, разработанных в конце 1950-х годов, до современных суперкомпьютеров, которые могут выполнять сложные вычисления за считанные секунды. В течение этого времени компьютерная техника развивалась со временем, и сегодня она включает в себя множество различных типов устройств, включая компьютеры общего назначения (CPU), микропроцессоры, графические процессоры, накопители, сети и многое другое. Эти устройства предназначены для обработки данных и выполнения вычислений, что позволяет людям использовать компьютеры для решения проблем, создания новых возможностей и доступа к информации по-новому.\n",
    "Оценка:\n",
    "\n",
    "model=xglm-4.5B_ru_v10epoch=5_step=20570 result=90\n",
    "\n",
    "Оцени выполненную задачу от 0 до 100. \n",
    "0  значит что модель совершенно не справилась с задачей, грамматическая структура нарушена, получен очень короткий и односложный ответ.  \n",
    "100 значит что модель справилась с задачей, язык соответствует всем грамматическим нормам, получен осмысленный и развернутый ответ.\n",
    "В ответе используй только число.\n",
    "Задача:\n",
    "Напишите краткое эссе на тему \"История развития компьютерной техники\".\n",
    "Выполненное задание:\n",
    "История развития компьютерной техники - это увлекательный и захватывающий рассказ о том, как технологии меняют нашу жизнь. С момента изобретения первого компьютера в начале 20-го века компьютерная техника превратилась из простого устройства для хранения и обработки данных в мощное средство для решения сложных проблем. В течение этого времени достижения в области вычислительной техники позволили ученым, инженерам и исследователям разработать новые методы и идеи, которые привели к развитию таких технологий, как искусственный интеллект, машинное обучение и облачные вычисления. Сегодня компьютеры используются по-разному, от игр до здравоохранения и финансового анализа, но их потенциал все еще неоценим.\n",
    "Оценка:\n",
    "\n",
    "model=xglm-4.5B_ru_v10epoch=5_step=41141 result=90\n",
    "\n",
    "Оцени выполненную задачу от 0 до 100. \n",
    "0  значит что модель совершенно не справилась с задачей, грамматическая структура нарушена, получен очень короткий и односложный ответ.  \n",
    "100 значит что модель справилась с задачей, язык соответствует всем грамматическим нормам, получен осмысленный и развернутый ответ.\n",
    "В ответе используй только число.\n",
    "Задача:\n",
    "Напишите краткое эссе на тему \"История развития компьютерной техники\".\n",
    "Выполненное задание:\n",
    "История развития компьютерной техники - это увлекательный и захватывающий рассказ о том, как технологии развивались с течением времени. От ранних механических компьютеров до современных суперкомпьютеров, история развития компьютерной техники полна достижений и открытий.\n",
    "\n",
    "С самого начала человеческая цивилизаци была основана на использовании инструментов для обработки информации. Первыми известными компьютерами были механические устройства, такие как аналитические машины, которые использовались для вычисления чисел. Однако первые электронные компьютеры не были построены людьми, а скорее были созданы в лаборатории. Эти ранние электронные компьютеры использовали перфокарты для хранения данных и использовали серию шестеренок для управления работой компьютера.\n",
    "\n",
    "В конце 19-го века достижения в области электромагнетизма позволили создать первый электронный компьютер. Это был ENIAC (Электрический вычислительный автомат), который был построен Джоном Мочли и Дж. Преспером Эккертом в Университете Пенсильвании. ENIAC был первым электронным компьютером, который использовал перфокарты для хранения данных и использовал серию шестеренок для управления работой компьютера. ENIAC также считается первым компьютером общего назначения, что означает, что он может быть использован для решения широкого спектра задач, включая математические вычисления, статистическое моделирование и научные исследования.\n",
    "\n",
    "В начале 20-го века достижения в области радиотехники позволили создать первый электронный телеграф. Это был telégraphe electronique (ЭЛТ) или вакуумный телеграф, который был разработан Луисом Лагранжем и Клодом Шенноном в Парижском университете. ЭЛТ был первым электронным телеграфом, который использовал серию шестеренок для управления работой компьютера. ЭЛТ также считается первым компьютером общего назначения, что означает, что он может быть использован для решения широкого спектра задач, включая математические вычисления, статистическое моделирование и научные исследования.\n",
    "\n",
    "В 1950-х годах достижения в области микроэлектроники позволили создать первый интегральный микропроцессор (ИИМ). Это был интегральный микропроцессор (ISP), который был разработан Джеком Килби и Джоном Маккарти в Массачусетском технологическом институте (MIT). ISP был первым интегральным микропроцессором, который использовал серию шестеренок для управления работой компьютера. ISP также считается первым компьютером общего назначения, что означает, что он может быть использован для решения широкого спектра задач, включая математические вычисления, статистическое моделирование и научные исследования.\n",
    "\n",
    "В 1980-х годах достижения в области полупроводниковых технологий позволили создать первый микропроцессор общего назначения. Это был процессор Intel 8088, который был разработан Джоном Маккарти и Стивом Возняком в Массачусетском технологическом институте (MIT). Процессор Intel 8088 был первым микропроцессором общего назначения, который использовал серию шестеренок для управления работой компьютера. ISP также считается первым компьютером общего назначения, что означает, что он может быть использован для решения широкого спектра задач, включая математические вычисления, статистическое моделирование и научные исследования.\n",
    "Оценка:\n",
    "\n",
    "model=xglm-4.5B_ru_v10epoch=5_step=61712 result=80\n",
    "\n",
    "Оцени выполненную задачу от 0 до 100. \n",
    "0  значит что модель совершенно не справилась с задачей, грамматическая структура нарушена, получен очень короткий и односложный ответ.  \n",
    "100 значит что модель справилась с задачей, язык соответствует всем грамматическим нормам, получен осмысленный и развернутый ответ.\n",
    "В ответе используй только число.\n",
    "Задача:\n",
    "Напишите краткое эссе на тему \"История развития компьютерной техники\".\n",
    "Выполненное задание:\n",
    "Компьютерная техника прокладывает себе путь от простого устройства, которое хранит и обрабатывает информацию, до сложной системы, которая использует вычислительные мощности для выполнения задач. С момента своего создания компьютеры развивались с течением времени, меняясь по мере того, как новые технологии добавлялись в их состав. В начале 1900-х годов первые электронные устройства были разработаны учеными и инженерами, которые хотели создать машину, которая могла бы выполнять вычисления. К 1930-м годам достижения в области электроники позволили создать более сложные компьютерные системы, такие как ENIAC (конец 1940-х - начало 1950-х годов). Эти ранние компьютеры использовали перфокарты и перфопленку для хранения данных, но они не были достаточно мощными, чтобы справиться со сложными математическими операциями, которые требовали современной вычислительной техники.\n",
    "\n",
    "В 1960-х годах достижения в области полупроводниковых технологий позволили создать более эффективные компьютеры, такие как ARPANET (начало 1970-х годов), которая объединила компьютеров из разных стран. Эти ранние компьютеры использовали перфокарты и перфопленку для хранения данных, но они не были достаточно мощными, чтобы справиться со сложными математическими операциями, которые потребовали современной вычислительной техники.\n",
    "\n",
    "В 1980-х годах достижения в области микропроцессоров позволили создавать более мощные компьютеры, такие как IBM PC (1984 год) и Apple Macintosh (1989). Эти ранние компьютеры использовали перфокарты и перфопленку для хранения данных, но они не были достаточно мощными, чтобы справиться со сложными математическими операциями, которые потребовали современной вычислительной техники.\n",
    "\n",
    "В 1990-х годах достижения в области программного обеспечения позволили создавать более мощные и эффективные компьютеры, такие как Windows 95 и Mac OS X. Эти ранние компьютеры использовали перфокарты и перфопленку для хранения данных, но они не были достаточно мощными, чтобы справиться со сложными математическими операциями, которые потребовали современной вычислительной техники.\n",
    "\n",
    "Сегодня компьютерная техника продолжает развиваться, предлагая новые функции и возможности, которые облегчают жизнь людей. Например, смартфоны становятся все более популярными благодаря своим удобным функциям, таким как доступ к Интернету и приложениям. Кроме того, облачные вычисления предлагают безопасные и надежные решения для хранения и обработки данных.\n",
    "Оценка:\n",
    "\n",
    "model=xglm-4.5B_ru_v10epoch=5_step=82283 result=80\n",
    "\n",
    "Оцени выполненную задачу от 0 до 100. \n",
    "0  значит что модель совершенно не справилась с задачей, грамматическая структура нарушена, получен очень короткий и односложный ответ.  \n",
    "100 значит что модель справилась с задачей, язык соответствует всем грамматическим нормам, получен осмысленный и развернутый ответ.\n",
    "В ответе используй только число.\n",
    "Задача:\n",
    "Напишите краткое эссе на тему \"История развития компьютерной техники\".\n",
    "Выполненное задание:\n",
    "Компьютерная техника существует уже давно, и ее история восходит к древним временам. Первыми компьютерами были механические устройства, такие как аналитические инструменты и счетные машины. В конце 19-го века электрические компьютеры начали появляться, но они были слишком дорогими и не могли выполнять сложные вычисления. В начале 20-го века полупроводниковые компьютеры стали доступны, и они позволили создать более мощные и эффективные компьютеры. К середине 20-го века цифровые компьютеры были разработаны и установлены впромышленных условиях. Сегодня компьютерная техника продвинулась далеко вперед, с множеством новых технологий и приложений.\n",
    "Оценка:\n",
    "\n",
    "model=xglm-4.5B_ru_v10epoch=6_step=20570 result=90\n",
    "\n",
    "Оцени выполненную задачу от 0 до 100. \n",
    "0  значит что модель совершенно не справилась с задачей, грамматическая структура нарушена, получен очень короткий и односложный ответ.  \n",
    "100 значит что модель справилась с задачей, язык соответствует всем грамматическим нормам, получен осмысленный и развернутый ответ.\n",
    "В ответе используй только число.\n",
    "Задача:\n",
    "Напишите краткое эссе на тему \"История развития компьютерной техники\".\n",
    "Выполненное задание:\n",
    "История развития компьютерной техники восходит к концу 1940-х годов, когда Алан Тьюринг предложил концепцию универсальной машины. В 1950-х годах были разработаны первые компьютеры общего назначения, такие как ENIAC и MITS. К 1960-м годам достижения в области вычислительной техники позволили создать более мощные и эффективные компьютеры. Эти достижения привели к созданию первого коммерческого компьютера, ПК IBM PC, в начале 1970-х годов. С тех пор компьютерная техника значительно продвинулась, с появлением таких технологий, как графические процессоры, микропроцессоры, сенсорные экраны и сети. Сегодня компьютерная техника используется во многих областях, от научных исследований до развлечений, и продолжает развиваться с каждым новым достижением.\n",
    "Оценка:\n",
    "\n",
    "model=xglm-4.5B_ru_v10epoch=6_step=41141 result=90\n",
    "\n",
    "Оцени выполненную задачу от 0 до 100. \n",
    "0  значит что модель совершенно не справилась с задачей, грамматическая структура нарушена, получен очень короткий и односложный ответ.  \n",
    "100 значит что модель справилась с задачей, язык соответствует всем грамматическим нормам, получен осмысленный и развернутый ответ.\n",
    "В ответе используй только число.\n",
    "Задача:\n",
    "Напишите краткое эссе на тему \"История развития компьютерной техники\".\n",
    "Выполненное задание:\n",
    "История развития компьютерной техники восходит к концу 19-го века, когда были разработаны первые электронные устройства. В начале 20-го века были созданы первые электронные компьютеры, такие как ENIAC (конец 1940-х годов) и Z1 (1950-е годы). Эти ранние компьютеры использовали перфокарты для хранения данных, но в 1950-х годах была разработана первая микропроцессорная система, ARPANET (1956 год), которая позволила компьютерам общаться друг с другом через Интернет.\n",
    "Оценка:\n",
    "\n",
    "model=xglm-4.5B_ru_v10epoch=6_step=61712 result=90\n",
    "\n",
    "\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
